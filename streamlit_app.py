import os
import datetime
import streamlit as st
from openai import OpenAI, APIError
from docx import Document
import tempfile
import json
import pandas as pd
import re
from typing import Dict, Any, Union

# ë£¨ë¸Œë¦­ ê¸°ì¤€ ì •ì˜
RUBRIC_CRITERIA = {
    "ë‚´ìš©ë…¼ë¦¬ì„±": {
        "4ì  (ìš°ìˆ˜)": "ì£¼ì¥ì´ ëª…í™•í•˜ê³  ì¶©ë¶„í•œ ê·¼ê±°ê°€ ì²´ê³„ì ìœ¼ë¡œ ì œì‹œë¨. ë…¼ë¦¬ì  ì—°ê²°ì´ ìì—°ìŠ¤ëŸ½ê³  ì„¤ë“ë ¥ì´ ìˆìŒ",
        "3ì  (ë³´í†µ)": "ì£¼ì¥ì€ ëª…í™•í•˜ë‚˜ ê·¼ê±°ê°€ ë¶€ë¶„ì ìœ¼ë¡œ ë¶€ì¡±í•˜ê±°ë‚˜ ë…¼ë¦¬ì  ì—°ê²°ì´ ì¼ë¶€ ì–´ìƒ‰í•¨",
        "2ì  (ë¯¸í¡)": "ì£¼ì¥ì´ ë‹¤ì†Œ ëª¨í˜¸í•˜ê³  ê·¼ê±°ê°€ ì•½í•¨. ë…¼ë¦¬ì  ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŒ",
        "1ì  (ë¶€ì¡±)": "ì£¼ì¥ê³¼ ê·¼ê±°ê°€ ë¶ˆë¶„ëª…í•˜ê³  ë…¼ë¦¬ì  íë¦„ì´ ë¶€ìì—°ìŠ¤ëŸ¬ì›€"
    },
    "êµ¬ì„±ì²´ê³„ì„±": {
        "4ì  (ìš°ìˆ˜)": "ì„œë¡ -ë³¸ë¡ -ê²°ë¡  êµ¬ì¡°ê°€ ëª…í™•í•˜ê³  ë¬¸ë‹¨ ê°„ ì—°ê²°ì´ ìì—°ìŠ¤ëŸ¬ì›€. ì‘ì§‘ì„±ê³¼ ì¼ê´€ì„±ì´ ë›°ì–´ë‚¨",
        "3ì  (ë³´í†µ)": "ì „ì²´ êµ¬ì¡°ëŠ” ê°–ì¶”ì—ˆìœ¼ë‚˜ ë¬¸ë‹¨ ê°„ ì—°ê²°ì´ ë¶€ë¶„ì ìœ¼ë¡œ ì–´ìƒ‰í•¨",
        "2ì  (ë¯¸í¡)": "êµ¬ì¡°ê°€ ë¶ˆë¶„ëª…í•˜ê±°ë‚˜ ë¬¸ë‹¨ ê°„ íë¦„ì´ ë¶€ìì—°ìŠ¤ëŸ¬ì›€", 
        "1ì  (ë¶€ì¡±)": "ì „ì²´ êµ¬ì„±ì´ ì²´ê³„ì ì´ì§€ ì•Šê³  ì¼ê´€ì„±ì´ ë¶€ì¡±í•¨"
    },
    "ë¬¸ë²•ì–´íœ˜ì •í™•ì„±": {
        "4ì  (ìš°ìˆ˜)": "ë¬¸ë²•ì  ì˜¤ë¥˜ê°€ ê±°ì˜ ì—†ê³  ì–´íœ˜ ì‚¬ìš©ì´ ì ì ˆí•˜ë©° ë¬¸ì¥ êµ¬ì¡°ê°€ ë‹¤ì–‘í•¨",
        "3ì  (ë³´í†µ)": "ë¬¸ë²•ì  ì˜¤ë¥˜ê°€ ì•½ê°„ ìˆìœ¼ë‚˜ ì˜ë¯¸ ì „ë‹¬ì— í° ë¬¸ì œì—†ìŒ. ì–´íœ˜ ì‚¬ìš©ì´ ëŒ€ì²´ë¡œ ì ì ˆí•¨",
        "2ì  (ë¯¸í¡)": "ë¬¸ë²•ì  ì˜¤ë¥˜ê°€ ìì£¼ ë°œìƒí•˜ê³  ì–´íœ˜ ì„ íƒì´ ë¶€ì ì ˆí•œ ê²½ìš°ê°€ ìˆìŒ",
        "1ì  (ë¶€ì¡±)": "ë¬¸ë²•ì  ì˜¤ë¥˜ê°€ ë§ê³  ì–´íœ˜ ì‚¬ìš©ì´ ë¶€ì •í™•í•˜ì—¬ ì˜ë¯¸ ì „ë‹¬ì— ì–´ë ¤ì›€ì´ ìˆìŒ"
    }
}

# í™˜ê²½ ì„¤ì •
try:
    OPENAI_KEY = st.secrets["openai"]["api_key"]
except KeyError:
    OPENAI_KEY = ""

OPENAI_OK = bool(OPENAI_KEY)

client = None
if OPENAI_OK:
    try:
        client = OpenAI(api_key=OPENAI_KEY)
    except Exception as e:
        st.error(f"OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        OPENAI_OK = False

# ëˆ„ë½ëœ í•¨ìˆ˜ ì¶”ê°€ - ë¬¸ì œ 1 í•´ê²°
def display_rubric():
    """ë£¨ë¸Œë¦­ ê¸°ì¤€ í‘œì‹œ"""
    st.markdown("### í‰ê°€ ê¸°ì¤€ (ë£¨ë¸Œë¦­)")
    st.markdown("ê¸€ì„ ì“°ê¸° ì „ì— í‰ê°€ ê¸°ì¤€ì„ í™•ì¸í•´ë³´ì„¸ìš”!")
    
    for category, criteria in RUBRIC_CRITERIA.items():
        with st.expander(f"{category} í‰ê°€ ê¸°ì¤€", expanded=False):
            for score, description in criteria.items():
                st.markdown(f"**{score}**: {description}")

# ìƒˆë¡œìš´ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì¶”ê°€
def parse_gpt_json_response(response_text: str) -> dict:
    """GPT ì‘ë‹µì—ì„œ JSON ë¸”ë¡ì„ ì¶”ì¶œí•˜ê³  íŒŒì‹±"""
    try:
        # ```json ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ
        if "```json" in response_text:
            json_match = re.search(r'```json\s*\n(.*?)\n```', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1).strip()
            else:
                json_str = response_text.replace('```json\n', '').replace('\n```', '').strip()
        else:
            json_str = response_text.strip()
        
        # JSON íŒŒì‹± ì‹œë„ (ë” ìœ ì—°í•˜ê²Œ)
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ì˜¤ë¥˜ ì •ë³´ ë°˜í™˜
        return {
            "error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}",
            "raw_response": response_text
        }
    except Exception as e:
        return {
            "error": f"ì‘ë‹µ ì²˜ë¦¬ ì‹¤íŒ¨: {e}",
            "raw_response": response_text
        }

def format_analysis_for_display(analysis_data: Union[dict, str], analysis_type: str = "analysis") -> dict:
    """ë¶„ì„ ë°ì´í„°ë¥¼ í‘œì‹œìš©ìœ¼ë¡œ í¬ë§·íŒ…"""
    if not analysis_data:
        return {"error": "ë°ì´í„° ì—†ìŒ"}
    
    if isinstance(analysis_data, dict) and "error" not in analysis_data:
        return analysis_data
    
    if isinstance(analysis_data, dict) and analysis_type in analysis_data:
        return parse_gpt_json_response(analysis_data[analysis_type])
    
    return analysis_data

def format_docx_section(doc, title: str, data: dict):
    """DOCX ë¬¸ì„œì— íŠ¹ì • ë¶„ì„ ì„¹ì…˜ì„ í¬ë§·íŒ…í•˜ì—¬ ì¶”ê°€"""
    doc.add_heading(title, level=2)
    
    if "error" in data:
        doc.add_paragraph(f"ì˜¤ë¥˜: {data['error']}")
        return
        
    for key, value in data.items():
        if isinstance(value, dict):
            doc.add_paragraph(f"â€¢ {key}: {value.get('ì ìˆ˜', 'N/A')}/4ì ")
            if 'ê·¼ê±°' in value:
                doc.add_paragraph(f"    - ê·¼ê±°: {value['ê·¼ê±°']}")
            if 'ê°œì„ ì œì•ˆ' in value:
                doc.add_paragraph(f"    - ê°œì„  ì œì•ˆ: {value['ê°œì„ ì œì•ˆ']}")
        elif isinstance(value, list):
            doc.add_paragraph(f"â€¢ {key}: {', '.join(value)}")
        else:
            doc.add_paragraph(f"â€¢ {key}: {value}")
    doc.add_paragraph("")

def get_paragraph_feedback(text: str, paragraph_type: str, context: dict = None) -> dict:
    """ë¬¸ë‹¨ë³„ ì¦‰ì‹œ í”¼ë“œë°± ì œê³µ"""
    if not OPENAI_OK or client is None:
        return {"error": "API ì˜¤ë¥˜"}
    
    if not text.strip():
        return {"error": "ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤"}
    
    context_info = ""
    if context:
        if context.get("summary1") and context.get("summary2"):
            context_info = f"""
            ì°¸ê³ ìš© ê¸°ì‚¬ ìš”ì•½:
            ê¸°ì‚¬1: {context['summary1'][:200]}...
            ê¸°ì‚¬2: {context['summary2'][:200]}...
            """
    
    prompt = f"""
    ë‹¤ìŒ {paragraph_type} ë¬¸ë‹¨ì„ ë¶„ì„í•˜ê³  ì¦‰ì‹œ ê°œì„ í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”.

    {context_info}

    ë¬¸ë‹¨ ë‚´ìš©: {text}

    ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•˜ì„¸ìš”:
    {{
        "ê°•ì ": ["êµ¬ì²´ì  ê°•ì 1", "êµ¬ì²´ì  ê°•ì 2"],
        "ê°œì„ ì ": ["ê°œì„ ì‚¬í•­1", "ê°œì„ ì‚¬í•­2"],
        "êµ¬ì²´ì ì œì•ˆ": "ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ìˆ˜ì • ì œì•ˆ",
        "ì¶”ì²œì ìˆ˜": 1~4 ì‚¬ì´ì˜ ì •ìˆ˜ê°’
    }}
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=500
        )
        
        result = response.choices[0].message.content.strip()
        return parse_gpt_json_response(result)
    except APIError as e:
        return {"error": f"í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨: OpenAI API ì˜¤ë¥˜ - {e}"}
    except Exception as e:
        return {"error": f"í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨: {e}"}

def summarize_paragraph_feedback(paragraph_feedback: dict) -> str:
    """ë¬¸ë‹¨ë³„ í”¼ë“œë°±ì„ ìš”ì•½"""
    if not paragraph_feedback:
        return "ë¬¸ë‹¨ë³„ í”¼ë“œë°± ì—†ìŒ"
    
    summary = "ë¬¸ë‹¨ë³„ í•™ìŠµ ê³¼ì • ìš”ì•½:\n"
    for section, feedback in paragraph_feedback.items():
        if isinstance(feedback, dict):
            if "error" not in feedback:
                summary += f"- {section}: ì¶”ì²œì ìˆ˜ {feedback.get('ì¶”ì²œì ìˆ˜', 'N/A')}ì \n"
                summary += f"  ì£¼ìš” ê°œì„ ì œì•ˆ: {feedback.get('êµ¬ì²´ì ì œì•ˆ', 'N/A')}\n"
            else:
                summary += f"- {section}: í”¼ë“œë°± ì—†ìŒ\n"
    return summary

def summarize_text(text: str) -> str:
    """ê¸°ì‚¬ ë‚´ìš©ì„ ì˜ì–´ë¡œ 5-10ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½"""
    if not OPENAI_OK or client is None:
        return "ìš”ì•½ ë¶ˆê°€: API ì˜¤ë¥˜"
    if not text.strip():
        return "ìš”ì•½ ë¶ˆê°€: ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    prompt = f"ë‹¤ìŒ ê¸°ì‚¬ ë‚´ìš©ì„ ì˜ì–´ë¡œ ë‹¤ì„¯ ë¬¸ì¥ ì´ìƒ, ì—´ë¬¸ì¥ ì´í•˜ë¡œ ìš”ì•½í•´ì¤˜:\n\n{text}"
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=800
        )
        return response.choices[0].message.content.strip()
    except APIError as e:
        return f"ìš”ì•½ ì‹¤íŒ¨: OpenAI API ì˜¤ë¥˜ - {e}"
    except Exception as e:
        return f"ìš”ì•½ ì‹¤íŒ¨: {e}"

def analyze_tone_and_stance(text: str) -> dict:
    """ë…¼ì¡° ë° ì…ì¥ ë¶„ì„ - ì ìˆ˜í™”ëœ ë…¼ì¡° í¬í•¨"""
    if not OPENAI_OK or client is None:
        return {"error": "API ì˜¤ë¥˜"}
    
    prompt = f"""
    ë‹¤ìŒ ê¸°ì‚¬ì˜ ë…¼ì¡°ì™€ ì…ì¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
    
    ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•˜ê³ , ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”:
    
    {{
        "ë…¼ì¡°ë¶„ë¥˜": "positive/neutral/negative",
        "ë…¼ì¡°ì ìˆ˜": -3~3 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
        "ì£¼ìš”ë…¼ì ": ["ë…¼ì 1", "ë…¼ì 2", "ë…¼ì 3"],
        "ê°ì •ì ì–¸ì–´": ["ì˜ˆì‹œ1", "ì˜ˆì‹œ2", "ì˜ˆì‹œ3"],
        "ì‹ ë¢°ë„ì ìˆ˜": 1~10 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
        "ê°ê´€ì„±ì ìˆ˜": 1~10 ì‚¬ì´ì˜ ì •ìˆ˜ê°’
    }}
    
    ê¸°ì‚¬: {text}
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=600
        )
        
        result = response.choices[0].message.content.strip()
        return parse_gpt_json_response(result)
    except APIError as e:
        return {"error": f"ë¶„ì„ ì‹¤íŒ¨: OpenAI API ì˜¤ë¥˜ - {e}"}
    except Exception as e:
        return {"error": f"ë¶„ì„ ì‹¤íŒ¨: {e}"}

def evaluate_writing_rubric(text: str) -> dict:
    """ì˜ì–´ í‘œí˜„ ëŠ¥ë ¥ ë£¨ë¸Œë¦­ í‰ê°€"""
    if not OPENAI_OK or client is None:
        return {"error": "API ì˜¤ë¥˜"}
    
    prompt = f"""
    ë‹¤ìŒ ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì²´ì ì¸ ë£¨ë¸Œë¦­ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.

    **í‰ê°€ ì˜ì—­ ë° ê¸°ì¤€:**

    **1. ë‚´ìš© ë…¼ë¦¬ì„± (Content Logic) - 1~4ì **
    **2. êµ¬ì„± ì²´ê³„ì„± (Organization) - 1~4ì **
    **3. ë¬¸ë²•Â·ì–´íœ˜ ì •í™•ì„± (Language Accuracy) - 1~4ì **

    ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•˜ê³ , ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”:

    {{
        "ë‚´ìš©ë…¼ë¦¬ì„±": {{
            "ì ìˆ˜": 1~4 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê·¼ê±°": "êµ¬ì²´ì  í‰ê°€ ê·¼ê±°"
        }},
        "êµ¬ì„±ì²´ê³„ì„±": {{
            "ì ìˆ˜": 1~4 ì‚¬ì´ì˜ ì •ìˆ˜ê°’, 
            "ê·¼ê±°": "êµ¬ì²´ì  í‰ê°€ ê·¼ê±°"
        }},
        "ë¬¸ë²•ì–´íœ˜ì •í™•ì„±": {{
            "ì ìˆ˜": 1~4 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê·¼ê±°": "êµ¬ì²´ì  í‰ê°€ ê·¼ê±°"
        }},
        "ì´ì ": "12ì  ë§Œì  ì¤‘ Xì ",
        "ì¢…í•©í‰ê°€": "ì „ì²´ì ì¸ í‰ê°€ ë° ê°œì„  ì œì•ˆ"
    }}

    í‰ê°€ ëŒ€ìƒ í…ìŠ¤íŠ¸: {text}
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=800
        )
        
        result = response.choices[0].message.content.strip()
        return parse_gpt_json_response(result)
    except APIError as e:
        return {"error": f"í‰ê°€ ì‹¤íŒ¨: OpenAI API ì˜¤ë¥˜ - {e}"}
    except Exception as e:
        return {"error": f"í‰ê°€ ì‹¤íŒ¨: {e}"}

def assess_problem_solving(reflection_text: str) -> dict:
    """ë¬¸ì œí•´ê²° ì—­ëŸ‰ í‰ê°€"""
    if not OPENAI_OK or client is None:
        return {"error": "API ì˜¤ë¥˜"}
    
    if not reflection_text or len(reflection_text.strip()) < 10:
        return {
            "assessment": "ì„±ì°° ë‚´ìš©ì´ ë„ˆë¬´ ì§§ì•„ í‰ê°€í•˜ê¸°ì— ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë¬¸ì œ í•´ê²° ê³¼ì •ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì„¤ëª…ì„ í¬í•¨í•´ ì£¼ì„¸ìš”."
        }
    
    prompt = f"""
    ë‹¤ìŒ í•™ìŠµìì˜ ì„±ì°° ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì œí•´ê²° ì—­ëŸ‰ì„ í‰ê°€í•´ì£¼ì„¸ìš”:
    
    ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•˜ê³ , ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”:
    
    {{
        "ë¬¸ì œì´í•´": {{
            "ì ìˆ˜": 1~5 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê°œì„ ì œì•ˆ": "êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ"
        }},
        "ë¶„ì„ì ì‚¬ê³ ": {{
            "ì ìˆ˜": 1~5 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê°œì„ ì œì•ˆ": "êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ"
        }},
        "ëŒ€ì•ˆë°œê²¬ë°ê¸°íš": {{
            "ì ìˆ˜": 1~5 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê°œì„ ì œì•ˆ": "êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ"
        }},
        "ì˜ì‚¬ì†Œí†µ": {{
            "ì ìˆ˜": 1~5 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê°œì„ ì œì•ˆ": "êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ"
        }},
        "ì´ì ": "20ì  ë§Œì  ì¤‘ Xì ",
        "ì¢…í•©í‰ê°€": "ì „ì²´ì ì¸ í‰ê°€ ìš”ì•½"
    }}
    
    ì„±ì°° ë‚´ìš©: {reflection_text}
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=800
        )
        
        result = response.choices[0].message.content.strip()
        return parse_gpt_json_response(result)
    except APIError as e:
        return {"error": f"í‰ê°€ ì‹¤íŒ¨: OpenAI API ì˜¤ë¥˜ - {e}"}
    except Exception as e:
        return {"error": f"í‰ê°€ ì‹¤íŒ¨: {e}"}

def display_emotional_words(analysis1: dict, analysis2: dict) -> None:
    """ê°ì •ì  ì–¸ì–´ ì‹œê°í™”"""
    st.markdown("#### ê°ì •ì  í‘œí˜„ ë¹„êµ")
    
    analysis1 = format_analysis_for_display(analysis1, "analysis")
    analysis2 = format_analysis_for_display(analysis2, "analysis")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**ê¸°ì‚¬ 1**")
        if "ê°ì •ì ì–¸ì–´" in analysis1 and analysis1["ê°ì •ì ì–¸ì–´"]:
            words = analysis1["ê°ì •ì ì–¸ì–´"]
            word_html = ""
            for i, word in enumerate(words):
                size = 20 - i*2
                color = ["#ff6b6b", "#4ecdc4", "#45b7d1", "#96ceb4", "#feca57"][i % 5]
                word_html += f'<span style="font-size:{size}px; color:{color}; margin:5px; font-weight:bold;">{word}</span> '
            
            st.markdown(f'<div style="line-height:2;">{word_html}</div>', unsafe_allow_html=True)
        else:
            st.info("ê°ì •ì  í‘œí˜„ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    with col2:
        st.markdown("**ê¸°ì‚¬ 2**")
        if "ê°ì •ì ì–¸ì–´" in analysis2 and analysis2["ê°ì •ì ì–¸ì–´"]:
            words = analysis2["ê°ì •ì ì–¸ì–´"]
            word_html = ""
            for i, word in enumerate(words):
                size = 20 - i*2
                color = ["#ff6b6b", "#4ecdc4", "#45b7d1", "#96ceb4", "#feca57"][i % 5]
                word_html += f'<span style="font-size:{size}px; color:{color}; margin:5px; font-weight:bold;">{word}</span> '
            
            st.markdown(f'<div style="line-height:2;">{word_html}</div>', unsafe_allow_html=True)
        else:
            st.info("ê°ì •ì  í‘œí˜„ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def create_simple_gauge(value: int, title: str) -> None:
    """ê°„ë‹¨í•œ ê²Œì´ì§€ ì‹œê°í™”"""
    percentage = ((value + 3) / 6) * 100
    
    if value <= -2:
        color = "#ff4757"
        emoji = "ğŸ˜"
    elif value <= -1:
        color = "#ffa502"
        emoji = "ğŸ˜•"
    elif value == 0:
        color = "#747d8c"
        emoji = "ğŸ˜"
    elif value <= 1:
        color = "#2ed573"
        emoji = "ğŸ™‚"
    else:
        color = "#5352ed"
        emoji = "ğŸ˜Š"
    
    gauge_html = f"""
    <div style="text-align: center; margin: 20px; padding: 20px; border-radius: 10px; background-color: #f8f9fa;">
        <h4 style="margin-bottom: 15px;">{title}</h4>
        <div style="font-size: 30px; margin-bottom: 10px;">{emoji}</div>
        <div style="width: 200px; height: 20px; background-color: #e1e8ed; border-radius: 10px; margin: 0 auto; position: relative;">
            <div style="width: {percentage}%; height: 100%; background-color: {color}; border-radius: 10px;"></div>
        </div>
        <p style="margin-top: 10px; font-weight: bold; color: {color}; font-size: 18px;">{value}ì </p>
    </div>
    """
    st.markdown(gauge_html, unsafe_allow_html=True)

def create_enhanced_comparison_chart(analysis1: dict, analysis2: dict) -> None:
    """ê°œì„ ëœ ë…¼ì¡° ë¹„êµ ì°¨íŠ¸"""
    analysis1 = format_analysis_for_display(analysis1, "analysis")
    analysis2 = format_analysis_for_display(analysis2, "analysis")
    
    if "error" in analysis1 or "error" in analysis2:
        st.error("ë…¼ì¡° ë¶„ì„ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    st.markdown("#### ë…¼ì¡° ì ìˆ˜ ë¹„êµ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        create_simple_gauge(analysis1.get('ë…¼ì¡°ì ìˆ˜', 0), "ê¸°ì‚¬ 1 ë…¼ì¡°")
    with col2:
        create_simple_gauge(analysis2.get('ë…¼ì¡°ì ìˆ˜', 0), "ê¸°ì‚¬ 2 ë…¼ì¡°")
    
    st.markdown("#### ì‹ ë¢°ë„ ë° ê°ê´€ì„±")
    
    trust1 = analysis1.get('ì‹ ë¢°ë„ì ìˆ˜', 5)
    trust2 = analysis2.get('ì‹ ë¢°ë„ì ìˆ˜', 5)
    obj1 = analysis1.get('ê°ê´€ì„±ì ìˆ˜', 5)
    obj2 = analysis2.get('ê°ê´€ì„±ì ìˆ˜', 5)
    
    metrics_df = pd.DataFrame({
        'ì§€í‘œ': ['ì‹ ë¢°ë„', 'ê°ê´€ì„±'],
        'ê¸°ì‚¬1': [trust1, obj1],
        'ê¸°ì‚¬2': [trust2, obj2]
    })
    st.bar_chart(metrics_df.set_index('ì§€í‘œ'))

def gpt_feedback(korean_text: str, reflection_text: str = "") -> str:
    """í•œêµ­ì–´ ì‘ë¬¸ì— ëŒ€í•œ í•œêµ­ì–´ í”¼ë“œë°± ì œê³µ (ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€)"""
    if not OPENAI_OK or client is None:
        return "GPT ì‚¬ìš©ì„ ìœ„í•œ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤."
    if not korean_text.strip():
        return "í”¼ë“œë°±í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
        
    reflection_info = ""
    if reflection_text:
        reflection_info = f"""
        í•™ìŠµìê°€ ë‚¨ê¸´ ì„±ì°° ë‚´ìš©:
        {reflection_text}
        
        **ì´ ì„±ì°° ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬, í•™ìŠµìê°€ ì–´ë ¤ì›€ì„ ëŠê¼ˆê±°ë‚˜ ê°œì„ í•˜ê³  ì‹¶ë‹¤ê³  ì–¸ê¸‰í•œ ë¶€ë¶„ì„ ì¤‘ì‹¬ìœ¼ë¡œ í”¼ë“œë°±ì„ ê°•í™”í•´ì£¼ì„¸ìš”.**
        """

    prompt = f"""
    ë‹¹ì‹ ì€ í•œêµ­ì¸ í•™ìŠµìë¥¼ ìœ„í•œ ê¸€ì“°ê¸° ì§€ë„êµì‚¬ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¹„êµ ì„¤ëª…ë¬¸ì„ í‰ê°€í•˜ê³  ê±´ì„¤ì ì¸ í”¼ë“œë°±ì„ í•œêµ­ì–´ë¡œ ì œê³µí•˜ì„¸ìš”.

    ë‹¤ìŒ ë£¨ë¸Œë¦­ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”:

    **1. ë‚´ìš© ë…¼ë¦¬ì„± (Content Logic)** - ì£¼ì¥ì˜ ëª…í™•ì„±, ê·¼ê±° ì œì‹œ ì¶©ë¶„ì„±, ë…¼ë¦¬ì  ì—°ê²°, ë¬¸ì œ ìƒí™© ë¶„ì„ ê¹Šì´

    **2. êµ¬ì„± ì²´ê³„ì„± (Organization)**
    - ì„œë¡ -ë³¸ë¡ -ê²°ë¡  êµ¬ì¡°, ë¬¸ë‹¨ ê°„ ì—°ê²°ê³¼ íë¦„, ì‘ì§‘ì„±ê³¼ ì¼ê´€ì„±

    **3. ë¬¸ë²•Â·ì–´íœ˜ ì •í™•ì„± (Language Accuracy)**
    - ë¬¸ë²•ì  ì •í™•ì„±, ë¬¸ì¥ êµ¬ì¡°ì˜ ë‹¤ì–‘ì„±, ì–´íœ˜ ì„ íƒì˜ ì ì ˆì„±

    ê° ì˜ì—­ë³„ë¡œ êµ¬ì²´ì ì¸ í”¼ë“œë°±ê³¼ 3-5ê°œì˜ ê°œì„  ì œì•ˆì„ ì œê³µí•´ì£¼ì„¸ìš”.

    {reflection_info}

    í‰ê°€ ëŒ€ìƒ ê¸€:
    {korean_text}
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸€ì“°ê¸° ì§€ë„êµì‚¬ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=1200
        )
        return response.choices[0].message.content.strip()
    except APIError as e:
        return f"OpenAI API ì˜¤ë¥˜: {e}"
    except Exception as e:
        return f"GPT í˜¸ì¶œ ì˜¤ë¥˜: {e}"

def translate_to_korean(text: str) -> str:
    """ì˜ë¬¸ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­"""
    if not OPENAI_OK or client is None:
        return "ë²ˆì—­ ë¶ˆê°€: API ì˜¤ë¥˜"
    if "ìš”ì•½ ì‹¤íŒ¨" in text or "ìš”ì•½ ë¶ˆê°€" in text:
        return "ì›ë³¸ ìš”ì•½ì´ ì—†ì–´ ë²ˆì—­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    if not text.strip():
        return "ë²ˆì—­ ë¶ˆê°€: ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."

    prompt = f"ë‹¤ìŒ ì˜ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì¤˜:\n\n{text}"
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=1000
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"ë²ˆì—­ ì‹¤íŒ¨: {e}"

def translate_to_english(text: str) -> str:
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­"""
    if not OPENAI_OK or client is None:
        return "ë²ˆì—­ ë¶ˆê°€: API ì˜¤ë¥˜"
    if not text.strip():
        return "ë²ˆì—­ ë¶ˆê°€: ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."

    prompt = f"ë‹¤ìŒ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ì˜ì–´ë¡œ ë²ˆì—­í•´ì¤˜:\n\n{text}"
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=1200
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"ë²ˆì—­ ì‹¤íŒ¨: {e}"

def create_docx_content(text: str, analysis_data: Dict[str, Any]) -> bytes:
    """í…ìŠ¤íŠ¸ì™€ ë¶„ì„ ë°ì´í„°ë¥¼ DOCX íŒŒì¼ë¡œ ë³€í™˜í•˜ì—¬ ë°”ì´íŠ¸ ë°ì´í„° ë°˜í™˜"""
    doc = Document()
    doc.add_heading('News Comparison Analysis', 0)
    doc.add_paragraph(f"ì‘ì„±ì¼: {datetime.datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}")
    doc.add_paragraph("")
    
    if analysis_data:
        doc.add_heading('ë¶„ì„ ìš”ì•½', level=1)
        
        for key, value in analysis_data.items():
            if isinstance(value, dict) and "error" not in value:
                format_docx_section(doc, key, value)
            elif isinstance(value, str):
                doc.add_heading(key, level=2)
                doc.add_paragraph(value)
                doc.add_paragraph("")
            else:
                doc.add_heading(key, level=2)
                doc.add_paragraph("ë°ì´í„° ì—†ìŒ ë˜ëŠ” ì˜¤ë¥˜.")
                doc.add_paragraph("")

    doc.add_heading('ì‘ì„±ëœ ì„¤ëª…ë¬¸', level=1)
    for line in text.splitlines():
        if line.strip():
            doc.add_paragraph(line)
    
    with tempfile.NamedTemporaryFile() as tmp:
        doc.save(tmp.name)
        tmp.seek(0)
        return tmp.read()

def read_uploaded_file(uploaded_file) -> str:
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ ì½ì–´ì„œ í…ìŠ¤íŠ¸ ë°˜í™˜"""
    try:
        try:
            content = uploaded_file.read().decode('utf-8')
        except UnicodeDecodeError:
            uploaded_file.seek(0)
            content = uploaded_file.read().decode('euc-kr')
        return content
    except Exception as e:
        return f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}"

# Streamlit ì•± ì„¤ì •
st.set_page_config(
    page_title="News Comparison Assistant", 
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ë¬¸ì œ 2 í•´ê²°: ëˆ„ë½ëœ ì„¸ì…˜ ìƒíƒœ í‚¤ë“¤ ì¶”ê°€
if "stage" not in st.session_state:
    st.session_state.update({
        "stage": "input",
        "article1": "", "article2": "",
        "uploaded_file1_content": "", "uploaded_file2_content": "",
        "summary1": "", "summary2": "",
        "summary1_kr": "", "summary2_kr": "",
        "tone_analysis1": {}, "tone_analysis2": {},
        "draft": "", "feedback": "",
        "writing_evaluation": {},
        "problem_solving_score": {},
        "reflection_log": [],
        "final_text": "",
        "paragraph_feedback": {},
        # ëˆ„ë½ëœ í‚¤ë“¤ ì¶”ê°€
        "intro_input": "",
        "body1_input": "",
        "body2_input": "",
        "compare_input": "",
        "conclusion_input": ""
    })

st.title("News Comparison and Writing Assistant")

if not OPENAI_OK:
    st.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ìš”ì•½ ë° í”¼ë“œë°± ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")

progress_stages = ["input", "analysis", "draft", "feedback", "final"]
current_stage_idx = progress_stages.index(st.session_state.stage)
progress = (current_stage_idx + 1) / len(progress_stages)

st.progress(progress)
stage_names = ["ê¸°ì‚¬ ì…ë ¥", "ë…¼ì¡° ë¶„ì„", "ì´ˆì•ˆ ì‘ì„±", "AI í”¼ë“œë°±", "ìµœì¢… ì™„ì„±"]
st.caption(f"í˜„ì¬ ë‹¨ê³„: {stage_names[current_stage_idx]} ({current_stage_idx + 1}/{len(progress_stages)})")

if st.session_state.stage in ["draft", "feedback"]:
    display_rubric()
    st.markdown("---")

if st.session_state.stage == "input":
    st.subheader("1ë‹¨ê³„. ê¸°ì‚¬ ë³¸ë¬¸ ì…ë ¥ (íŒŒì¼ ì—…ë¡œë“œ)")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**ê¸°ì‚¬ 1**")
        uploaded_file1 = st.file_uploader(
            "ì²« ë²ˆì§¸ ê¸°ì‚¬ íŒŒì¼ ì—…ë¡œë“œ (.txt)", 
            type=['txt'], 
            key="file1",
            help="UTF-8 ë˜ëŠ” EUC-KR ì¸ì½”ë”©ëœ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë“œë˜ê·¸í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš” (ìµœëŒ€ 10MB)"
        )
        
        if uploaded_file1:
            st.session_state.uploaded_file1_content = read_uploaded_file(uploaded_file1)
            st.session_state.article1 = st.session_state.uploaded_file1_content
            if st.session_state.uploaded_file1_content.startswith("íŒŒì¼ ì½ê¸° ì˜¤ë¥˜"):
                st.error(st.session_state.uploaded_file1_content)
    
    with col2:
        st.markdown("**ê¸°ì‚¬ 2**")
        uploaded_file2 = st.file_uploader(
            "ë‘ ë²ˆì§¸ ê¸°ì‚¬ íŒŒì¼ ì—…ë¡œë“œ (.txt)", 
            type=['txt'], 
            key="file2",
            help="UTF-8 ë˜ëŠ” EUC-KR ì¸ì½”ë”©ëœ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë“œë˜ê·¸í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš” (ìµœëŒ€ 10MB)"
        )
        
        if uploaded_file2:
            st.session_state.uploaded_file2_content = read_uploaded_file(uploaded_file2)
            st.session_state.article2 = st.session_state.uploaded_file2_content
            if st.session_state.uploaded_file2_content.startswith("íŒŒì¼ ì½ê¸° ì˜¤ë¥˜"):
                st.error(st.session_state.uploaded_file2_content)
    
    st.markdown("---")
    
    col_btn1, col_btn2 = st.columns([1, 1])
    with col_btn2:
        overall_error_placeholder = st.empty()
        if st.button("ë‹¤ìŒ ë‹¨ê³„ â†’ (ë¶„ì„ ì‹œì‘)", type="primary", use_container_width=True):
            is_valid = True
            if not st.session_state.article1.strip():
                st.error("ê¸°ì‚¬ 1 íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                is_valid = False

            if not st.session_state.article2.strip():
                st.error("ê¸°ì‚¬ 2 íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                is_valid = False

            if is_valid:
                st.session_state.stage = "analysis"
                st.rerun()
            else:
                st.warning("ëª¨ë“  í•„ìˆ˜ ì…ë ¥ í•„ë“œë¥¼ ì±„ì›Œì£¼ì„¸ìš”.")

elif st.session_state.stage == "analysis":
    st.subheader("2ë‹¨ê³„. ë…¼ì¡° ë¶„ì„ ë° ìš”ì•½")
    
    if not st.session_state.get("summary1") or not st.session_state.get("tone_analysis1"):
        with st.spinner("ê¸°ì‚¬ ë¶„ì„ ë° ìš”ì•½ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            st.info("ê¸°ì‚¬ 1 ìš”ì•½ ì¤‘...", icon="ğŸ“")
            st.session_state.summary1 = summarize_text(st.session_state.article1)
            st.info("ê¸°ì‚¬ 2 ìš”ì•½ ì¤‘...", icon="ğŸ“")
            st.session_state.summary2 = summarize_text(st.session_state.article2)
            
            st.info("ê¸°ì‚¬ 1 ë…¼ì¡° ë¶„ì„ ì¤‘...", icon="ğŸ”")
            st.session_state.tone_analysis1 = analyze_tone_and_stance(st.session_state.article1)
            st.info("ê¸°ì‚¬ 2 ë…¼ì¡° ë¶„ì„ ì¤‘...", icon="ğŸ”")
            st.session_state.tone_analysis2 = analyze_tone_and_stance(st.session_state.article2)
            
            st.info("ìš”ì•½ë¬¸ ë²ˆì—­ ì¤‘...", icon="ğŸŒ")
            st.session_state.summary1_kr = translate_to_korean(st.session_state.summary1)
            st.session_state.summary2_kr = translate_to_korean(st.session_state.summary2)
        st.success("ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ê¸°ì‚¬ 1 ë¶„ì„")
        with st.expander("ìš”ì•½ (ì˜ì–´/í•œêµ­ì–´)", expanded=True):
            st.info(f"**[English]**\n{st.session_state.summary1}")
            st.success(f"**[í•œêµ­ì–´]**\n{st.session_state.summary1_kr}")
        
        with st.expander("ë…¼ì¡° ë¶„ì„", expanded=True):
            analysis1 = format_analysis_for_display(st.session_state.tone_analysis1, "analysis")
            if "error" not in analysis1:
                st.markdown(f"**ë…¼ì¡°**: {analysis1.get('ë…¼ì¡°ë¶„ë¥˜', 'N/A')} ({analysis1.get('ë…¼ì¡°ì ìˆ˜', 0)}ì )")
                st.markdown(f"**ì‹ ë¢°ë„**: {analysis1.get('ì‹ ë¢°ë„ì ìˆ˜', 0)}/10ì ")
                st.markdown(f"**ê°ê´€ì„±**: {analysis1.get('ê°ê´€ì„±ì ìˆ˜', 0)}/10ì ")
                
                if analysis1.get('ì£¼ìš”ë…¼ì '):
                    st.markdown("**ì£¼ìš” ë…¼ì **:")
                    for i, point in enumerate(analysis1.get('ì£¼ìš”ë…¼ì ', []), 1):
                        st.markdown(f"  {i}. {point}")
            else:
                st.error(analysis1.get("error", "ë¶„ì„ ì˜¤ë¥˜"))
    
    with col2:
        st.markdown("#### ê¸°ì‚¬ 2 ë¶„ì„")
        with st.expander("ìš”ì•½ (ì˜ì–´/í•œêµ­ì–´)", expanded=True):
            st.info(f"**[English]**\n{st.session_state.summary2}")
            st.success(f"**[í•œêµ­ì–´]**\n{st.session_state.summary2_kr}")
        
        with st.expander("ë…¼ì¡° ë¶„ì„", expanded=True):
            analysis2 = format_analysis_for_display(st.session_state.tone_analysis2, "analysis")
            if "error" not in analysis2:
                st.markdown(f"**ë…¼ì¡°**: {analysis2.get('ë…¼ì¡°ë¶„ë¥˜', 'N/A')} ({analysis2.get('ë…¼ì¡°ì ìˆ˜', 0)}ì )")
                st.markdown(f"**ì‹ ë¢°ë„**: {analysis2.get('ì‹ ë¢°ë„ì ìˆ˜', 0)}/10ì ")
                st.markdown(f"**ê°ê´€ì„±**: {analysis2.get('ê°ê´€ì„±ì ìˆ˜', 0)}/10ì ")
                
                if analysis2.get('ì£¼ìš”ë…¼ì '):
                    st.markdown("**ì£¼ìš” ë…¼ì **:")
                    for i, point in enumerate(analysis2.get('ì£¼ìš”ë…¼ì ', []), 1):
                        st.markdown(f"  {i}. {point}")
            else:
                st.error(analysis2.get("error", "ë¶„ì„ ì˜¤ë¥˜"))
    
    st.markdown("---")
    create_enhanced_comparison_chart(st.session_state.tone_analysis1, st.session_state.tone_analysis2)
    
    st.markdown("---")
    display_emotional_words(st.session_state.tone_analysis1, st.session_state.tone_analysis2)
    
    st.markdown("---")
    st.markdown("#### ë¶„ì„ ì„±ì°°")
    reflection_error_placeholder = st.empty()
    reflection = st.text_area(
        "ë‘ ê¸°ì‚¬ì˜ ì°¨ì´ì ê³¼ ê³µí†µì , ê·¸ë¦¬ê³  ê°ê°ì˜ ë…¼ì¡°ì— ëŒ€í•œ ë‹¹ì‹ ì˜ ìƒê°ì„ ì ì–´ë³´ì„¸ìš”:",
        height=100,
        key="analysis_reflection"
    )
    
    col_btn1, col_btn2 = st.columns([1, 1])
    with col_btn1:
        if st.button("â† ì´ì „ ë‹¨ê³„", use_container_width=True):
            st.session_state.stage = "input"
            st.rerun()
    
    with col_btn2:
        if st.button("ì´ˆì•ˆ ì‘ì„± ë‹¨ê³„ë¡œ â†’", type="primary", use_container_width=True):
            if not reflection.strip():
                reflection_error_placeholder.error("ë¶„ì„ ì„±ì°° ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                reflection_error_placeholder.empty()
                st.session_state.reflection_log.append({
                    "stage": "analysis",
                    "content": reflection,
                    "timestamp": datetime.datetime.now()
                })
                st.session_state.stage = "draft"
                st.rerun()

elif st.session_state.stage == "draft":
    st.subheader("3ë‹¨ê³„. ë¹„êµ ì„¤ëª…ë¬¸ ì´ˆì•ˆ ì‘ì„±")

    # ë¬¸ì œ 4 í•´ê²°: ê°œì„ ëœ ë¬¸ë‹¨ ì…ë ¥ í•¨ìˆ˜
    def paragraph_input_with_guide(title, key, guide_title, guide_lines, summary_text=None, hint_key=None, hint_prompt=None):
        col1, col2 = st.columns([2, 1])
        with col1:
            st.subheader(title)
            
            # í˜„ì¬ ê°’ ê°€ì ¸ì˜¤ê¸°
            current_value = st.session_state.get(key, "")
            
            # ê³ ìœ í•œ í‚¤ë¡œ text_area ìƒì„±
            user_input = st.text_area(
                "", 
                value=current_value, 
                key=f"input_{key}_{st.session_state.stage}", 
                height=160
            )
            
            # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state[key] = user_input
            
            col1_1, col1_2 = st.columns([1, 1])
            with col1_1:
                if st.button(f"{title.split(' ')[0]} ì™„ë£Œ", key=f"{key}_complete"):
                    if user_input.strip():
                        context = {
                            "summary1": st.session_state.get("summary1"),
                            "summary2": st.session_state.get("summary2")
                        }
                        feedback = get_paragraph_feedback(user_input, title, context)
                        st.session_state.paragraph_feedback[key] = feedback
                        st.success("í”¼ë“œë°±ì„ í™•ì¸í•˜ì„¸ìš”!")
                    else:
                        st.error("ë¬¸ë‹¨ì„ ë¨¼ì € ì‘ì„±í•´ì£¼ì„¸ìš”.")
            
            with col1_2:
                if key in st.session_state.paragraph_feedback:
                    feedback = st.session_state.paragraph_feedback[key]
                    if "error" not in feedback:
                        score = feedback.get('ì¶”ì²œì ìˆ˜', 'N/A')
                        st.metric("ì¶”ì²œì ìˆ˜", f"{score}/4ì ")
            
            if key in st.session_state.paragraph_feedback:
                feedback = st.session_state.paragraph_feedback[key]
                if "error" not in feedback:
                    with st.expander("ë¬¸ë‹¨ë³„ í”¼ë“œë°±", expanded=True):
                        if feedback.get('ê°•ì '):
                            st.markdown("**ê°•ì :**")
                            for strength in feedback['ê°•ì ']:
                                st.markdown(f"- {strength}")
                        
                        if feedback.get('ê°œì„ ì '):
                            st.markdown("**ê°œì„ ì :**")
                            for improvement in feedback['ê°œì„ ì ']:
                                st.markdown(f"- {improvement}")
                        
                        if feedback.get('êµ¬ì²´ì ì œì•ˆ'):
                            st.markdown("**êµ¬ì²´ì  ì œì•ˆ:**")
                            st.info(feedback['êµ¬ì²´ì ì œì•ˆ'])
                else:
                    st.error(feedback.get("error", "í”¼ë“œë°± ì˜¤ë¥˜"))
        
        with col2:
            st.markdown(f"#### {guide_title}")
            for line in guide_lines:
                st.markdown(f"- {line}")
            
            if summary_text:
                st.markdown("#### ê´€ë ¨ ê¸°ì‚¬ ìš”ì•½")
                summary_en = summary_text
                summary_kr_key = "summary1_kr" if summary_en == st.session_state.get("summary1") else "summary2_kr"
                summary_kr = st.session_state.get(summary_kr_key, "ë²ˆì—­ ì—†ìŒ")
                
                with st.expander("ìš”ì•½ë¬¸ ë³´ê¸°", expanded=True):
                    st.info(f"**[English]**\n{summary_en}")
                    st.success(f"**[í•œêµ­ì–´]**\n{summary_kr}")

            if hint_key and hint_prompt and OPENAI_OK:
                if f"{hint_key}_hint" not in st.session_state:
                    st.session_state[f"{hint_key}_hint"] = ""
                if st.button(f"AI íŒíŠ¸ ë°›ê¸°", key=f"{hint_key}_btn"):
                    with st.spinner("AI íŒíŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                        try:
                            hint_response = client.chat.completions.create(
                                model="gpt-4o",
                                messages=[{"role": "user", "content": hint_prompt}],
                                temperature=0.5,
                                max_tokens=300
                            )
                            st.session_state[f"{hint_key}_hint"] = hint_response.choices[0].message.content.strip()
                        except Exception as e:
                            st.session_state[f"{hint_key}_hint"] = f"íŒíŠ¸ ìƒì„± ì‹¤íŒ¨: {e}"
                if st.session_state[f"{hint_key}_hint"]:
                    st.markdown("#### AI íŒíŠ¸")
                    st.success(st.session_state[f"{hint_key}_hint"])
        
        return user_input

    intro = paragraph_input_with_guide(
        "ì„œë¡ ", "intro_input", "ë¹„êµ ì£¼ì œ ì†Œê°œ", [
            "ë¹„êµí•  ë‘ ê¸°ì‚¬ ê°„ë‹¨íˆ ì†Œê°œ",
            "ê¸€ì˜ ëª©ì , ë¬¸ì œ ì œê¸°",
            "ë‘ ê´€ì  ê°„ ì°¨ì´ì— ëŒ€í•œ ì•”ì‹œ"
        ],
        hint_key="intro", hint_prompt="ë¹„êµ ì„¤ëª…ë¬¸ì˜ ì„œë¡ ì„ ì“°ê¸° ìœ„í•œ ë¬¸ì¥ êµ¬ì„± íŒíŠ¸ë¥¼ 3ê°œ ì œì‹œí•´ì¤˜. (í•œêµ­ì–´)"
    )

    body1 = paragraph_input_with_guide(
        "ë³¸ë¡  - ê¸°ì‚¬ 1 ì„¤ëª…", "body1_input", "ê¸°ì‚¬ 1 ìš”ì•½", [
            "ê¸°ì‚¬ 1ì˜ ì£¼ì¥ê³¼ ê·¼ê±° ìš”ì•½",
            "ìë£Œ, ì‚¬ë¡€, ê°•ì¡°ì  ê¸°ìˆ "
        ],
        summary_text=st.session_state.get("summary1"),
        hint_key="body1", hint_prompt="ì²« ë²ˆì§¸ ê¸°ì‚¬ ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” ë¬¸ë‹¨ ì‘ì„±ì— ì“¸ ìˆ˜ ìˆëŠ” ë¬¸ì¥ ì˜ˆì‹œ 3ê°œë¥¼ ì œì‹œí•´ì¤˜. (í•œêµ­ì–´)"
    )

    body2 = paragraph_input_with_guide(
        "ë³¸ë¡  - ê¸°ì‚¬ 2 ì„¤ëª…", "body2_input", "ê¸°ì‚¬ 2 ìš”ì•½", [
            "ê¸°ì‚¬ 2ì˜ ì£¼ìš” ë‚´ìš© ìš”ì•½",
            "ê¸°ì‚¬ 1ê³¼ ë¹„êµí–ˆì„ ë•Œì˜ íŠ¹ì§• ì–¸ê¸‰"
        ],
        summary_text=st.session_state.get("summary2"),
        hint_key="body2", hint_prompt="ë‘ ë²ˆì§¸ ê¸°ì‚¬ ë‚´ìš©ì„ ìš”ì•½í•˜ë©° ë¹„êµí•˜ëŠ” ë¬¸ë‹¨ì„ ì“°ê¸° ìœ„í•œ ë¬¸ì¥ ì˜ˆì‹œ 3ê°œë¥¼ ì œì‹œí•´ì¤˜. (í•œêµ­ì–´)"
    )

    compare = paragraph_input_with_guide(
        "ë¹„êµ ë¶„ì„", "compare_input", "ê³µí†µì ê³¼ ì°¨ì´ì ", [
            "ê¸°ì¤€(ê´€ì , ëª©ì  ë“±)ì„ ì„¤ì •í•´ ë¹„êµ",
            "ë…¼ë¦¬ì ìœ¼ë¡œ ìœ ì‚¬ì Â·ì°¨ì´ì  ì œì‹œ"
        ],
        hint_key="compare", hint_prompt="ë‘ ê¸°ì‚¬ ê°„ ê³µí†µì ê³¼ ì°¨ì´ì ì„ ë¹„êµí•˜ì—¬ ë¶„ì„í•˜ëŠ” ë¬¸ë‹¨ì„ ìœ„í•œ ë¬¸ì¥ êµ¬ì„± íŒíŠ¸ë¥¼ ì œì‹œí•´ì¤˜. (í•œêµ­ì–´)"
    )

    conclusion = paragraph_input_with_guide(
        "ê²°ë¡ ", "conclusion_input", "ìš”ì•½ ë° ì˜ê²¬", [
            "ì „ì²´ ë¹„êµ ë‚´ìš© ìš”ì•½",
            "ìì‹ ì˜ ì˜ê²¬ì´ë‚˜ í‰ê°€ í¬í•¨"
        ],
        hint_key="conclusion", hint_prompt="ë¹„êµ ì„¤ëª…ë¬¸ ê²°ë¡ ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë§ˆë¬´ë¦¬ ë¬¸ì¥ 3ê°œë¥¼ ì œì•ˆí•´ì¤˜. (í•œêµ­ì–´)"
    )

    st.markdown("---")
    st.markdown("### ì „ì²´ ì´ˆì•ˆ ë¯¸ë¦¬ë³´ê¸°")

    full_draft = "\n\n".join([
        f"[ì„œë¡ ]\n{st.session_state.intro_input}",
        f"[ë³¸ë¡  1 - ê¸°ì‚¬ 1]\n{st.session_state.body1_input}",
        f"[ë³¸ë¡  2 - ê¸°ì‚¬ 2]\n{st.session_state.body2_input}",
        f"[ë¹„êµ ë¶„ì„]\n{st.session_state.compare_input}",
        f"[ê²°ë¡ ]\n{st.session_state.conclusion_input}"
    ])

    st.session_state.draft = full_draft

    st.markdown(f"""<div style="background-color:#f9f9f9; padding:15px; border-radius:10px; color:black; font-size:16px;">
<pre style="white-space: pre-wrap; word-wrap: break-word;">{full_draft}</pre>
</div>""", unsafe_allow_html=True)

    if st.session_state.paragraph_feedback:
        st.markdown("---")
        st.markdown("### ë¬¸ë‹¨ë³„ í”¼ë“œë°± ìš”ì•½")
        summary_text = summarize_paragraph_feedback(st.session_state.paragraph_feedback)
        st.info(summary_text)

    col_btn1, col_btn2 = st.columns([1, 1])
    with col_btn1:
        if st.button("â† ì´ì „ ë‹¨ê³„", use_container_width=True):
            st.session_state.stage = "analysis"
            st.rerun()

    with col_btn2:
        overall_draft_error = st.empty()
        if st.button("AI í”¼ë“œë°± ë°›ê¸° â†’", type="primary", use_container_width=True):
            paragraphs = [st.session_state.intro_input, st.session_state.body1_input,
                          st.session_state.body2_input, st.session_state.compare_input,
                          st.session_state.conclusion_input]
            
            is_valid = all(p.strip() for p in paragraphs)
            
            if is_valid:
                overall_draft_error.empty()
                st.session_state.stage = "feedback"
                st.rerun()
            else:
                overall_draft_error.error("ëª¨ë“  ë¬¸ë‹¨ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.")

elif st.session_state.stage == "feedback":
    st.subheader("4ë‹¨ê³„. AI í”¼ë“œë°±")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("**ë‚´ ì´ˆì•ˆ**")
        st.text_area(
            "ì‘ì„±í•œ ì´ˆì•ˆ",
            value=st.session_state.draft,
            height=400,
            disabled=True,
            key="draft_display_feedback"
        )
    
    with col2:
        st.markdown("**AI í”¼ë“œë°±**")
        
        # AI í”¼ë“œë°± ìƒì„± (í•œ ë²ˆë§Œ)
        if not st.session_state.get("feedback"):
            if OPENAI_OK:
                with st.spinner("AI í”¼ë“œë°±ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    st.info("ì¢…í•© í”¼ë“œë°± ìƒì„± ì¤‘...", icon="ğŸ§ ")
                    feedback = gpt_feedback(st.session_state.draft)
                    st.session_state.feedback = feedback
                    
                    st.info("ì˜ì–´ í‘œí˜„ ëŠ¥ë ¥ í‰ê°€ ì¤‘...", icon="ğŸ“")
                    english_draft = translate_to_english(st.session_state.draft)
                    st.session_state.writing_evaluation = evaluate_writing_rubric(english_draft)
            else:
                st.session_state.feedback = "AI í”¼ë“œë°± ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        
        tab1, tab2 = st.tabs(["AI í”¼ë“œë°±", "ë£¨ë¸Œë¦­ í‰ê°€"])
        
        with tab1:
            st.text_area(
                "AI í”¼ë“œë°±",
                value=st.session_state.feedback,
                height=400,
                disabled=True
            )
        
        with tab2:
            st.markdown("#### ì˜ì–´ í‘œí˜„ ëŠ¥ë ¥ í‰ê°€")
            eval_data = format_analysis_for_display(st.session_state.writing_evaluation, "evaluation")
            
            if "error" not in eval_data:
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    if "ë‚´ìš©ë…¼ë¦¬ì„±" in eval_data and isinstance(eval_data["ë‚´ìš©ë…¼ë¦¬ì„±"], dict):
                        logic = eval_data["ë‚´ìš©ë…¼ë¦¬ì„±"]
                        st.metric("ë‚´ìš© ë…¼ë¦¬ì„±", f"{logic.get('ì ìˆ˜', 0)}/4ì ")
                        st.caption(logic.get('ê·¼ê±°', ''))
                    else:
                        st.metric("ë‚´ìš© ë…¼ë¦¬ì„±", "N/A")
                
                with col2:
                    if "êµ¬ì„±ì²´ê³„ì„±" in eval_data and isinstance(eval_data["êµ¬ì„±ì²´ê³„ì„±"], dict):
                        org = eval_data["êµ¬ì„±ì²´ê³„ì„±"]
                        st.metric("êµ¬ì„± ì²´ê³„ì„±", f"{org.get('ì ìˆ˜', 0)}/4ì ")
                        st.caption(org.get('ê·¼ê±°', ''))
                    else:
                        st.metric("êµ¬ì„± ì²´ê³„ì„±", "N/A")
                
                with col3:
                    if "ë¬¸ë²•ì–´íœ˜ì •í™•ì„±" in eval_data and isinstance(eval_data["ë¬¸ë²•ì–´íœ˜ì •í™•ì„±"], dict):
                        lang = eval_data["ë¬¸ë²•ì–´íœ˜ì •í™•ì„±"]
                        st.metric("ë¬¸ë²•Â·ì–´íœ˜", f"{lang.get('ì ìˆ˜', 0)}/4ì ")
                        st.caption(lang.get('ê·¼ê±°', ''))
                    else:
                        st.metric("ë¬¸ë²•Â·ì–´íœ˜", "N/A")
                
                if eval_data.get('ì´ì '):
                    st.markdown(f"**ì´ì **: {eval_data['ì´ì ']}")
                
                if eval_data.get('ì¢…í•©í‰ê°€'):
                    st.markdown("**ì¢…í•© í‰ê°€**")
                    st.info(eval_data['ì¢…í•©í‰ê°€'])
            else:
                st.error(eval_data.get("error", "í‰ê°€ ì˜¤ë¥˜"))
    
    st.markdown("---")
    st.markdown("#### í”¼ë“œë°± ì„±ì°°")
    feedback_reflection_error = st.empty()
    feedback_reflection = st.text_area(
        "AI í”¼ë“œë°±ì„ ë°›ì€ í›„ ëŠë‚€ ì ê³¼ ê°œì„ í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì„ ì ì–´ë³´ì„¸ìš”:",
        height=100,
        key="feedback_reflection"
    )
    
    col_btn1, col_btn2 = st.columns([1, 1])
    with col_btn1:
        if st.button("â† ì´ì „ ë‹¨ê³„", use_container_width=True):
            st.session_state.stage = "draft"
            st.rerun()
    
    with col_btn2:
        if st.button("ìµœì¢… ìˆ˜ì • ë‹¨ê³„ë¡œ â†’", type="primary", use_container_width=True):
            if not feedback_reflection.strip():
                feedback_reflection_error.error("í”¼ë“œë°± ì„±ì°° ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                feedback_reflection_error.empty()
                st.session_state.reflection_log.append({
                    "stage": "feedback",
                    "content": feedback_reflection,
                    "timestamp": datetime.datetime.now()
                })
                with st.spinner("ì„±ì°° ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì œí•´ê²° ì—­ëŸ‰ í‰ê°€ ì¤‘..."):
                    st.session_state.problem_solving_score = assess_problem_solving(feedback_reflection)
                st.session_state.stage = "final"
                st.rerun()

elif st.session_state.stage == "final":
    st.subheader("5ë‹¨ê³„. ìµœì¢… ìˆ˜ì • ë° ì™„ì„±")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("**ìµœì¢… ìˆ˜ì •**")
        if "final_text" not in st.session_state or not st.session_state.final_text:
             st.session_state.final_text = st.session_state.draft
             
        final_text = st.text_area(
            "í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ìµœì¢… ìˆ˜ì •í•˜ì„¸ìš”",
            value=st.session_state.final_text,
            height=400,
            key="final_input"
        )
        
        st.session_state.final_text = final_text
    
    with col2:
        st.markdown("**ì¢…í•© í‰ê°€ ê²°ê³¼**")
        
        if st.session_state.problem_solving_score:
            with st.expander("ë¬¸ì œí•´ê²° ì—­ëŸ‰ í‰ê°€", expanded=True):
                problem_data = format_analysis_for_display(st.session_state.problem_solving_score, "assessment")
                
                if "error" not in problem_data:
                    if "assessment" in problem_data:
                        st.info(problem_data["assessment"])
                    else:
                        col1, col2 = st.columns(2)
                        
                        areas = ["ë¬¸ì œì´í•´", "ë¶„ì„ì ì‚¬ê³ ", "ëŒ€ì•ˆë°œê²¬ë°ê¸°íš", "ì˜ì‚¬ì†Œí†µ"]
                        for i, area in enumerate(areas):
                            col = col1 if i % 2 == 0 else col2
                            with col:
                                if area in problem_data and isinstance(problem_data[area], dict):
                                    score = problem_data[area].get('ì ìˆ˜', 0)
                                    st.metric(area.replace('ë°', ' & '), f"{score}/5ì ")
                                elif area in problem_data:
                                    st.metric(area.replace('ë°', ' & '), str(problem_data[area]))
                        
                        if problem_data.get('ì´ì '):
                            st.markdown(f"**ì´ì **: {problem_data['ì´ì ']}")
                        
                        if problem_data.get('ì¢…í•©í‰ê°€'):
                            st.markdown("**ì¢…í•© í‰ê°€**")
                            st.info(problem_data['ì¢…í•©í‰ê°€'])
                else:
                    st.error(problem_data.get("error", "í‰ê°€ ì˜¤ë¥˜"))
        
        if st.session_state.writing_evaluation:
            with st.expander("ì˜ì–´ í‘œí˜„ ëŠ¥ë ¥ í‰ê°€", expanded=True):
                eval_data = format_analysis_for_display(st.session_state.writing_evaluation, "evaluation")
                
                if "error" not in eval_data:
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        if "ë‚´ìš©ë…¼ë¦¬ì„±" in eval_data and isinstance(eval_data["ë‚´ìš©ë…¼ë¦¬ì„±"], dict):
                            logic = eval_data["ë‚´ìš©ë…¼ë¦¬ì„±"]
                            score = logic.get('ì ìˆ˜', 0)
                            st.metric("ë‚´ìš© ë…¼ë¦¬ì„±", f"{score}/4ì ")
                        else:
                            st.metric("ë‚´ìš© ë…¼ë¦¬ì„±", "N/A")
                    
                    with col2:
                        if "êµ¬ì„±ì²´ê³„ì„±" in eval_data and isinstance(eval_data["êµ¬ì„±ì²´ê³„ì„±"], dict):
                            org = eval_data["êµ¬ì„±ì²´ê³„ì„±"]
                            score = org.get('ì ìˆ˜', 0)
                            st.metric("êµ¬ì„± ì²´ê³„ì„±", f"{score}/4ì ")
                        else:
                            st.metric("êµ¬ì„± ì²´ê³„ì„±", "N/A")
                    
                    with col3:
                        if "ë¬¸ë²•ì–´íœ˜ì •í™•ì„±" in eval_data and isinstance(eval_data["ë¬¸ë²•ì–´íœ˜ì •í™•ì„±"], dict):
                            lang = eval_data["ë¬¸ë²•ì–´íœ˜ì •í™•ì„±"]
                            score = lang.get('ì ìˆ˜', 0)
                            st.metric("ë¬¸ë²•Â·ì–´íœ˜", f"{score}/4ì ")
                        else:
                            st.metric("ë¬¸ë²•Â·ì–´íœ˜", "N/A")
                else:
                    st.error(eval_data.get("error", "í‰ê°€ ì˜¤ë¥˜"))
    
    st.markdown("---")
    
    col_btn1, col_btn2, col_btn3, col_btn4 = st.columns([1, 1, 1, 1])
    
    with col_btn1:
        if st.button("â† ì´ì „ ë‹¨ê³„", use_container_width=True):
            st.session_state.stage = "feedback"
            st.rerun()

    with col_btn2:
        analysis_summary = {
            "ë…¼ì¡°ë¶„ì„1": st.session_state.tone_analysis1,
            "ë…¼ì¡°ë¶„ì„2": st.session_state.tone_analysis2,
            "ì˜ì–´í‘œí˜„í‰ê°€": st.session_state.writing_evaluation,
            "ë¬¸ë‹¨ë³„í”¼ë“œë°±": summarize_paragraph_feedback(st.session_state.paragraph_feedback)
        }
        if st.session_state.problem_solving_score:
            analysis_summary["ë¬¸ì œí•´ê²°í‰ê°€"] = st.session_state.problem_solving_score
            
        docx_data = create_docx_content(final_text, analysis_summary)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"news_comparison_complete_{timestamp}.docx"
        st.download_button(
            label="ì¢…í•© ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
            data=docx_data,
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            use_container_width=True,
            disabled=not final_text.strip()
        )

    with col_btn4:
        if st.button("ì²˜ìŒë¶€í„° ë‹¤ì‹œ", use_container_width=True):
            for key in list(st.session_state.keys()):
                if key != 'stage':
                    st.session_state.pop(key)
            st.session_state.stage = "input"
            st.rerun()
    
    if final_text.strip():
        st.markdown("### ì™„ì„±ëœ ì‘ë¬¸ ë¯¸ë¦¬ë³´ê¸°")
        st.success(final_text)
        
        if st.session_state.reflection_log:
            with st.expander("í•™ìŠµ ì„±ì°° ê¸°ë¡", expanded=False):
                for idx, log in enumerate(st.session_state.reflection_log):
                    st.markdown(f"**{log['stage']} ë‹¨ê³„ ì„±ì°°:**")
                    st.write(log['content'])
                    st.caption(f"ì‘ì„± ì‹œê°„: {log['timestamp']}")
                    st.markdown("---")

with st.sidebar:
    st.markdown("### ì‚¬ìš© ë°©ë²•")
    st.markdown("""
    1. **ê¸°ì‚¬ ì…ë ¥**: ë¹„êµí•  ë‘ ê¸°ì‚¬ì˜ ë³¸ë¬¸ì„ íŒŒì¼ ì—…ë¡œë“œ
    2. **ë…¼ì¡° ë¶„ì„**: AIê°€ ê° ê¸°ì‚¬ì˜ ë…¼ì¡°ì™€ ì…ì¥ì„ ë¶„ì„
    3. **ì´ˆì•ˆ ì‘ì„±**: ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ë¹„êµ ì„¤ëª…ë¬¸ ì‘ì„±
       - ê° ë¬¸ë‹¨ ì™„ë£Œ ì‹œ ì¦‰ì‹œ í”¼ë“œë°± ê°€ëŠ¥
    4. **AI í”¼ë“œë°±**: ë£¨ë¸Œë¦­ ê¸°ë°˜ AI í”¼ë“œë°±
    5. **ìµœì¢… ì™„ì„±**: í”¼ë“œë°±ì„ ë°˜ì˜í•œ ìˆ˜ì • í›„ ì¢…í•© ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ
    """)
    
    st.markdown("### ì„¤ì • ìƒíƒœ")
    if OPENAI_OK:
        st.success("OpenAI API ì—°ê²°ë¨")
    else:
        st.error("OpenAI API ì—°ê²° ì‹¤íŒ¨")
    
    st.markdown("### ì§„í–‰ ìƒí™©")
    st.markdown(f"í˜„ì¬ ë‹¨ê³„: **{stage_names[current_stage_idx]}**")
    
    checklist_items = [
        ("ê¸°ì‚¬ ì…ë ¥", bool(st.session_state.get("article1") and st.session_state.get("article2"))),
        ("ë…¼ì¡° ë¶„ì„", bool(st.session_state.get("tone_analysis1") and st.session_state.get("tone_analysis2"))),
        ("ì´ˆì•ˆ ì‘ì„±", bool(st.session_state.get("draft"))),
        ("ë¬¸ë‹¨ë³„ í”¼ë“œë°±", bool(st.session_state.get("paragraph_feedback"))),
        ("AI í”¼ë“œë°±", bool(st.session_state.get("feedback"))),
        ("ë£¨ë¸Œë¦­ í‰ê°€", bool(st.session_state.get("writing_evaluation"))),
        ("ìµœì¢… ì™„ì„±", bool(st.session_state.get("final_text")))
    ]
    
    for item, completed in checklist_items:
        icon = "âœ…" if completed else "â³"
        st.markdown(f"{icon} {item}")