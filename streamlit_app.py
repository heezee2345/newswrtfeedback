import os
import datetime
import streamlit as st
from openai import OpenAI, APIError
from docx import Document
import tempfile
import json
import pandas as pd
import re

# ë£¨ë¸Œë¦­ ê¸°ì¤€ ì •ì˜
RUBRIC_CRITERIA = {
    "ë‚´ìš©ë…¼ë¦¬ì„±": {
        "4ì  (ìš°ìˆ˜)": "ì£¼ì¥ì´ ëª…í™•í•˜ê³  ì¶©ë¶„í•œ ê·¼ê±°ê°€ ì²´ê³„ì ìœ¼ë¡œ ì œì‹œë¨. ë…¼ë¦¬ì  ì—°ê²°ì´ ìì—°ìŠ¤ëŸ½ê³  ì„¤ë“ë ¥ì´ ìˆìŒ",
        "3ì  (ë³´í†µ)": "ì£¼ì¥ì€ ëª…í™•í•˜ë‚˜ ê·¼ê±°ê°€ ë¶€ë¶„ì ìœ¼ë¡œ ë¶€ì¡±í•˜ê±°ë‚˜ ë…¼ë¦¬ì  ì—°ê²°ì´ ì¼ë¶€ ì–´ìƒ‰í•¨",
        "2ì  (ë¯¸í¡)": "ì£¼ì¥ì´ ë‹¤ì†Œ ëª¨í˜¸í•˜ê³  ê·¼ê±°ê°€ ì•½í•¨. ë…¼ë¦¬ì  ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŒ",
        "1ì  (ë¶€ì¡±)": "ì£¼ì¥ê³¼ ê·¼ê±°ê°€ ë¶ˆë¶„ëª…í•˜ê³  ë…¼ë¦¬ì  íë¦„ì´ ë¶€ìì—°ìŠ¤ëŸ¬ì›€"
    },
    "êµ¬ì„±ì²´ê³„ì„±": {
        "4ì  (ìš°ìˆ˜)": "ì„œë¡ -ë³¸ë¡ -ê²°ë¡  êµ¬ì¡°ê°€ ëª…í™•í•˜ê³  ë¬¸ë‹¨ ê°„ ì—°ê²°ì´ ìì—°ìŠ¤ëŸ¬ì›€. ì‘ì§‘ì„±ê³¼ ì¼ê´€ì„±ì´ ë›°ì–´ë‚¨",
        "3ì  (ë³´í†µ)": "ì „ì²´ êµ¬ì¡°ëŠ” ê°–ì¶”ì—ˆìœ¼ë‚˜ ë¬¸ë‹¨ ê°„ ì—°ê²°ì´ ë¶€ë¶„ì ìœ¼ë¡œ ì–´ìƒ‰í•¨",
        "2ì  (ë¯¸í¡)": "êµ¬ì¡°ê°€ ë¶ˆë¶„ëª…í•˜ê±°ë‚˜ ë¬¸ë‹¨ ê°„ íë¦„ì´ ë¶€ìì—°ìŠ¤ëŸ¬ì›€", 
        "1ì  (ë¶€ì¡±)": "ì „ì²´ êµ¬ì„±ì´ ì²´ê³„ì ì´ì§€ ì•Šê³  ì¼ê´€ì„±ì´ ë¶€ì¡±í•¨"
    },
    "ë¬¸ë²•ì–´íœ˜ì •í™•ì„±": {
        "4ì  (ìš°ìˆ˜)": "ë¬¸ë²•ì  ì˜¤ë¥˜ê°€ ê±°ì˜ ì—†ê³  ì–´íœ˜ ì‚¬ìš©ì´ ì ì ˆí•˜ë©° ë¬¸ì¥ êµ¬ì¡°ê°€ ë‹¤ì–‘í•¨",
        "3ì  (ë³´í†µ)": "ë¬¸ë²•ì  ì˜¤ë¥˜ê°€ ì•½ê°„ ìˆìœ¼ë‚˜ ì˜ë¯¸ ì „ë‹¬ì— í° ë¬¸ì œì—†ìŒ. ì–´íœ˜ ì‚¬ìš©ì´ ëŒ€ì²´ë¡œ ì ì ˆí•¨",
        "2ì  (ë¯¸í¡)": "ë¬¸ë²•ì  ì˜¤ë¥˜ê°€ ìì£¼ ë°œìƒí•˜ê³  ì–´íœ˜ ì„ íƒì´ ë¶€ì ì ˆí•œ ê²½ìš°ê°€ ìˆìŒ",
        "1ì  (ë¶€ì¡±)": "ë¬¸ë²•ì  ì˜¤ë¥˜ê°€ ë§ê³  ì–´íœ˜ ì‚¬ìš©ì´ ë¶€ì •í™•í•˜ì—¬ ì˜ë¯¸ ì „ë‹¬ì— ì–´ë ¤ì›€ì´ ìˆìŒ"
    }
}

# í™˜ê²½ ì„¤ì •
try:
    OPENAI_KEY = st.secrets["openai"]["api_key"]
except KeyError:
    OPENAI_KEY = ""

OPENAI_OK = bool(OPENAI_KEY)

client = None
if OPENAI_OK:
    try:
        client = OpenAI(api_key=OPENAI_KEY)
    except Exception as e:
        st.error(f"OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        OPENAI_OK = False

# ìƒˆë¡œìš´ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì¶”ê°€
def parse_gpt_json_response(response_text: str) -> dict:
    """GPT ì‘ë‹µì—ì„œ JSON ë¸”ë¡ì„ ì¶”ì¶œí•˜ê³  íŒŒì‹±"""
    try:
        # ```json ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ
        if "```json" in response_text:
            # ```jsonê³¼ ``` ì‚¬ì´ì˜ ë‚´ìš© ì¶”ì¶œ
            json_match = re.search(r'```json\s*\n(.*?)\n```', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1).strip()
            else:
                # ë‹¤ë¥¸ íŒ¨í„´ ì‹œë„
                json_str = response_text.replace('```json\n', '').replace('\n```', '').strip()
        else:
            json_str = response_text.strip()
        
        # JSON íŒŒì‹± ì‹œë„
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ì˜¤ë¥˜ ì •ë³´ ë°˜í™˜
        return {
            "error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}",
            "raw_response": response_text
        }
    except Exception as e:
        return {
            "error": f"ì‘ë‹µ ì²˜ë¦¬ ì‹¤íŒ¨: {e}",
            "raw_response": response_text
        }

def format_analysis_for_display(analysis_data: dict, analysis_type: str = "analysis") -> dict:
    """ë¶„ì„ ë°ì´í„°ë¥¼ í‘œì‹œìš©ìœ¼ë¡œ í¬ë§·íŒ…"""
    if not analysis_data:
        return {"error": "ë°ì´í„° ì—†ìŒ"}
    
    # ì´ë¯¸ íŒŒì‹±ëœ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
    if isinstance(analysis_data, dict) and "error" not in analysis_data:
        return analysis_data
    
    # analysis í‚¤ì— JSON ë¬¸ìì—´ì´ ìˆëŠ” ê²½ìš°
    if isinstance(analysis_data, dict) and analysis_type in analysis_data:
        return parse_gpt_json_response(analysis_data[analysis_type])
    
    # ê¸°íƒ€ ê²½ìš°
    return analysis_data

def format_for_docx(data: dict, title: str) -> str:
    """docxìš© ê°€ë…ì„± ìˆëŠ” í…ìŠ¤íŠ¸ í¬ë§·íŒ…"""
    if not isinstance(data, dict):
        return f"{title}: {str(data)}"
    
    if "error" in data:
        return f"{title}: ì˜¤ë¥˜ - {data['error']}"
    
    formatted_text = f"{title}:\n"
    
    # ë…¼ì¡° ë¶„ì„ ë°ì´í„° í¬ë§·íŒ…
    if "ë…¼ì¡°ë¶„ë¥˜" in data:
        formatted_text += f"  â€¢ ë…¼ì¡°ë¶„ë¥˜: {data.get('ë…¼ì¡°ë¶„ë¥˜', 'N/A')}\n"
        formatted_text += f"  â€¢ ë…¼ì¡°ì ìˆ˜: {data.get('ë…¼ì¡°ì ìˆ˜', 'N/A')}\n"
        formatted_text += f"  â€¢ ì‹ ë¢°ë„ì ìˆ˜: {data.get('ì‹ ë¢°ë„ì ìˆ˜', 'N/A')}/10\n"
        formatted_text += f"  â€¢ ê°ê´€ì„±ì ìˆ˜: {data.get('ê°ê´€ì„±ì ìˆ˜', 'N/A')}/10\n"
        
        if data.get('ì£¼ìš”ë…¼ì '):
            formatted_text += "  â€¢ ì£¼ìš”ë…¼ì :\n"
            for i, point in enumerate(data['ì£¼ìš”ë…¼ì '], 1):
                formatted_text += f"    {i}. {point}\n"
        
        if data.get('ê°ì •ì ì–¸ì–´'):
            formatted_text += f"  â€¢ ê°ì •ì ì–¸ì–´: {', '.join(data['ê°ì •ì ì–¸ì–´'])}\n"
    
    # ì˜ì–´ í‘œí˜„ í‰ê°€ ë°ì´í„° í¬ë§·íŒ…
    elif "ë‚´ìš©ë…¼ë¦¬ì„±" in data:
        for key in ["ë‚´ìš©ë…¼ë¦¬ì„±", "êµ¬ì„±ì²´ê³„ì„±", "ë¬¸ë²•ì–´íœ˜ì •í™•ì„±"]:
            if key in data and isinstance(data[key], dict):
                formatted_text += f"  â€¢ {key}: {data[key].get('ì ìˆ˜', 'N/A')}/4ì \n"
                formatted_text += f"    ê·¼ê±°: {data[key].get('ê·¼ê±°', 'N/A')}\n"
        
        if data.get('ì´ì '):
            formatted_text += f"  â€¢ ì´ì : {data['ì´ì ']}\n"
        if data.get('ì¢…í•©í‰ê°€'):
            formatted_text += f"  â€¢ ì¢…í•©í‰ê°€: {data['ì¢…í•©í‰ê°€']}\n"
    
    # ë¬¸ì œí•´ê²° í‰ê°€ ë°ì´í„° í¬ë§·íŒ…
    elif any(key in data for key in ["ë¬¸ì œì´í•´", "ë¶„ì„ì ì‚¬ê³ ", "ëŒ€ì•ˆë°œê²¬ë°ê¸°íš", "ì˜ì‚¬ì†Œí†µ"]):
        for key in ["ë¬¸ì œì´í•´", "ë¶„ì„ì ì‚¬ê³ ", "ëŒ€ì•ˆë°œê²¬ë°ê¸°íš", "ì˜ì‚¬ì†Œí†µ"]:
            if key in data:
                if isinstance(data[key], dict):
                    formatted_text += f"  â€¢ {key}: {data[key].get('ì ìˆ˜', 'N/A')}/5ì \n"
                    if 'ê°œì„ ì œì•ˆ' in data[key]:
                        formatted_text += f"    ê°œì„ ì œì•ˆ: {data[key]['ê°œì„ ì œì•ˆ']}\n"
                else:
                    formatted_text += f"  â€¢ {key}: {data[key]}\n"
    
    # ê¸°íƒ€ ë°ì´í„°
    else:
        for key, value in data.items():
            if key not in ["error", "raw_response"]:
                formatted_text += f"  â€¢ {key}: {value}\n"
    
    return formatted_text

# ë£¨ë¸Œë¦­ í‘œì‹œ í•¨ìˆ˜
def display_rubric():
    """ë£¨ë¸Œë¦­ ê¸°ì¤€ í‘œì‹œ"""
    st.markdown("### í‰ê°€ ê¸°ì¤€ (ë£¨ë¸Œë¦­)")
    st.markdown("ê¸€ì„ ì“°ê¸° ì „ì— í‰ê°€ ê¸°ì¤€ì„ í™•ì¸í•´ë³´ì„¸ìš”!")
    
    for category, criteria in RUBRIC_CRITERIA.items():
        with st.expander(f"{category} í‰ê°€ ê¸°ì¤€", expanded=False):
            for score, description in criteria.items():
                st.markdown(f"**{score}**: {description}")

# ë¬¸ë‹¨ë³„ í”¼ë“œë°± í•¨ìˆ˜
def get_paragraph_feedback(text: str, paragraph_type: str, context: dict = None) -> dict:
    """ë¬¸ë‹¨ë³„ ì¦‰ì‹œ í”¼ë“œë°± ì œê³µ"""
    if not OPENAI_OK or client is None:
        return {"error": "API ì˜¤ë¥˜"}
    
    if not text.strip():
        return {"error": "ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤"}
    
    # ë§¥ë½ ì •ë³´ êµ¬ì„±
    context_info = ""
    if context:
        if context.get("summary1") and context.get("summary2"):
            context_info = f"""
            ì°¸ê³ ìš© ê¸°ì‚¬ ìš”ì•½:
            ê¸°ì‚¬1: {context['summary1'][:200]}...
            ê¸°ì‚¬2: {context['summary2'][:200]}...
            """
    
    prompt = f"""
    ë‹¤ìŒ {paragraph_type} ë¬¸ë‹¨ì„ ë¶„ì„í•˜ê³  ì¦‰ì‹œ ê°œì„ í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”.

    {context_info}

    ë¬¸ë‹¨ ë‚´ìš©: {text}

    ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•˜ì„¸ìš”:
    {{
        "ê°•ì ": ["êµ¬ì²´ì  ê°•ì 1", "êµ¬ì²´ì  ê°•ì 2"],
        "ê°œì„ ì ": ["ê°œì„ ì‚¬í•­1", "ê°œì„ ì‚¬í•­2"],
        "êµ¬ì²´ì ì œì•ˆ": "ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ìˆ˜ì • ì œì•ˆ",
        "ì¶”ì²œì ìˆ˜": 1~4 ì‚¬ì´ì˜ ì •ìˆ˜ê°’
    }}
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=500
        )
        
        result = response.choices[0].message.content.strip()
        return parse_gpt_json_response(result)
    except Exception as e:
        return {"error": f"í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨: {e}"}

# ìê¸°í‰ê°€ ì¸í„°í˜ì´ìŠ¤
def self_assessment_interface():
    """ìê¸°í‰ê°€ ì¸í„°í˜ì´ìŠ¤"""
    st.subheader("ìê¸°í‰ê°€")
    st.markdown("AI í”¼ë“œë°±ì„ ë°›ê¸° ì „ì— ë¨¼ì € ë³¸ì¸ì˜ ê¸€ì„ ìŠ¤ìŠ¤ë¡œ í‰ê°€í•´ë³´ì„¸ìš”.")
    
    # ë£¨ë¸Œë¦­ ë‹¤ì‹œ ë³´ê¸° ë²„íŠ¼
    if st.button("í‰ê°€ ê¸°ì¤€ ë‹¤ì‹œ ë³´ê¸°"):
        display_rubric()
    
    st.markdown("---")
    
    self_scores = {}
    self_reflections = {}
    
    # ê° ì˜ì—­ë³„ ìê¸°í‰ê°€
    categories = ["ë‚´ìš©ë…¼ë¦¬ì„±", "êµ¬ì„±ì²´ê³„ì„±", "ë¬¸ë²•ì–´íœ˜ì •í™•ì„±"]
    
    for category in categories:
        st.markdown(f"#### {category}")
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            score = st.selectbox(
                f"{category} ì ìˆ˜",
                options=[1, 2, 3, 4],
                format_func=lambda x: f"{x}ì ",
                key=f"self_{category}_score"
            )
            self_scores[category] = score
        
        with col2:
            reflection = st.text_area(
                f"{category} í‰ê°€ ì´ìœ ",
                placeholder=f"ì™œ {score}ì ì„ ì£¼ì—ˆëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì ì–´ë³´ì„¸ìš”...",
                height=80,
                key=f"self_{category}_reflection"
            )
            self_reflections[category] = reflection
    
    # ì „ì²´ ì„±ì°°
    st.markdown("#### ì „ì²´ì ì¸ ìê¸° ì„±ì°°")
    overall_reflection = st.text_area(
        "ì‘ì„± ê³¼ì •ì—ì„œ ì–´ë ¤ì› ë˜ ì , ì˜í–ˆë‹¤ê³  ìƒê°í•˜ëŠ” ë¶€ë¶„, ê°œì„ í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì„ ììœ ë¡­ê²Œ ì ì–´ë³´ì„¸ìš”.",
        height=100,
        key="overall_self_reflection"
    )
    
    return {
        "scores": self_scores,
        "reflections": self_reflections,
        "overall_reflection": overall_reflection
    }

# ì¢…í•©ì  í”¼ë“œë°± í•¨ìˆ˜
def enhanced_gpt_feedback(korean_text: str, self_assessment: dict, paragraph_feedback: dict = None) -> str:
    """ìê¸°í‰ê°€ì™€ ë¬¸ë‹¨ë³„ í”¼ë“œë°±ì´ ë°˜ì˜ëœ ì¢…í•©ì  GPT í”¼ë“œë°±"""
    if not OPENAI_OK or client is None:
        return "GPT ì‚¬ìš©ì„ ìœ„í•œ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤."
    if not korean_text.strip():
        return "í”¼ë“œë°±í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."

    # ìê¸°í‰ê°€ ì •ë³´ êµ¬ì„±
    self_scores_str = ", ".join([f"{k}: {v}ì " for k, v in self_assessment["scores"].items()])
    self_reflections_str = "\n".join([f"- {k}: {v}" for k, v in self_assessment["reflections"].items() if v.strip()])
    
    # ë¬¸ë‹¨ë³„ í”¼ë“œë°± ìš”ì•½
    paragraph_summary = ""
    if paragraph_feedback:
        paragraph_summary = "í•™ìŠµ ê³¼ì •ì—ì„œ ë°›ì€ ë¬¸ë‹¨ë³„ í”¼ë“œë°±:\n"
        for section, feedback in paragraph_feedback.items():
            if isinstance(feedback, dict) and "êµ¬ì²´ì ì œì•ˆ" in feedback:
                paragraph_summary += f"- {section}: {feedback['êµ¬ì²´ì ì œì•ˆ']}\n"
    
    prompt = f"""
    ë‹¹ì‹ ì€ ê²½í—˜ ë§ì€ ê¸€ì“°ê¸° ì§€ë„êµì‚¬ì…ë‹ˆë‹¤. í•™ìŠµìê°€ ì‘ë¬¸ ê³¼ì •ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ í•™ìŠµ í™œë™ì„ í–ˆìŠµë‹ˆë‹¤:

    **í•™ìŠµìì˜ ìê¸°í‰ê°€ ê²°ê³¼:**
    - ì ìˆ˜: {self_scores_str}
    - ìê¸°ì„±ì°°: 
    {self_reflections_str}
    - ì „ì²´ ì„±ì°°: {self_assessment["overall_reflection"]}

    {paragraph_summary}

    **ì¢…í•© í‰ê°€ ê¸°ì¤€:**
    1. ë‚´ìš© ë…¼ë¦¬ì„±: ì£¼ì¥ì˜ ëª…í™•ì„±, ê·¼ê±° ì œì‹œ ì¶©ë¶„ì„±, ë…¼ë¦¬ì  ì—°ê²°
    2. êµ¬ì„± ì²´ê³„ì„±: ì„œë¡ -ë³¸ë¡ -ê²°ë¡  êµ¬ì¡°, ë¬¸ë‹¨ ê°„ ì—°ê²°ê³¼ íë¦„, ì‘ì§‘ì„±
    3. ë¬¸ë²•Â·ì–´íœ˜ ì •í™•ì„±: ë¬¸ë²•ì  ì •í™•ì„±, ì–´íœ˜ ì„ íƒì˜ ì ì ˆì„±

    **ì¢…í•© í”¼ë“œë°± êµ¬ì„±:**
    1. í•™ìŠµ ê³¼ì •ì— ëŒ€í•œ ê²©ë ¤ì™€ ì¸ì •
    2. ìê¸°í‰ê°€ ì •í™•ë„ ë¶„ì„ (ë™ì˜/ì°¨ì´ì ê³¼ ê·¸ ì´ìœ )
    3. ê° ì˜ì—­ë³„ êµ¬ì²´ì  í”¼ë“œë°±ê³¼ ê°ê´€ì  í‰ê°€ (1-4ì )
    4. í•™ìŠµìê°€ ë†“ì¹œ ê°•ì  ë°œê²¬í•˜ì—¬ ê²©ë ¤
    5. ìš°ì„ ìˆœìœ„ê°€ ìˆëŠ” êµ¬ì²´ì  ê°œì„  ì œì•ˆ (3-4ê°€ì§€)
    6. ë‹¤ìŒ ê¸€ì“°ê¸°ë¥¼ ìœ„í•œ ëª©í‘œ ì„¤ì • ì œì•ˆ

    í‰ê°€ ëŒ€ìƒ ê¸€:
    {korean_text}
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ê±´ì„¤ì ì´ê³  ê²©ë ¤ì ì¸ ê¸€ì“°ê¸° ì§€ë„êµì‚¬ì…ë‹ˆë‹¤. í•™ìŠµìì˜ ì„±ì¥ì„ ë•ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=1800
        )
        return response.choices[0].message.content.strip()
    except APIError as e:
        return f"OpenAI API ì˜¤ë¥˜: {e}"
    except Exception as e:
        return f"GPT í˜¸ì¶œ ì˜¤ë¥˜: {e}"

def summarize_paragraph_feedback(paragraph_feedback: dict) -> str:
    """ë¬¸ë‹¨ë³„ í”¼ë“œë°±ì„ ìš”ì•½"""
    if not paragraph_feedback:
        return "ë¬¸ë‹¨ë³„ í”¼ë“œë°± ì—†ìŒ"
    
    summary = "ë¬¸ë‹¨ë³„ í•™ìŠµ ê³¼ì • ìš”ì•½:\n"
    for section, feedback in paragraph_feedback.items():
        if isinstance(feedback, dict):
            if "error" not in feedback:
                summary += f"- {section}: ì¶”ì²œì ìˆ˜ {feedback.get('ì¶”ì²œì ìˆ˜', 'N/A')}ì \n"
                summary += f"  ì£¼ìš” ê°œì„ ì œì•ˆ: {feedback.get('êµ¬ì²´ì ì œì•ˆ', 'N/A')}\n"
            else:
                summary += f"- {section}: í”¼ë“œë°± ì—†ìŒ\n"
    return summary

# ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ìˆ˜ì •ë˜ì§€ ì•ŠìŒ)
def summarize_text(text: str) -> str:
    """ê¸°ì‚¬ ë‚´ìš©ì„ ì˜ì–´ë¡œ 5-10ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½"""
    if not OPENAI_OK or client is None:
        return "ìš”ì•½ ë¶ˆê°€: API ì˜¤ë¥˜"
    if not text.strip():
        return "ìš”ì•½ ë¶ˆê°€: ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    prompt = f"ë‹¤ìŒ ê¸°ì‚¬ ë‚´ìš©ì„ ì˜ì–´ë¡œ ë‹¤ì„¯ ë¬¸ì¥ ì´ìƒ, ì—´ë¬¸ì¥ ì´í•˜ë¡œ ìš”ì•½í•´ì¤˜:\n\n{text}"
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=800
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"ìš”ì•½ ì‹¤íŒ¨: {e}"

def analyze_tone_and_stance(text: str) -> dict:
    """ë…¼ì¡° ë° ì…ì¥ ë¶„ì„ - ì ìˆ˜í™”ëœ ë…¼ì¡° í¬í•¨"""
    if not OPENAI_OK or client is None:
        return {"error": "API ì˜¤ë¥˜"}
    
    prompt = f"""
    ë‹¤ìŒ ê¸°ì‚¬ì˜ ë…¼ì¡°ì™€ ì…ì¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
    
    ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•˜ê³ , ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”:
    
    {{
        "ë…¼ì¡°ë¶„ë¥˜": "positive/neutral/negative",
        "ë…¼ì¡°ì ìˆ˜": -3~3 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
        "ì£¼ìš”ë…¼ì ": ["ë…¼ì 1", "ë…¼ì 2", "ë…¼ì 3"],
        "ê°ì •ì ì–¸ì–´": ["ì˜ˆì‹œ1", "ì˜ˆì‹œ2", "ì˜ˆì‹œ3"],
        "ì‹ ë¢°ë„ì ìˆ˜": 1~10 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
        "ê°ê´€ì„±ì ìˆ˜": 1~10 ì‚¬ì´ì˜ ì •ìˆ˜ê°’
    }}
    
    ê¸°ì‚¬: {text}
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=600
        )
        
        result = response.choices[0].message.content.strip()
        return parse_gpt_json_response(result)
    except Exception as e:
        return {"error": f"ë¶„ì„ ì‹¤íŒ¨: {e}"}

def evaluate_writing_rubric(text: str) -> dict:
    """ì˜ì–´ í‘œí˜„ ëŠ¥ë ¥ ë£¨ë¸Œë¦­ í‰ê°€"""
    if not OPENAI_OK or client is None:
        return {"error": "API ì˜¤ë¥˜"}
    
    prompt = f"""
    ë‹¤ìŒ ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì²´ì ì¸ ë£¨ë¸Œë¦­ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.

    **í‰ê°€ ì˜ì—­ ë° ê¸°ì¤€:**

    **1. ë‚´ìš© ë…¼ë¦¬ì„± (Content Logic) - 1~4ì **
    **2. êµ¬ì„± ì²´ê³„ì„± (Organization) - 1~4ì **
    **3. ë¬¸ë²•Â·ì–´íœ˜ ì •í™•ì„± (Language Accuracy) - 1~4ì **

    ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•˜ê³ , ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”:

    {{
        "ë‚´ìš©ë…¼ë¦¬ì„±": {{
            "ì ìˆ˜": 1~4 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê·¼ê±°": "êµ¬ì²´ì  í‰ê°€ ê·¼ê±°"
        }},
        "êµ¬ì„±ì²´ê³„ì„±": {{
            "ì ìˆ˜": 1~4 ì‚¬ì´ì˜ ì •ìˆ˜ê°’, 
            "ê·¼ê±°": "êµ¬ì²´ì  í‰ê°€ ê·¼ê±°"
        }},
        "ë¬¸ë²•ì–´íœ˜ì •í™•ì„±": {{
            "ì ìˆ˜": 1~4 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê·¼ê±°": "êµ¬ì²´ì  í‰ê°€ ê·¼ê±°"
        }},
        "ì´ì ": "12ì  ë§Œì  ì¤‘ Xì ",
        "ì¢…í•©í‰ê°€": "ì „ì²´ì ì¸ í‰ê°€ ë° ê°œì„  ì œì•ˆ"
    }}

    í‰ê°€ ëŒ€ìƒ í…ìŠ¤íŠ¸: {text}
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=800
        )
        
        result = response.choices[0].message.content.strip()
        return parse_gpt_json_response(result)
    except Exception as e:
        return {"error": f"í‰ê°€ ì‹¤íŒ¨: {e}"}

def assess_problem_solving(reflection_text: str) -> dict:
    """ë¬¸ì œí•´ê²° ì—­ëŸ‰ í‰ê°€"""
    if not OPENAI_OK or client is None:
        return {"error": "API ì˜¤ë¥˜"}
    
    # ì„±ì°° ë‚´ìš©ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ì˜ë¯¸ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
    if not reflection_text or len(reflection_text.strip()) < 10:
        return {
            "assessment": f"ì„±ì°° ë‚´ìš©ì´ \"{reflection_text}\"ë¼ëŠ” í•œ ë‹¨ì–´ë¡œë§Œ ì œê³µë˜ì–´ ìˆì–´, í•™ìŠµìì˜ ë¬¸ì œí•´ê²° ì—­ëŸ‰ì„ í‰ê°€í•˜ê¸°ì—ëŠ” ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì„±ì°° ë‚´ìš©ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í•™ìŠµìê°€ ì–´ë–¤ ë¬¸ì œë¥¼ ë‹¤ë£¨ì—ˆëŠ”ì§€, ê·¸ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ ì´í•´í•˜ê³  ë¶„ì„í–ˆëŠ”ì§€, ì–´ë–¤ ëŒ€ì•ˆì„ ë°œê²¬í•˜ê³  ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í–ˆëŠ”ì§€, ê·¸ë¦¬ê³  ì˜ì‚¬ì†Œí†µì„ ì–´ë–»ê²Œ í–ˆëŠ”ì§€ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.\n\ní˜„ì¬ ì œê³µëœ ì •ë³´ë¡œëŠ” í‰ê°€ë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, ì¶”ê°€ì ì¸ ì„±ì°° ë‚´ìš©ì„ ì œê³µí•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."
        }
    
    prompt = f"""
    ë‹¤ìŒ í•™ìŠµìì˜ ì„±ì°° ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì œí•´ê²° ì—­ëŸ‰ì„ í‰ê°€í•´ì£¼ì„¸ìš”:
    
    ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•˜ê³ , ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”:
    
    {{
        "ë¬¸ì œì´í•´": {{
            "ì ìˆ˜": 1~5 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê°œì„ ì œì•ˆ": "êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ"
        }},
        "ë¶„ì„ì ì‚¬ê³ ": {{
            "ì ìˆ˜": 1~5 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê°œì„ ì œì•ˆ": "êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ"
        }},
        "ëŒ€ì•ˆë°œê²¬ë°ê¸°íš": {{
            "ì ìˆ˜": 1~5 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê°œì„ ì œì•ˆ": "êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ"
        }},
        "ì˜ì‚¬ì†Œí†µ": {{
            "ì ìˆ˜": 1~5 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê°œì„ ì œì•ˆ": "êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ"
        }},
        "ì´ì ": "20ì  ë§Œì  ì¤‘ Xì ",
        "ì¢…í•©í‰ê°€": "ì „ì²´ì ì¸ í‰ê°€ ìš”ì•½"
    }}
    
    ì„±ì°° ë‚´ìš©: {reflection_text}
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=800
        )
        
        result = response.choices[0].message.content.strip()
        return parse_gpt_json_response(result)
    except Exception as e:
        return {"error": f"í‰ê°€ ì‹¤íŒ¨: {e}"}

# ë‚˜ë¨¸ì§€ í•¨ìˆ˜ë“¤ì€ ê¸°ì¡´ê³¼ ë™ì¼
def display_emotional_words(analysis1: dict, analysis2: dict) -> None:
    """ê°ì •ì  ì–¸ì–´ ì‹œê°í™”"""
    st.markdown("#### ê°ì •ì  í‘œí˜„ ë¹„êµ")
    
    # ë°ì´í„° í¬ë§·íŒ…
    analysis1 = format_analysis_for_display(analysis1, "analysis")
    analysis2 = format_analysis_for_display(analysis2, "analysis")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**ê¸°ì‚¬ 1**")
        if "ê°ì •ì ì–¸ì–´" in analysis1 and analysis1["ê°ì •ì ì–¸ì–´"]:
            words = analysis1["ê°ì •ì ì–¸ì–´"]
            word_html = ""
            for i, word in enumerate(words):
                size = 20 - i*2
                color = ["#ff6b6b", "#4ecdc4", "#45b7d1", "#96ceb4", "#feca57"][i % 5]
                word_html += f'<span style="font-size:{size}px; color:{color}; margin:5px; font-weight:bold;">{word}</span> '
            
            st.markdown(f'<div style="line-height:2;">{word_html}</div>', unsafe_allow_html=True)
        else:
            st.info("ê°ì •ì  í‘œí˜„ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    with col2:
        st.markdown("**ê¸°ì‚¬ 2**")
        if "ê°ì •ì ì–¸ì–´" in analysis2 and analysis2["ê°ì •ì ì–¸ì–´"]:
            words = analysis2["ê°ì •ì ì–¸ì–´"]
            word_html = ""
            for i, word in enumerate(words):
                size = 20 - i*2
                color = ["#ff6b6b", "#4ecdc4", "#45b7d1", "#96ceb4", "#feca57"][i % 5]
                word_html += f'<span style="font-size:{size}px; color:{color}; margin:5px; font-weight:bold;">{word}</span> '
            
            st.markdown(f'<div style="line-height:2;">{word_html}</div>', unsafe_allow_html=True)
        else:
            st.info("ê°ì •ì  í‘œí˜„ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def create_simple_gauge(value: int, title: str) -> None:
    """ê°„ë‹¨í•œ ê²Œì´ì§€ ì‹œê°í™”"""
    percentage = ((value + 3) / 6) * 100
    
    if value <= -2:
        color = "#ff4757"
        emoji = "ğŸ˜"
    elif value <= -1:
        color = "#ffa502"
        emoji = "ğŸ˜•"
    elif value == 0:
        color = "#747d8c"
        emoji = "ğŸ˜"
    elif value <= 1:
        color = "#2ed573"
        emoji = "ğŸ™‚"
    else:
        color = "#5352ed"
        emoji = "ğŸ˜Š"
    
    gauge_html = f"""
    <div style="text-align: center; margin: 20px; padding: 20px; border-radius: 10px; background-color: #f8f9fa;">
        <h4 style="margin-bottom: 15px;">{title}</h4>
        <div style="font-size: 30px; margin-bottom: 10px;">{emoji}</div>
        <div style="width: 200px; height: 20px; background-color: #e1e8ed; border-radius: 10px; margin: 0 auto; position: relative;">
            <div style="width: {percentage}%; height: 100%; background-color: {color}; border-radius: 10px;"></div>
        </div>
        <p style="margin-top: 10px; font-weight: bold; color: {color}; font-size: 18px;">{value}ì </p>
    </div>
    """
    st.markdown(gauge_html, unsafe_allow_html=True)

def create_enhanced_comparison_chart(analysis1: dict, analysis2: dict) -> None:
    """ê°œì„ ëœ ë…¼ì¡° ë¹„êµ ì°¨íŠ¸"""
    # ë°ì´í„° í¬ë§·íŒ…
    analysis1 = format_analysis_for_display(analysis1, "analysis")
    analysis2 = format_analysis_for_display(analysis2, "analysis")
    
    if "error" in analysis1 or "error" in analysis2:
        st.error("ë…¼ì¡° ë¶„ì„ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    st.markdown("#### ë…¼ì¡° ì ìˆ˜ ë¹„êµ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        create_simple_gauge(analysis1.get('ë…¼ì¡°ì ìˆ˜', 0), "ê¸°ì‚¬ 1 ë…¼ì¡°")
    with col2:
        create_simple_gauge(analysis2.get('ë…¼ì¡°ì ìˆ˜', 0), "ê¸°ì‚¬ 2 ë…¼ì¡°")
    
    # ì‹ ë¢°ë„ & ê°ê´€ì„± ì°¨íŠ¸
    st.markdown("#### ì‹ ë¢°ë„ ë° ê°ê´€ì„±")
    
    trust1 = analysis1.get('ì‹ ë¢°ë„ì ìˆ˜', 5)
    trust2 = analysis2.get('ì‹ ë¢°ë„ì ìˆ˜', 5)
    obj1 = analysis1.get('ê°ê´€ì„±ì ìˆ˜', 5)
    obj2 = analysis2.get('ê°ê´€ì„±ì ìˆ˜', 5)
    
    metrics_df = pd.DataFrame({
        'ì§€í‘œ': ['ì‹ ë¢°ë„', 'ê°ê´€ì„±'],
        'ê¸°ì‚¬1': [trust1, obj1],
        'ê¸°ì‚¬2': [trust2, obj2]
    })
    st.bar_chart(metrics_df.set_index('ì§€í‘œ'))

def gpt_feedback(korean_text: str) -> str:
    """í•œêµ­ì–´ ì‘ë¬¸ì— ëŒ€í•œ í•œêµ­ì–´ í”¼ë“œë°± ì œê³µ (ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€)"""
    if not OPENAI_OK or client is None:
        return "GPT ì‚¬ìš©ì„ ìœ„í•œ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤."
    if not korean_text.strip():
        return "í”¼ë“œë°±í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."

    prompt = f"""
    ë‹¹ì‹ ì€ í•œêµ­ì¸ í•™ìŠµìë¥¼ ìœ„í•œ ê¸€ì“°ê¸° ì§€ë„êµì‚¬ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¹„êµ ì„¤ëª…ë¬¸ì„ í‰ê°€í•˜ê³  ê±´ì„¤ì ì¸ í”¼ë“œë°±ì„ í•œêµ­ì–´ë¡œ ì œê³µí•˜ì„¸ìš”.

    ë‹¤ìŒ ë£¨ë¸Œë¦­ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”:

    **1. ë‚´ìš© ë…¼ë¦¬ì„± (Content Logic)** - ì£¼ì¥ì˜ ëª…í™•ì„±, ê·¼ê±° ì œì‹œ ì¶©ë¶„ì„±, ë…¼ë¦¬ì  ì—°ê²°, ë¬¸ì œ ìƒí™© ë¶„ì„ ê¹Šì´

    **2. êµ¬ì„± ì²´ê³„ì„± (Organization)**
    - ì„œë¡ -ë³¸ë¡ -ê²°ë¡  êµ¬ì¡°, ë¬¸ë‹¨ ê°„ ì—°ê²°ê³¼ íë¦„, ì‘ì§‘ì„±ê³¼ ì¼ê´€ì„±

    **3. ë¬¸ë²•Â·ì–´íœ˜ ì •í™•ì„± (Language Accuracy)**
    - ë¬¸ë²•ì  ì •í™•ì„±, ë¬¸ì¥ êµ¬ì¡°ì˜ ë‹¤ì–‘ì„±, ì–´íœ˜ ì„ íƒì˜ ì ì ˆì„±

    ê° ì˜ì—­ë³„ë¡œ êµ¬ì²´ì ì¸ í”¼ë“œë°±ê³¼ 3-5ê°œì˜ ê°œì„  ì œì•ˆì„ ì œê³µí•´ì£¼ì„¸ìš”.

    í‰ê°€ ëŒ€ìƒ ê¸€:
    {korean_text}
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸€ì“°ê¸° ì§€ë„êµì‚¬ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=1200
        )
        return response.choices[0].message.content.strip()
    except APIError as e:
        return f"OpenAI API ì˜¤ë¥˜: {e}"
    except Exception as e:
        return f"GPT í˜¸ì¶œ ì˜¤ë¥˜: {e}"

def translate_to_korean(text: str) -> str:
    """ì˜ë¬¸ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­"""
    if not OPENAI_OK or client is None:
        return "ë²ˆì—­ ë¶ˆê°€: API ì˜¤ë¥˜"
    if "ìš”ì•½ ì‹¤íŒ¨" in text or "ìš”ì•½ ë¶ˆê°€" in text:
        return "ì›ë³¸ ìš”ì•½ì´ ì—†ì–´ ë²ˆì—­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    if not text.strip():
        return "ë²ˆì—­ ë¶ˆê°€: ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."

    prompt = f"ë‹¤ìŒ ì˜ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì¤˜:\n\n{text}"
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=1000
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"ë²ˆì—­ ì‹¤íŒ¨: {e}"

def translate_to_english(text: str) -> str:
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­"""
    if not OPENAI_OK or client is None:
        return "ë²ˆì—­ ë¶ˆê°€: API ì˜¤ë¥˜"
    if not text.strip():
        return "ë²ˆì—­ ë¶ˆê°€: ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."

    prompt = f"ë‹¤ìŒ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ì˜ì–´ë¡œ ë²ˆì—­í•´ì¤˜:\n\n{text}"
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=1200
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"ë²ˆì—­ ì‹¤íŒ¨: {e}"

def create_docx_content(text: str, analysis_data: dict = None) -> bytes:
    """í…ìŠ¤íŠ¸ë¥¼ DOCX íŒŒì¼ë¡œ ë³€í™˜í•˜ì—¬ ë°”ì´íŠ¸ ë°ì´í„° ë°˜í™˜"""
    doc = Document()
    doc.add_heading('News Comparison Analysis', 0)
    doc.add_paragraph(f"ì‘ì„±ì¼: {datetime.datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}")
    doc.add_paragraph("")
    
    if analysis_data:
        doc.add_heading('ë¶„ì„ ìš”ì•½', level=1)
        
        for key, value in analysis_data.items():
            if key == "ë…¼ì¡°ë¶„ì„1":
                formatted_analysis1 = format_analysis_for_display(value, "analysis")
                doc.add_paragraph(format_for_docx(formatted_analysis1, "ë…¼ì¡°ë¶„ì„1"))
                doc.add_paragraph("")
            elif key == "ë…¼ì¡°ë¶„ì„2":
                formatted_analysis2 = format_analysis_for_display(value, "analysis")
                doc.add_paragraph(format_for_docx(formatted_analysis2, "ë…¼ì¡°ë¶„ì„2"))
                doc.add_paragraph("")
            elif key == "ì˜ì–´í‘œí˜„í‰ê°€":
                formatted_evaluation = format_analysis_for_display(value, "evaluation")
                doc.add_paragraph(format_for_docx(formatted_evaluation, "ì˜ì–´í‘œí˜„í‰ê°€"))
                doc.add_paragraph("")
            elif key == "ë¬¸ì œí•´ê²°í‰ê°€":
                formatted_problem_solving = format_analysis_for_display(value, "assessment")
                doc.add_paragraph(format_for_docx(formatted_problem_solving, "ë¬¸ì œí•´ê²°í‰ê°€"))
                doc.add_paragraph("")
            elif key == "ë¬¸ë‹¨ë³„í”¼ë“œë°±":
                doc.add_paragraph(f"ë¬¸ë‹¨ë³„í”¼ë“œë°±:\n{value}")
                doc.add_paragraph("")
        
        doc.add_paragraph("")
    
    doc.add_heading('ì‘ì„±ëœ ì„¤ëª…ë¬¸', level=1)
    for line in text.splitlines():
        if line.strip():
            doc.add_paragraph(line)
    
    with tempfile.NamedTemporaryFile() as tmp:
        doc.save(tmp.name)
        tmp.seek(0)
        return tmp.read()

# Streamlit ì•± ì„¤ì •
st.set_page_config(
    page_title="News Comparison Assistant", 
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "stage" not in st.session_state:
    st.session_state.update({
        "stage": "input",
        "article1": "", "article2": "",
        "summary1": "", "summary2": "",
        "summary1_kr": "", "summary2_kr": "",
        "tone_analysis1": {}, "tone_analysis2": {},
        "draft": "", "feedback": "",
        "writing_evaluation": {},
        "problem_solving_score": {},
        "reflection_log": [],
        "final_text": "",
        "paragraph_feedback": {},  # ë¬¸ë‹¨ë³„ í”¼ë“œë°± ì €ì¥
        "self_assessment": None,   # ìê¸°í‰ê°€ ê²°ê³¼
        "enhanced_feedback": ""    # í–¥ìƒëœ í”¼ë“œë°±
    })

# ë©”ì¸ íƒ€ì´í‹€ê³¼ ê²½ê³  ë©”ì‹œì§€
st.title("News Comparison and Writing Assistant")

if not OPENAI_OK:
    st.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ìš”ì•½ ë° í”¼ë“œë°± ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")

# ì§„í–‰ ìƒíƒœ í‘œì‹œ
progress_stages = ["input", "analysis", "draft", "feedback", "final"]
current_stage_idx = progress_stages.index(st.session_state.stage)
progress = (current_stage_idx + 1) / len(progress_stages)

st.progress(progress)
stage_names = ["ê¸°ì‚¬ ì…ë ¥", "ë…¼ì¡° ë¶„ì„", "ì´ˆì•ˆ ì‘ì„±", "AI í”¼ë“œë°±", "ìµœì¢… ì™„ì„±"]
st.caption(f"í˜„ì¬ ë‹¨ê³„: {stage_names[current_stage_idx]} ({current_stage_idx + 1}/{len(progress_stages)})")

# ë£¨ë¸Œë¦­ ì‚¬ì „ í‘œì‹œ
if st.session_state.stage in ["draft", "feedback"]:
    display_rubric()
    st.markdown("---")

# ë‹¨ê³„ë³„ í™”ë©´ êµ¬ì„±

# 1ë‹¨ê³„: ê¸°ì‚¬ ì…ë ¥
if st.session_state.stage == "input":
    st.subheader("1ë‹¨ê³„. ê¸°ì‚¬ ë³¸ë¬¸ ì…ë ¥")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**ê¸°ì‚¬ 1 ë³¸ë¬¸**")
        error_placeholder1 = st.empty()
        article1 = st.text_area(
            "ì²« ë²ˆì§¸ ê¸°ì‚¬ì˜ ë³¸ë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
            value=st.session_state.get("article1", ""),
            height=300,
            key="article1_input"
        )
    
    with col2:
        st.markdown("**ê¸°ì‚¬ 2 ë³¸ë¬¸**")
        error_placeholder2 = st.empty()
        article2 = st.text_area(
            "ë‘ ë²ˆì§¸ ê¸°ì‚¬ì˜ ë³¸ë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
            value=st.session_state.get("article2", ""),
            height=300,
            key="article2_input"
        )
    
    st.markdown("---")
    
    col_btn1, col_btn2 = st.columns([1, 1])
    with col_btn2:
        overall_error_placeholder = st.empty()
        if st.button("ë‹¤ìŒ ë‹¨ê³„ â†’ (ë¶„ì„ ì‹œì‘)", type="primary", use_container_width=True):
            is_valid = True
            if not article1.strip():
                error_placeholder1.error("ê¸°ì‚¬ 1 ë³¸ë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                is_valid = False
            else:
                error_placeholder1.empty()

            if not article2.strip():
                error_placeholder2.error("ê¸°ì‚¬ 2 ë³¸ë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                is_valid = False
            else:
                error_placeholder2.empty()

            if is_valid:
                overall_error_placeholder.empty()
                st.session_state.article1 = article1
                st.session_state.article2 = article2
                st.session_state.stage = "analysis"
                st.rerun()
            else:
                overall_error_placeholder.error("ëª¨ë“  í•„ìˆ˜ ì…ë ¥ í•„ë“œë¥¼ ì±„ì›Œì£¼ì„¸ìš”.")

# 2ë‹¨ê³„: ë…¼ì¡° ë¶„ì„ ë° ì‹œê°í™”
elif st.session_state.stage == "analysis":
    st.subheader("2ë‹¨ê³„. ë…¼ì¡° ë¶„ì„ ë° ìš”ì•½")
    
    if not st.session_state.get("summary1"):
        with st.spinner("ê¸°ì‚¬ ë¶„ì„ ë° ìš”ì•½ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
            st.session_state.summary1 = summarize_text(st.session_state.article1)
            st.session_state.summary2 = summarize_text(st.session_state.article2)
            
            st.session_state.tone_analysis1 = analyze_tone_and_stance(st.session_state.article1)
            st.session_state.tone_analysis2 = analyze_tone_and_stance(st.session_state.article2)
            
            st.session_state.summary1_kr = translate_to_korean(st.session_state.summary1)
            st.session_state.summary2_kr = translate_to_korean(st.session_state.summary2)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ê¸°ì‚¬ 1 ë¶„ì„")
        with st.expander("ìš”ì•½ (ì˜ì–´/í•œêµ­ì–´)", expanded=True):
            st.info(f"**[English]**\n{st.session_state.summary1}")
            st.success(f"**[í•œêµ­ì–´]**\n{st.session_state.summary1_kr}")
        
        with st.expander("ë…¼ì¡° ë¶„ì„", expanded=True):
            analysis1 = format_analysis_for_display(st.session_state.tone_analysis1, "analysis")
            if "error" not in analysis1:
                st.markdown(f"**ë…¼ì¡°**: {analysis1.get('ë…¼ì¡°ë¶„ë¥˜', 'N/A')} ({analysis1.get('ë…¼ì¡°ì ìˆ˜', 0)}ì )")
                st.markdown(f"**ì‹ ë¢°ë„**: {analysis1.get('ì‹ ë¢°ë„ì ìˆ˜', 0)}/10ì ")
                st.markdown(f"**ê°ê´€ì„±**: {analysis1.get('ê°ê´€ì„±ì ìˆ˜', 0)}/10ì ")
                
                if analysis1.get('ì£¼ìš”ë…¼ì '):
                    st.markdown("**ì£¼ìš” ë…¼ì **:")
                    for i, point in enumerate(analysis1.get('ì£¼ìš”ë…¼ì ', []), 1):
                        st.markdown(f"  {i}. {point}")
            else:
                st.error(analysis1.get("error", "ë¶„ì„ ì˜¤ë¥˜"))
    
    with col2:
        st.markdown("#### ê¸°ì‚¬ 2 ë¶„ì„")
        with st.expander("ìš”ì•½ (ì˜ì–´/í•œêµ­ì–´)", expanded=True):
            st.info(f"**[English]**\n{st.session_state.summary2}")
            st.success(f"**[í•œêµ­ì–´]**\n{st.session_state.summary2_kr}")
        
        with st.expander("ë…¼ì¡° ë¶„ì„", expanded=True):
            analysis2 = format_analysis_for_display(st.session_state.tone_analysis2, "analysis")
            if "error" not in analysis2:
                st.markdown(f"**ë…¼ì¡°**: {analysis2.get('ë…¼ì¡°ë¶„ë¥˜', 'N/A')} ({analysis2.get('ë…¼ì¡°ì ìˆ˜', 0)}ì )")
                st.markdown(f"**ì‹ ë¢°ë„**: {analysis2.get('ì‹ ë¢°ë„ì ìˆ˜', 0)}/10ì ")
                st.markdown(f"**ê°ê´€ì„±**: {analysis2.get('ê°ê´€ì„±ì ìˆ˜', 0)}/10ì ")
                
                if analysis2.get('ì£¼ìš”ë…¼ì '):
                    st.markdown("**ì£¼ìš” ë…¼ì **:")
                    for i, point in enumerate(analysis2.get('ì£¼ìš”ë…¼ì ', []), 1):
                        st.markdown(f"  {i}. {point}")
            else:
                st.error(analysis2.get("error", "ë¶„ì„ ì˜¤ë¥˜"))
    
    # ë…¼ì¡° ì‹œê°í™”
    st.markdown("---")
    create_enhanced_comparison_chart(st.session_state.tone_analysis1, st.session_state.tone_analysis2)
    
    # ê°ì •ì  ì–¸ì–´ ì‹œê°í™”
    st.markdown("---")
    display_emotional_words(st.session_state.tone_analysis1, st.session_state.tone_analysis2)
    
    # ì„±ì°° ì§ˆë¬¸
    st.markdown("---")
    st.markdown("#### ë¶„ì„ ì„±ì°°")
    reflection_error_placeholder = st.empty()
    reflection = st.text_area(
        "ë‘ ê¸°ì‚¬ì˜ ì°¨ì´ì ê³¼ ê³µí†µì , ê·¸ë¦¬ê³  ê°ê°ì˜ ë…¼ì¡°ì— ëŒ€í•œ ë‹¹ì‹ ì˜ ìƒê°ì„ ì ì–´ë³´ì„¸ìš”:",
        height=100,
        key="analysis_reflection"
    )
    
    col_btn1, col_btn2 = st.columns([1, 1])
    with col_btn1:
        if st.button("â† ì´ì „ ë‹¨ê³„", use_container_width=True):
            st.session_state.stage = "input"
            st.rerun()
    
    with col_btn2:
        if st.button("ì´ˆì•ˆ ì‘ì„± ë‹¨ê³„ë¡œ â†’", type="primary", use_container_width=True):
            if not reflection.strip():
                reflection_error_placeholder.error("ë¶„ì„ ì„±ì°° ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                reflection_error_placeholder.empty()
                st.session_state.reflection_log.append({
                    "stage": "analysis",
                    "content": reflection,
                    "timestamp": datetime.datetime.now()
                })
                st.session_state.stage = "draft"
                st.rerun()

# 3ë‹¨ê³„: ì´ˆì•ˆ ì‘ì„± (ë¬¸ë‹¨ë³„ í”¼ë“œë°± ê¸°ëŠ¥ ì¶”ê°€)
elif st.session_state.stage == "draft":
    st.subheader("3ë‹¨ê³„. ë¹„êµ ì„¤ëª…ë¬¸ ì´ˆì•ˆ ì‘ì„±")

    def paragraph_input_with_guide(title, key, guide_title, guide_lines, summary_text=None, hint_key=None, hint_prompt=None):
        col1, col2 = st.columns([2, 1])
        with col1:
            st.subheader(title)
            if key not in st.session_state:
                st.session_state[key] = ""
            
            error_key = f"{key}_error_placeholder"
            if error_key not in st.session_state:
                st.session_state[error_key] = st.empty()
            
            user_input = st.text_area("", key=key, height=160)
            
            # ë¬¸ë‹¨ë³„ ì™„ë£Œ ë²„íŠ¼ ë° í”¼ë“œë°±
            col1_1, col1_2 = st.columns([1, 1])
            with col1_1:
                if st.button(f"{title.split(' ')[0]} ì™„ë£Œ", key=f"{key}_complete"):
                    if user_input.strip():
                        context = {
                            "summary1": st.session_state.get("summary1"),
                            "summary2": st.session_state.get("summary2")
                        }
                        feedback = get_paragraph_feedback(user_input, title, context)
                        st.session_state.paragraph_feedback[key] = feedback
                        st.success("í”¼ë“œë°±ì„ í™•ì¸í•˜ì„¸ìš”!")
                    else:
                        st.error("ë¬¸ë‹¨ì„ ë¨¼ì € ì‘ì„±í•´ì£¼ì„¸ìš”.")
            
            with col1_2:
                if key in st.session_state.paragraph_feedback:
                    feedback = st.session_state.paragraph_feedback[key]
                    if "error" not in feedback:
                        score = feedback.get('ì¶”ì²œì ìˆ˜', 'N/A')
                        st.metric("ì¶”ì²œì ìˆ˜", f"{score}/4ì ")
            
            # ë¬¸ë‹¨ë³„ í”¼ë“œë°± í‘œì‹œ
            if key in st.session_state.paragraph_feedback:
                feedback = st.session_state.paragraph_feedback[key]
                if "error" not in feedback:
                    with st.expander("ë¬¸ë‹¨ë³„ í”¼ë“œë°±", expanded=True):
                        if feedback.get('ê°•ì '):
                            st.markdown("**ê°•ì :**")
                            for strength in feedback['ê°•ì ']:
                                st.markdown(f"- {strength}")
                        
                        if feedback.get('ê°œì„ ì '):
                            st.markdown("**ê°œì„ ì :**")
                            for improvement in feedback['ê°œì„ ì ']:
                                st.markdown(f"- {improvement}")
                        
                        if feedback.get('êµ¬ì²´ì ì œì•ˆ'):
                            st.markdown("**êµ¬ì²´ì  ì œì•ˆ:**")
                            st.info(feedback['êµ¬ì²´ì ì œì•ˆ'])
                else:
                    st.error(feedback.get("error", "í”¼ë“œë°± ì˜¤ë¥˜"))
        
        with col2:
            st.markdown(f"#### {guide_title}")
            for line in guide_lines:
                st.markdown(f"- {line}")
            
            if summary_text:
                st.markdown("#### ê´€ë ¨ ê¸°ì‚¬ ìš”ì•½")
                summary_en = summary_text
                summary_kr_key = "summary1_kr" if summary_en == st.session_state.get("summary1") else "summary2_kr"
                summary_kr = st.session_state.get(summary_kr_key, "ë²ˆì—­ ì—†ìŒ")
                
                with st.expander("ìš”ì•½ë¬¸ ë³´ê¸°", expanded=True):
                    st.info(f"**[English]**\n{summary_en}")
                    st.success(f"**[í•œêµ­ì–´]**\n{summary_kr}")

            if hint_key and hint_prompt and OPENAI_OK:
                if f"{hint_key}_hint" not in st.session_state:
                    st.session_state[f"{hint_key}_hint"] = ""
                if st.button(f"AI íŒíŠ¸ ë°›ê¸°", key=f"{hint_key}_btn"):
                    with st.spinner("AI íŒíŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                        try:
                            hint_response = client.chat.completions.create(
                                model="gpt-4o",
                                messages=[{"role": "user", "content": hint_prompt}],
                                temperature=0.5,
                                max_tokens=300
                            )
                            st.session_state[f"{hint_key}_hint"] = hint_response.choices[0].message.content.strip()
                        except Exception as e:
                            st.session_state[f"{hint_key}_hint"] = f"íŒíŠ¸ ìƒì„± ì‹¤íŒ¨: {e}"
                if st.session_state[f"{hint_key}_hint"]:
                    st.markdown("#### AI íŒíŠ¸")
                    st.success(st.session_state[f"{hint_key}_hint"])
        
        return user_input

    intro = paragraph_input_with_guide(
        "ì„œë¡ ", "intro_input", "ë¹„êµ ì£¼ì œ ì†Œê°œ", [
            "ë¹„êµí•  ë‘ ê¸°ì‚¬ ê°„ë‹¨íˆ ì†Œê°œ",
            "ê¸€ì˜ ëª©ì , ë¬¸ì œ ì œê¸°",
            "ë‘ ê´€ì  ê°„ ì°¨ì´ì— ëŒ€í•œ ì•”ì‹œ"
        ],
        hint_key="intro", hint_prompt="ë¹„êµ ì„¤ëª…ë¬¸ì˜ ì„œë¡ ì„ ì“°ê¸° ìœ„í•œ ë¬¸ì¥ êµ¬ì„± íŒíŠ¸ë¥¼ 3ê°œ ì œì‹œí•´ì¤˜. (í•œêµ­ì–´)"
    )

    body1 = paragraph_input_with_guide(
        "ë³¸ë¡  - ê¸°ì‚¬ 1 ì„¤ëª…", "body1_input", "ê¸°ì‚¬ 1 ìš”ì•½", [
            "ê¸°ì‚¬ 1ì˜ ì£¼ì¥ê³¼ ê·¼ê±° ìš”ì•½",
            "ìë£Œ, ì‚¬ë¡€, ê°•ì¡°ì  ê¸°ìˆ "
        ],
        summary_text=st.session_state.get("summary1"),
        hint_key="body1", hint_prompt="ì²« ë²ˆì§¸ ê¸°ì‚¬ ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” ë¬¸ë‹¨ ì‘ì„±ì— ì“¸ ìˆ˜ ìˆëŠ” ë¬¸ì¥ ì˜ˆì‹œ 3ê°œë¥¼ ì œì‹œí•´ì¤˜. (í•œêµ­ì–´)"
    )

    body2 = paragraph_input_with_guide(
        "ë³¸ë¡  - ê¸°ì‚¬ 2 ì„¤ëª…", "body2_input", "ê¸°ì‚¬ 2 ìš”ì•½", [
            "ê¸°ì‚¬ 2ì˜ ì£¼ìš” ë‚´ìš© ìš”ì•½",
            "ê¸°ì‚¬ 1ê³¼ ë¹„êµí–ˆì„ ë•Œì˜ íŠ¹ì§• ì–¸ê¸‰"
        ],
        summary_text=st.session_state.get("summary2"),
        hint_key="body2", hint_prompt="ë‘ ë²ˆì§¸ ê¸°ì‚¬ ë‚´ìš©ì„ ìš”ì•½í•˜ë©° ë¹„êµí•˜ëŠ” ë¬¸ë‹¨ì„ ì“°ê¸° ìœ„í•œ ë¬¸ì¥ ì˜ˆì‹œ 3ê°œë¥¼ ì œì‹œí•´ì¤˜. (í•œêµ­ì–´)"
    )

    compare = paragraph_input_with_guide(
        "ë¹„êµ ë¶„ì„", "compare_input", "ê³µí†µì ê³¼ ì°¨ì´ì ", [
            "ê¸°ì¤€(ê´€ì , ëª©ì  ë“±)ì„ ì„¤ì •í•´ ë¹„êµ",
            "ë…¼ë¦¬ì ìœ¼ë¡œ ìœ ì‚¬ì Â·ì°¨ì´ì  ì œì‹œ"
        ],
        hint_key="compare", hint_prompt="ë‘ ê¸°ì‚¬ ê°„ ê³µí†µì ê³¼ ì°¨ì´ì ì„ ë¹„êµí•˜ì—¬ ë¶„ì„í•˜ëŠ” ë¬¸ë‹¨ì„ ìœ„í•œ ë¬¸ì¥ êµ¬ì„± íŒíŠ¸ë¥¼ ì œì‹œí•´ì¤˜. (í•œêµ­ì–´)"
    )

    conclusion = paragraph_input_with_guide(
        "ê²°ë¡ ", "conclusion_input", "ìš”ì•½ ë° ì˜ê²¬", [
            "ì „ì²´ ë¹„êµ ë‚´ìš© ìš”ì•½",
            "ìì‹ ì˜ ì˜ê²¬ì´ë‚˜ í‰ê°€ í¬í•¨"
        ],
        hint_key="conclusion", hint_prompt="ë¹„êµ ì„¤ëª…ë¬¸ ê²°ë¡ ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë§ˆë¬´ë¦¬ ë¬¸ì¥ 3ê°œë¥¼ ì œì•ˆí•´ì¤˜. (í•œêµ­ì–´)"
    )

    st.markdown("---")
    st.markdown("### ì „ì²´ ì´ˆì•ˆ ë¯¸ë¦¬ë³´ê¸°")

    full_draft = "\n\n".join([
        f"[ì„œë¡ ]\n{intro}",
        f"[ë³¸ë¡  1 - ê¸°ì‚¬ 1]\n{body1}",
        f"[ë³¸ë¡  2 - ê¸°ì‚¬ 2]\n{body2}",
        f"[ë¹„êµ ë¶„ì„]\n{compare}",
        f"[ê²°ë¡ ]\n{conclusion}"
    ])

    st.session_state.draft = full_draft

    st.markdown(f"""<div style="background-color:#f9f9f9; padding:15px; border-radius:10px; color:black; font-size:16px;">
<pre style="white-space: pre-wrap; word-wrap: break-word;">{full_draft}</pre>
</div>""", unsafe_allow_html=True)

    # ë¬¸ë‹¨ë³„ í”¼ë“œë°± ìš”ì•½
    if st.session_state.paragraph_feedback:
        st.markdown("---")
        st.markdown("### ë¬¸ë‹¨ë³„ í”¼ë“œë°± ìš”ì•½")
        summary_text = summarize_paragraph_feedback(st.session_state.paragraph_feedback)
        st.info(summary_text)

    col_btn1, col_btn2 = st.columns([1, 1])
    with col_btn1:
        if st.button("â† ì´ì „ ë‹¨ê³„", use_container_width=True):
            st.session_state.stage = "analysis"
            st.rerun()

    with col_btn2:
        overall_draft_error = st.empty()
        if st.button("AI í”¼ë“œë°± ë°›ê¸° â†’", type="primary", use_container_width=True):
            paragraphs = [
                (intro, "intro_input", "ì„œë¡ "),
                (body1, "body1_input", "ë³¸ë¡  1"),
                (body2, "body2_input", "ë³¸ë¡  2"),
                (compare, "compare_input", "ë¹„êµ ë¶„ì„"),
                (conclusion, "conclusion_input", "ê²°ë¡ ")
            ]
            
            is_valid = True
            for content, key, title in paragraphs:
                error_key = f"{key}_error_placeholder"
                if not content.strip():
                    if error_key in st.session_state:
                        st.session_state[error_key].error(f"{title} ë¶€ë¶„ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.")
                    is_valid = False
                else:
                    if error_key in st.session_state:
                        st.session_state[error_key].empty()
            
            if is_valid:
                overall_draft_error.empty()
                st.session_state.stage = "feedback"
                st.rerun()
            else:
                overall_draft_error.error("ëª¨ë“  ë¬¸ë‹¨ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.")

# 4ë‹¨ê³„: ìê¸°í‰ê°€ ë° í–¥ìƒëœ AI í”¼ë“œë°±
elif st.session_state.stage == "feedback":
    st.subheader("4ë‹¨ê³„. ìê¸°í‰ê°€ ë° AI í”¼ë“œë°±")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("**ë‚´ ì´ˆì•ˆ**")
        st.text_area(
            "ì‘ì„±í•œ ì´ˆì•ˆ",
            value=st.session_state.draft,
            height=400,
            disabled=True,
            key="draft_display_feedback"
        )
    
    with col2:
        # ìê¸°í‰ê°€ê°€ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ìê¸°í‰ê°€ ì¸í„°í˜ì´ìŠ¤ í‘œì‹œ
        if not st.session_state.self_assessment:
            st.markdown("**1ë‹¨ê³„: ìê¸°í‰ê°€**")
            self_assessment_data = self_assessment_interface()
            
            # ìê¸°í‰ê°€ ì™„ë£Œ ë²„íŠ¼
            if st.button("ìê¸°í‰ê°€ ì™„ë£Œ â†’ AI í”¼ë“œë°± ë°›ê¸°", type="primary"):
                # ëª¨ë“  í•„ë“œê°€ ì±„ì›Œì¡ŒëŠ”ì§€ í™•ì¸ (ê°œì„ ëœ ë¡œì§)
                errors = []
                for category in ["ë‚´ìš©ë…¼ë¦¬ì„±", "êµ¬ì„±ì²´ê³„ì„±", "ë¬¸ë²•ì–´íœ˜ì •í™•ì„±"]:
                    if not self_assessment_data["reflections"][category].strip():
                        errors.append(f"{category} í‰ê°€ ì´ìœ ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.")
                
                if not self_assessment_data["overall_reflection"].strip():
                    errors.append("ì „ì²´ì ì¸ ìê¸° ì„±ì°°ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.")

                if errors:
                    for error in errors:
                        st.error(error)
                else:
                    st.session_state.self_assessment = self_assessment_data
                    st.rerun()
        else:
            # ìê¸°í‰ê°€ê°€ ì™„ë£Œë˜ë©´ AI í”¼ë“œë°± í‘œì‹œ
            st.markdown("**2ë‹¨ê³„: AI í”¼ë“œë°±**")
            
            # AI í”¼ë“œë°± ìƒì„± (í•œ ë²ˆë§Œ)
            if not st.session_state.enhanced_feedback:
                if OPENAI_OK:
                    with st.spinner("ìê¸°í‰ê°€ë¥¼ ë°˜ì˜í•œ ë§ì¶¤í˜• í”¼ë“œë°±ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        enhanced_feedback = enhanced_gpt_feedback(
                            st.session_state.draft, 
                            st.session_state.self_assessment,
                            st.session_state.paragraph_feedback
                        )
                        st.session_state.enhanced_feedback = enhanced_feedback
                        
                        # ê¸°ì¡´ ë£¨ë¸Œë¦­ í‰ê°€ë„ ì‹¤í–‰
                        english_draft = translate_to_english(st.session_state.draft)
                        st.session_state.writing_evaluation = evaluate_writing_rubric(english_draft)
                else:
                    st.session_state.enhanced_feedback = "AI í”¼ë“œë°± ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
            
            # íƒ­ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ í‘œì‹œ
            tab1, tab2, tab3 = st.tabs(["ë§ì¶¤í˜• í”¼ë“œë°±", "ë£¨ë¸Œë¦­ í‰ê°€", "ìê¸°í‰ê°€ ê²°ê³¼"])
            
            with tab1:
                st.text_area(
                    "ìê¸°í‰ê°€ ê¸°ë°˜ ë§ì¶¤í˜• í”¼ë“œë°±",
                    value=st.session_state.enhanced_feedback,
                    height=400,
                    disabled=True
                )
            
            with tab2:
                st.markdown("#### ì˜ì–´ í‘œí˜„ ëŠ¥ë ¥ í‰ê°€")
                eval_data = format_analysis_for_display(st.session_state.writing_evaluation, "evaluation")
                
                if "error" not in eval_data:
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        if "ë‚´ìš©ë…¼ë¦¬ì„±" in eval_data and isinstance(eval_data["ë‚´ìš©ë…¼ë¦¬ì„±"], dict):
                            logic = eval_data["ë‚´ìš©ë…¼ë¦¬ì„±"]
                            st.metric("ë‚´ìš© ë…¼ë¦¬ì„±", f"{logic.get('ì ìˆ˜', 0)}/4ì ")
                            st.caption(logic.get('ê·¼ê±°', ''))
                        else:
                            st.metric("ë‚´ìš© ë…¼ë¦¬ì„±", "N/A")
                    
                    with col2:
                        if "êµ¬ì„±ì²´ê³„ì„±" in eval_data and isinstance(eval_data["êµ¬ì„±ì²´ê³„ì„±"], dict):
                            org = eval_data["êµ¬ì„±ì²´ê³„ì„±"]
                            st.metric("êµ¬ì„± ì²´ê³„ì„±", f"{org.get('ì ìˆ˜', 0)}/4ì ")
                            st.caption(org.get('ê·¼ê±°', ''))
                        else:
                            st.metric("êµ¬ì„± ì²´ê³„ì„±", "N/A")
                    
                    with col3:
                        if "ë¬¸ë²•ì–´íœ˜ì •í™•ì„±" in eval_data and isinstance(eval_data["ë¬¸ë²•ì–´íœ˜ì •í™•ì„±"], dict):
                            lang = eval_data["ë¬¸ë²•ì–´íœ˜ì •í™•ì„±"]
                            st.metric("ë¬¸ë²•Â·ì–´íœ˜", f"{lang.get('ì ìˆ˜', 0)}/4ì ")
                            st.caption(lang.get('ê·¼ê±°', ''))
                        else:
                            st.metric("ë¬¸ë²•Â·ì–´íœ˜", "N/A")
                    
                    if eval_data.get('ì´ì '):
                        st.markdown(f"**ì´ì **: {eval_data['ì´ì ']}")
                    
                    if eval_data.get('ì¢…í•©í‰ê°€'):
                        st.markdown("**ì¢…í•© í‰ê°€**")
                        st.info(eval_data['ì¢…í•©í‰ê°€'])
                else:
                    st.error(eval_data.get("error", "í‰ê°€ ì˜¤ë¥˜"))
            
            with tab3:
                st.markdown("#### ë‚˜ì˜ ìê¸°í‰ê°€ ê²°ê³¼")
                for category, score in st.session_state.self_assessment["scores"].items():
                    st.markdown(f"**{category}**: {score}ì ")
                    st.caption(st.session_state.self_assessment["reflections"][category])
                st.markdown("**ì „ì²´ ì„±ì°°**")
                st.info(st.session_state.self_assessment["overall_reflection"])
    
    st.markdown("---")
    st.markdown("#### í”¼ë“œë°± ì„±ì°°")
    feedback_reflection_error = st.empty()
    feedback_reflection = st.text_area(
        "AI í”¼ë“œë°±ì„ ë°›ì€ í›„ ëŠë‚€ ì ê³¼ ê°œì„ í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì„ ì ì–´ë³´ì„¸ìš”:",
        height=100,
        key="feedback_reflection"
    )
    
    col_btn1, col_btn2 = st.columns([1, 1])
    with col_btn1:
        if st.button("â† ì´ì „ ë‹¨ê³„", use_container_width=True):
            st.session_state.stage = "draft"
            st.rerun()
    
    with col_btn2:
        if st.button("ìµœì¢… ìˆ˜ì • ë‹¨ê³„ë¡œ â†’", type="primary", use_container_width=True):
            if not feedback_reflection.strip():
                feedback_reflection_error.error("í”¼ë“œë°± ì„±ì°° ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                feedback_reflection_error.empty()
                st.session_state.reflection_log.append({
                    "stage": "feedback",
                    "content": feedback_reflection,
                    "timestamp": datetime.datetime.now()
                })
                # ë¬¸ì œí•´ê²° ì—­ëŸ‰ í‰ê°€ ìˆ˜í–‰
                st.session_state.problem_solving_score = assess_problem_solving(feedback_reflection)
                st.session_state.stage = "final"
                st.rerun()

# 5ë‹¨ê³„: ìµœì¢… ì™„ì„±
elif st.session_state.stage == "final":
    st.subheader("5ë‹¨ê³„. ìµœì¢… ìˆ˜ì • ë° ì™„ì„±")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("**ìµœì¢… ìˆ˜ì •**")
        if "final_text" not in st.session_state or not st.session_state.final_text:
             st.session_state.final_text = st.session_state.draft
             
        final_text = st.text_area(
            "í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ìµœì¢… ìˆ˜ì •í•˜ì„¸ìš”",
            value=st.session_state.final_text,
            height=400,
            key="final_input"
        )
        
        st.session_state.final_text = final_text
    
    with col2:
        st.markdown("**ì¢…í•© í‰ê°€ ê²°ê³¼**")
        
        # ë¬¸ì œí•´ê²° ì—­ëŸ‰ í‰ê°€ ê²°ê³¼
        if st.session_state.problem_solving_score:
            with st.expander("ë¬¸ì œí•´ê²° ì—­ëŸ‰ í‰ê°€", expanded=True):
                problem_data = format_analysis_for_display(st.session_state.problem_solving_score, "assessment")
                
                if "error" not in problem_data:
                    # assessment í‚¤ê°€ ìˆëŠ” ê²½ìš° (ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì‘ë‹µ)
                    if "assessment" in problem_data:
                        st.info(problem_data["assessment"])
                    else:
                        # 4ê°œ ì˜ì—­ì„ 2x2 ê·¸ë¦¬ë“œë¡œ ë°°ì¹˜
                        col1, col2 = st.columns(2)
                        
                        areas = ["ë¬¸ì œì´í•´", "ë¶„ì„ì ì‚¬ê³ ", "ëŒ€ì•ˆë°œê²¬ë°ê¸°íš", "ì˜ì‚¬ì†Œí†µ"]
                        for i, area in enumerate(areas):
                            col = col1 if i % 2 == 0 else col2
                            with col:
                                if area in problem_data and isinstance(problem_data[area], dict):
                                    score = problem_data[area].get('ì ìˆ˜', 0)
                                    st.metric(area.replace('ë°', ' & '), f"{score}/5ì ")
                                elif area in problem_data:
                                    st.metric(area.replace('ë°', ' & '), str(problem_data[area]))
                        
                        if problem_data.get('ì´ì '):
                            st.markdown(f"**ì´ì **: {problem_data['ì´ì ']}")
                        
                        if problem_data.get('ì¢…í•©í‰ê°€'):
                            st.markdown("**ì¢…í•© í‰ê°€**")
                            st.info(problem_data['ì¢…í•©í‰ê°€'])
                else:
                    st.error(problem_data.get("error", "í‰ê°€ ì˜¤ë¥˜"))
        
        # ì˜ì–´ í‘œí˜„ ëŠ¥ë ¥ í‰ê°€ ê²°ê³¼
        if st.session_state.writing_evaluation:
            with st.expander("ì˜ì–´ í‘œí˜„ ëŠ¥ë ¥ í‰ê°€", expanded=True):
                eval_data = format_analysis_for_display(st.session_state.writing_evaluation, "evaluation")
                
                if "error" not in eval_data:
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        if "ë‚´ìš©ë…¼ë¦¬ì„±" in eval_data and isinstance(eval_data["ë‚´ìš©ë…¼ë¦¬ì„±"], dict):
                            logic = eval_data["ë‚´ìš©ë…¼ë¦¬ì„±"]
                            score = logic.get('ì ìˆ˜', 0)
                            st.metric("ë‚´ìš© ë…¼ë¦¬ì„±", f"{score}/4ì ")
                        else:
                            st.metric("ë‚´ìš© ë…¼ë¦¬ì„±", "N/A")
                    
                    with col2:
                        if "êµ¬ì„±ì²´ê³„ì„±" in eval_data and isinstance(eval_data["êµ¬ì„±ì²´ê³„ì„±"], dict):
                            org = eval_data["êµ¬ì„±ì²´ê³„ì„±"]
                            score = org.get('ì ìˆ˜', 0)
                            st.metric("êµ¬ì„± ì²´ê³„ì„±", f"{score}/4ì ")
                        else:
                            st.metric("êµ¬ì„± ì²´ê³„ì„±", "N/A")
                    
                    with col3:
                        if "ë¬¸ë²•ì–´íœ˜ì •í™•ì„±" in eval_data and isinstance(eval_data["ë¬¸ë²•ì–´íœ˜ì •í™•ì„±"], dict):
                            lang = eval_data["ë¬¸ë²•ì–´íœ˜ì •í™•ì„±"]
                            score = lang.get('ì ìˆ˜', 0)
                            st.metric("ë¬¸ë²•Â·ì–´íœ˜", f"{score}/4ì ")
                        else:
                            st.metric("ë¬¸ë²•Â·ì–´íœ˜", "N/A")
                else:
                    st.error(eval_data.get("error", "í‰ê°€ ì˜¤ë¥˜"))
    
    st.markdown("---")
    
    col_btn1, col_btn2, col_btn3, col_btn4 = st.columns([1, 1, 1, 1])
    
    with col_btn1:
        if st.button("â† ì´ì „ ë‹¨ê³„", use_container_width=True):
            st.session_state.stage = "feedback"
            st.rerun()

    with col_btn2:
        # ì¢…í•© ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ (ë¬¸ë‹¨ë³„ í”¼ë“œë°± í¬í•¨)
        analysis_summary = {
            "ë…¼ì¡°ë¶„ì„1": st.session_state.tone_analysis1,
            "ë…¼ì¡°ë¶„ì„2": st.session_state.tone_analysis2,
            "ì˜ì–´í‘œí˜„í‰ê°€": st.session_state.writing_evaluation,
            "ë¬¸ì œí•´ê²°í‰ê°€": st.session_state.problem_solving_score,
            "ë¬¸ë‹¨ë³„í”¼ë“œë°±": summarize_paragraph_feedback(st.session_state.paragraph_feedback)
        }
        docx_data = create_docx_content(final_text, analysis_summary)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"news_comparison_complete_{timestamp}.docx"
        st.download_button(
            label="ì¢…í•© ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
            data=docx_data,
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            use_container_width=True,
            disabled=not final_text.strip()
        )

    with col_btn4:
        if st.button("ì²˜ìŒë¶€í„° ë‹¤ì‹œ", use_container_width=True):
            # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            for key in list(st.session_state.keys()):
                if key != 'stage':
                    st.session_state.pop(key)
            st.session_state.stage = "input"
            st.rerun()
    
    # ì™„ì„±ëœ ì‘ë¬¸ ë¯¸ë¦¬ë³´ê¸°
    if final_text.strip():
        st.markdown("### ì™„ì„±ëœ ì‘ë¬¸ ë¯¸ë¦¬ë³´ê¸°")
        st.success(final_text)
        
        # í•™ìŠµ ì„±ì°° ë¡œê·¸ í‘œì‹œ
        if st.session_state.reflection_log:
            with st.expander("í•™ìŠµ ì„±ì°° ê¸°ë¡", expanded=False):
                for idx, log in enumerate(st.session_state.reflection_log):
                    st.markdown(f"**{log['stage']} ë‹¨ê³„ ì„±ì°°:**")
                    st.write(log['content'])
                    st.caption(f"ì‘ì„± ì‹œê°„: {log['timestamp']}")
                    st.markdown("---")

# ì‚¬ì´ë“œë°” ì •ë³´
with st.sidebar:
    st.markdown("### ì‚¬ìš© ë°©ë²•")
    st.markdown("""
    1. **ê¸°ì‚¬ ì…ë ¥**: ë¹„êµí•  ë‘ ê¸°ì‚¬ì˜ ë³¸ë¬¸ì„ ì…ë ¥
    2. **ë…¼ì¡° ë¶„ì„**: AIê°€ ê° ê¸°ì‚¬ì˜ ë…¼ì¡°ì™€ ì…ì¥ì„ ë¶„ì„
    3. **ì´ˆì•ˆ ì‘ì„±**: ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ë¹„êµ ì„¤ëª…ë¬¸ ì‘ì„±
       - ê° ë¬¸ë‹¨ ì™„ë£Œ ì‹œ ì¦‰ì‹œ í”¼ë“œë°± ê°€ëŠ¥
    4. **ìê¸°í‰ê°€ + AI í”¼ë“œë°±**: ë£¨ë¸Œë¦­ ê¸°ë°˜ ìê¸°í‰ê°€ í›„ ë§ì¶¤í˜• AI í”¼ë“œë°±
    5. **ìµœì¢… ì™„ì„±**: í”¼ë“œë°±ì„ ë°˜ì˜í•œ ìˆ˜ì • í›„ ì¢…í•© ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ
    """)
    
    st.markdown("### ì„¤ì • ìƒíƒœ")
    if OPENAI_OK:
        st.success("OpenAI API ì—°ê²°ë¨")
    else:
        st.error("OpenAI API ì—°ê²° ì‹¤íŒ¨")
    
    st.markdown("### ì§„í–‰ ìƒí™©")
    st.markdown(f"í˜„ì¬ ë‹¨ê³„: **{stage_names[current_stage_idx]}**")
    
    # ì§„í–‰ ìƒí™© ì²´í¬ë¦¬ìŠ¤íŠ¸
    checklist_items = [
        ("ê¸°ì‚¬ ì…ë ¥", bool(st.session_state.get("article1") and st.session_state.get("article2"))),
        ("ë…¼ì¡° ë¶„ì„", bool(st.session_state.get("tone_analysis1") and st.session_state.get("tone_analysis2"))),
        ("ì´ˆì•ˆ ì‘ì„±", bool(st.session_state.get("draft"))),
        ("ë¬¸ë‹¨ë³„ í”¼ë“œë°±", bool(st.session_state.get("paragraph_feedback"))),
        ("ìê¸°í‰ê°€", bool(st.session_state.get("self_assessment"))),
        ("AI í”¼ë“œë°±", bool(st.session_state.get("enhanced_feedback"))),
        ("ë£¨ë¸Œë¦­ í‰ê°€", bool(st.session_state.get("writing_evaluation"))),
        ("ìµœì¢… ì™„ì„±", bool(st.session_state.get("final_text")))
    ]
    
    for item, completed in checklist_items:
        icon = "ì™„ë£Œ" if completed else "ëŒ€ê¸°"
        st.markdown(f"**{icon}**: {item}")