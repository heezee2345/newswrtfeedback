import os
import datetime
import streamlit as st
from openai import OpenAI, APIError
from docx import Document
import tempfile
import json
import pandas as pd
import re

# â”€â”€â”€â”€â”€ í™˜ê²½ ì„¤ì • â”€â”€â”€â”€â”€
try:
    OPENAI_KEY = st.secrets["openai"]["api_key"]
except KeyError:
    OPENAI_KEY = ""

OPENAI_OK = bool(OPENAI_KEY)

client = None
if OPENAI_OK:
    try:
        client = OpenAI(api_key=OPENAI_KEY)
    except Exception as e:
        st.error(f"OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        OPENAI_OK = False

# â”€â”€â”€â”€â”€ ìƒˆë¡œìš´ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì¶”ê°€ â”€â”€â”€â”€â”€
def parse_gpt_json_response(response_text: str) -> dict:
    """GPT ì‘ë‹µì—ì„œ JSON ë¸”ë¡ì„ ì¶”ì¶œí•˜ê³  íŒŒì‹±"""
    try:
        # ```json ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ
        if "```json" in response_text:
            # ```jsonê³¼ ``` ì‚¬ì´ì˜ ë‚´ìš© ì¶”ì¶œ
            json_match = re.search(r'```json\s*\n(.*?)\n```', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1).strip()
            else:
                # ë‹¤ë¥¸ íŒ¨í„´ ì‹œë„
                json_str = response_text.replace('```json\n', '').replace('\n```', '').strip()
        else:
            json_str = response_text.strip()
        
        # JSON íŒŒì‹± ì‹œë„
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ì˜¤ë¥˜ ì •ë³´ ë°˜í™˜
        return {
            "error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}",
            "raw_response": response_text
        }
    except Exception as e:
        return {
            "error": f"ì‘ë‹µ ì²˜ë¦¬ ì‹¤íŒ¨: {e}",
            "raw_response": response_text
        }

def format_analysis_for_display(analysis_data: dict, analysis_type: str = "analysis") -> dict:
    """ë¶„ì„ ë°ì´í„°ë¥¼ í‘œì‹œìš©ìœ¼ë¡œ í¬ë§·íŒ…"""
    if not analysis_data:
        return {"error": "ë°ì´í„° ì—†ìŒ"}
    
    # ì´ë¯¸ íŒŒì‹±ëœ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
    if isinstance(analysis_data, dict) and "error" not in analysis_data:
        return analysis_data
    
    # analysis í‚¤ì— JSON ë¬¸ìì—´ì´ ìˆëŠ” ê²½ìš°
    if isinstance(analysis_data, dict) and analysis_type in analysis_data:
        return parse_gpt_json_response(analysis_data[analysis_type])
    
    # ê¸°íƒ€ ê²½ìš°
    return analysis_data

def format_for_docx(data: dict, title: str) -> str:
    """docxìš© ê°€ë…ì„± ìˆëŠ” í…ìŠ¤íŠ¸ í¬ë§·íŒ…"""
    if not isinstance(data, dict):
        return f"{title}: {str(data)}"
    
    if "error" in data:
        return f"{title}: ì˜¤ë¥˜ - {data['error']}"
    
    formatted_text = f"{title}:\n"
    
    # ë…¼ì¡° ë¶„ì„ ë°ì´í„° í¬ë§·íŒ…
    if "ë…¼ì¡°ë¶„ë¥˜" in data:
        formatted_text += f"  â€¢ ë…¼ì¡°ë¶„ë¥˜: {data.get('ë…¼ì¡°ë¶„ë¥˜', 'N/A')}\n"
        formatted_text += f"  â€¢ ë…¼ì¡°ì ìˆ˜: {data.get('ë…¼ì¡°ì ìˆ˜', 'N/A')}\n"
        formatted_text += f"  â€¢ ì‹ ë¢°ë„ì ìˆ˜: {data.get('ì‹ ë¢°ë„ì ìˆ˜', 'N/A')}/10\n"
        formatted_text += f"  â€¢ ê°ê´€ì„±ì ìˆ˜: {data.get('ê°ê´€ì„±ì ìˆ˜', 'N/A')}/10\n"
        
        if data.get('ì£¼ìš”ë…¼ì '):
            formatted_text += "  â€¢ ì£¼ìš”ë…¼ì :\n"
            for i, point in enumerate(data['ì£¼ìš”ë…¼ì '], 1):
                formatted_text += f"    {i}. {point}\n"
        
        if data.get('ê°ì •ì ì–¸ì–´'):
            formatted_text += f"  â€¢ ê°ì •ì ì–¸ì–´: {', '.join(data['ê°ì •ì ì–¸ì–´'])}\n"
    
    # ì˜ì–´ í‘œí˜„ í‰ê°€ ë°ì´í„° í¬ë§·íŒ…
    elif "ë‚´ìš©ë…¼ë¦¬ì„±" in data:
        for key in ["ë‚´ìš©ë…¼ë¦¬ì„±", "êµ¬ì„±ì²´ê³„ì„±", "ë¬¸ë²•ì–´íœ˜ì •í™•ì„±"]:
            if key in data and isinstance(data[key], dict):
                formatted_text += f"  â€¢ {key}: {data[key].get('ì ìˆ˜', 'N/A')}/4ì \n"
                formatted_text += f"    ê·¼ê±°: {data[key].get('ê·¼ê±°', 'N/A')}\n"
        
        if data.get('ì´ì '):
            formatted_text += f"  â€¢ ì´ì : {data['ì´ì ']}\n"
        if data.get('ì¢…í•©í‰ê°€'):
            formatted_text += f"  â€¢ ì¢…í•©í‰ê°€: {data['ì¢…í•©í‰ê°€']}\n"
    
    # ë¬¸ì œí•´ê²° í‰ê°€ ë°ì´í„° í¬ë§·íŒ…
    elif any(key in data for key in ["ë¬¸ì œì´í•´", "ë¶„ì„ì ì‚¬ê³ ", "ëŒ€ì•ˆë°œê²¬ë°ê¸°íš", "ì˜ì‚¬ì†Œí†µ"]):
        for key in ["ë¬¸ì œì´í•´", "ë¶„ì„ì ì‚¬ê³ ", "ëŒ€ì•ˆë°œê²¬ë°ê¸°íš", "ì˜ì‚¬ì†Œí†µ"]:
            if key in data:
                if isinstance(data[key], dict):
                    formatted_text += f"  â€¢ {key}: {data[key].get('ì ìˆ˜', 'N/A')}/5ì \n"
                    if 'ê°œì„ ì œì•ˆ' in data[key]:
                        formatted_text += f"    ê°œì„ ì œì•ˆ: {data[key]['ê°œì„ ì œì•ˆ']}\n"
                else:
                    formatted_text += f"  â€¢ {key}: {data[key]}\n"
    
    # ê¸°íƒ€ ë°ì´í„°
    else:
        for key, value in data.items():
            if key not in ["error", "raw_response"]:
                formatted_text += f"  â€¢ {key}: {value}\n"
    
    return formatted_text

# â”€â”€â”€â”€â”€ ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ìˆ˜ì •ë¨) â”€â”€â”€â”€â”€
def summarize_text(text: str) -> str:
    """ê¸°ì‚¬ ë‚´ìš©ì„ ì˜ì–´ë¡œ 5-10ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½"""
    if not OPENAI_OK or client is None:
        return "ìš”ì•½ ë¶ˆê°€: API ì˜¤ë¥˜"
    if not text.strip():
        return "ìš”ì•½ ë¶ˆê°€: ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    prompt = f"ë‹¤ìŒ ê¸°ì‚¬ ë‚´ìš©ì„ ì˜ì–´ë¡œ ë‹¤ì„¯ ë¬¸ì¥ ì´ìƒ, ì—´ë¬¸ì¥ ì´í•˜ë¡œ ìš”ì•½í•´ì¤˜:\n\n{text}"
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=800
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"ìš”ì•½ ì‹¤íŒ¨: {e}"

def analyze_tone_and_stance(text: str) -> dict:
    """ë…¼ì¡° ë° ì…ì¥ ë¶„ì„ - ì ìˆ˜í™”ëœ ë…¼ì¡° í¬í•¨ (ìˆ˜ì •ë¨)"""
    if not OPENAI_OK or client is None:
        return {"error": "API ì˜¤ë¥˜"}
    
    prompt = f"""
    ë‹¤ìŒ ê¸°ì‚¬ì˜ ë…¼ì¡°ì™€ ì…ì¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
    
    ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•˜ê³ , ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”:
    
    {{
        "ë…¼ì¡°ë¶„ë¥˜": "positive/neutral/negative",
        "ë…¼ì¡°ì ìˆ˜": -3~3 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
        "ì£¼ìš”ë…¼ì ": ["ë…¼ì 1", "ë…¼ì 2", "ë…¼ì 3"],
        "ê°ì •ì ì–¸ì–´": ["ì˜ˆì‹œ1", "ì˜ˆì‹œ2", "ì˜ˆì‹œ3"],
        "ì‹ ë¢°ë„ì ìˆ˜": 1~10 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
        "ê°ê´€ì„±ì ìˆ˜": 1~10 ì‚¬ì´ì˜ ì •ìˆ˜ê°’
    }}
    
    ê¸°ì‚¬: {text}
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=600
        )
        
        result = response.choices[0].message.content.strip()
        return parse_gpt_json_response(result)
    except Exception as e:
        return {"error": f"ë¶„ì„ ì‹¤íŒ¨: {e}"}

def evaluate_writing_rubric(text: str) -> dict:
    """ì˜ì–´ í‘œí˜„ ëŠ¥ë ¥ ë£¨ë¸Œë¦­ í‰ê°€ (ìˆ˜ì •ë¨)"""
    if not OPENAI_OK or client is None:
        return {"error": "API ì˜¤ë¥˜"}
    
    prompt = f"""
    ë‹¤ìŒ ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì²´ì ì¸ ë£¨ë¸Œë¦­ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.

    **í‰ê°€ ì˜ì—­ ë° ê¸°ì¤€:**

    **1. ë‚´ìš© ë…¼ë¦¬ì„± (Content Logic) - 1~4ì **
    **2. êµ¬ì„± ì²´ê³„ì„± (Organization) - 1~4ì **
    **3. ë¬¸ë²•Â·ì–´íœ˜ ì •í™•ì„± (Language Accuracy) - 1~4ì **

    ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•˜ê³ , ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”:

    {{
        "ë‚´ìš©ë…¼ë¦¬ì„±": {{
            "ì ìˆ˜": 1~4 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê·¼ê±°": "êµ¬ì²´ì  í‰ê°€ ê·¼ê±°"
        }},
        "êµ¬ì„±ì²´ê³„ì„±": {{
            "ì ìˆ˜": 1~4 ì‚¬ì´ì˜ ì •ìˆ˜ê°’, 
            "ê·¼ê±°": "êµ¬ì²´ì  í‰ê°€ ê·¼ê±°"
        }},
        "ë¬¸ë²•ì–´íœ˜ì •í™•ì„±": {{
            "ì ìˆ˜": 1~4 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê·¼ê±°": "êµ¬ì²´ì  í‰ê°€ ê·¼ê±°"
        }},
        "ì´ì ": "12ì  ë§Œì  ì¤‘ Xì ",
        "ì¢…í•©í‰ê°€": "ì „ì²´ì ì¸ í‰ê°€ ë° ê°œì„  ì œì•ˆ"
    }}

    í‰ê°€ ëŒ€ìƒ í…ìŠ¤íŠ¸: {text}
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=800
        )
        
        result = response.choices[0].message.content.strip()
        return parse_gpt_json_response(result)
    except Exception as e:
        return {"error": f"í‰ê°€ ì‹¤íŒ¨: {e}"}

def assess_problem_solving(reflection_text: str) -> dict:
    """ë¬¸ì œí•´ê²° ì—­ëŸ‰ í‰ê°€ (ìˆ˜ì •ë¨)"""
    if not OPENAI_OK or client is None:
        return {"error": "API ì˜¤ë¥˜"}
    
    # ì„±ì°° ë‚´ìš©ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ì˜ë¯¸ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
    if not reflection_text or len(reflection_text.strip()) < 10:
        return {
            "assessment": f"ì„±ì°° ë‚´ìš©ì´ \"{reflection_text}\"ë¼ëŠ” í•œ ë‹¨ì–´ë¡œë§Œ ì œê³µë˜ì–´ ìˆì–´, í•™ìŠµìì˜ ë¬¸ì œí•´ê²° ì—­ëŸ‰ì„ í‰ê°€í•˜ê¸°ì—ëŠ” ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì„±ì°° ë‚´ìš©ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í•™ìŠµìê°€ ì–´ë–¤ ë¬¸ì œë¥¼ ë‹¤ë£¨ì—ˆëŠ”ì§€, ê·¸ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ ì´í•´í•˜ê³  ë¶„ì„í–ˆëŠ”ì§€, ì–´ë–¤ ëŒ€ì•ˆì„ ë°œê²¬í•˜ê³  ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í–ˆëŠ”ì§€, ê·¸ë¦¬ê³  ì˜ì‚¬ì†Œí†µì„ ì–´ë–»ê²Œ í–ˆëŠ”ì§€ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.\n\ní˜„ì¬ ì œê³µëœ ì •ë³´ë¡œëŠ” í‰ê°€ë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, ì¶”ê°€ì ì¸ ì„±ì°° ë‚´ìš©ì„ ì œê³µí•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."
        }
    
    prompt = f"""
    ë‹¤ìŒ í•™ìŠµìì˜ ì„±ì°° ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì œí•´ê²° ì—­ëŸ‰ì„ í‰ê°€í•´ì£¼ì„¸ìš”:
    
    ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•˜ê³ , ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”:
    
    {{
        "ë¬¸ì œì´í•´": {{
            "ì ìˆ˜": 1~5 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê°œì„ ì œì•ˆ": "êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ"
        }},
        "ë¶„ì„ì ì‚¬ê³ ": {{
            "ì ìˆ˜": 1~5 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê°œì„ ì œì•ˆ": "êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ"
        }},
        "ëŒ€ì•ˆë°œê²¬ë°ê¸°íš": {{
            "ì ìˆ˜": 1~5 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê°œì„ ì œì•ˆ": "êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ"
        }},
        "ì˜ì‚¬ì†Œí†µ": {{
            "ì ìˆ˜": 1~5 ì‚¬ì´ì˜ ì •ìˆ˜ê°’,
            "ê°œì„ ì œì•ˆ": "êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ"
        }},
        "ì´ì ": "20ì  ë§Œì  ì¤‘ Xì ",
        "ì¢…í•©í‰ê°€": "ì „ì²´ì ì¸ í‰ê°€ ìš”ì•½"
    }}
    
    ì„±ì°° ë‚´ìš©: {reflection_text}
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=800
        )
        
        result = response.choices[0].message.content.strip()
        return parse_gpt_json_response(result)
    except Exception as e:
        return {"error": f"í‰ê°€ ì‹¤íŒ¨: {e}"}

# â”€â”€â”€â”€â”€ ë‚˜ë¨¸ì§€ í•¨ìˆ˜ë“¤ì€ ê¸°ì¡´ê³¼ ë™ì¼ â”€â”€â”€â”€â”€
def display_emotional_words(analysis1: dict, analysis2: dict) -> None:
    """ê°ì •ì  ì–¸ì–´ ì‹œê°í™”"""
    st.markdown("#### ğŸ”¤ ê°ì •ì  í‘œí˜„ ë¹„êµ")
    
    # ë°ì´í„° í¬ë§·íŒ…
    analysis1 = format_analysis_for_display(analysis1, "analysis")
    analysis2 = format_analysis_for_display(analysis2, "analysis")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**ê¸°ì‚¬ 1**")
        if "ê°ì •ì ì–¸ì–´" in analysis1 and analysis1["ê°ì •ì ì–¸ì–´"]:
            words = analysis1["ê°ì •ì ì–¸ì–´"]
            word_html = ""
            for i, word in enumerate(words):
                size = 20 - i*2
                color = ["#ff6b6b", "#4ecdc4", "#45b7d1", "#96ceb4", "#feca57"][i % 5]
                word_html += f'<span style="font-size:{size}px; color:{color}; margin:5px; font-weight:bold;">{word}</span> '
            
            st.markdown(f'<div style="line-height:2;">{word_html}</div>', unsafe_allow_html=True)
        else:
            st.info("ê°ì •ì  í‘œí˜„ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    with col2:
        st.markdown("**ê¸°ì‚¬ 2**")
        if "ê°ì •ì ì–¸ì–´" in analysis2 and analysis2["ê°ì •ì ì–¸ì–´"]:
            words = analysis2["ê°ì •ì ì–¸ì–´"]
            word_html = ""
            for i, word in enumerate(words):
                size = 20 - i*2
                color = ["#ff6b6b", "#4ecdc4", "#45b7d1", "#96ceb4", "#feca57"][i % 5]
                word_html += f'<span style="font-size:{size}px; color:{color}; margin:5px; font-weight:bold;">{word}</span> '
            
            st.markdown(f'<div style="line-height:2;">{word_html}</div>', unsafe_allow_html=True)
        else:
            st.info("ê°ì •ì  í‘œí˜„ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def create_simple_gauge(value: int, title: str) -> None:
    """ê°„ë‹¨í•œ ê²Œì´ì§€ ì‹œê°í™”"""
    percentage = ((value + 3) / 6) * 100
    
    if value <= -2:
        color = "#ff4757"
        emoji = "ğŸ˜"
    elif value <= -1:
        color = "#ffa502"
        emoji = "ğŸ˜•"
    elif value == 0:
        color = "#747d8c"
        emoji = "ğŸ˜"
    elif value <= 1:
        color = "#2ed573"
        emoji = "ğŸ™‚"
    else:
        color = "#5352ed"
        emoji = "ğŸ˜Š"
    
    gauge_html = f"""
    <div style="text-align: center; margin: 20px; padding: 20px; border-radius: 10px; background-color: #f8f9fa;">
        <h4 style="margin-bottom: 15px;">{title}</h4>
        <div style="font-size: 30px; margin-bottom: 10px;">{emoji}</div>
        <div style="width: 200px; height: 20px; background-color: #e1e8ed; border-radius: 10px; margin: 0 auto; position: relative;">
            <div style="width: {percentage}%; height: 100%; background-color: {color}; border-radius: 10px;"></div>
        </div>
        <p style="margin-top: 10px; font-weight: bold; color: {color}; font-size: 18px;">{value}ì </p>
    </div>
    """
    st.markdown(gauge_html, unsafe_allow_html=True)

def create_enhanced_comparison_chart(analysis1: dict, analysis2: dict) -> None:
    """ê°œì„ ëœ ë…¼ì¡° ë¹„êµ ì°¨íŠ¸"""
    # ë°ì´í„° í¬ë§·íŒ…
    analysis1 = format_analysis_for_display(analysis1, "analysis")
    analysis2 = format_analysis_for_display(analysis2, "analysis")
    
    if "error" in analysis1 or "error" in analysis2:
        st.error("ë…¼ì¡° ë¶„ì„ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    st.markdown("#### ğŸ“Š ë…¼ì¡° ì ìˆ˜ ë¹„êµ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        create_simple_gauge(analysis1.get('ë…¼ì¡°ì ìˆ˜', 0), "ê¸°ì‚¬ 1 ë…¼ì¡°")
    with col2:
        create_simple_gauge(analysis2.get('ë…¼ì¡°ì ìˆ˜', 0), "ê¸°ì‚¬ 2 ë…¼ì¡°")
    
    # ì‹ ë¢°ë„ & ê°ê´€ì„± ì°¨íŠ¸
    st.markdown("#### ğŸ“ˆ ì‹ ë¢°ë„ & ê°ê´€ì„±")
    
    trust1 = analysis1.get('ì‹ ë¢°ë„ì ìˆ˜', 5)
    trust2 = analysis2.get('ì‹ ë¢°ë„ì ìˆ˜', 5)
    obj1 = analysis1.get('ê°ê´€ì„±ì ìˆ˜', 5)
    obj2 = analysis2.get('ê°ê´€ì„±ì ìˆ˜', 5)
    
    metrics_df = pd.DataFrame({
        'ì§€í‘œ': ['ì‹ ë¢°ë„', 'ê°ê´€ì„±'],
        'ê¸°ì‚¬1': [trust1, obj1],
        'ê¸°ì‚¬2': [trust2, obj2]
    })
    st.bar_chart(metrics_df.set_index('ì§€í‘œ'))

def gpt_feedback(korean_text: str) -> str:
    """í•œêµ­ì–´ ì‘ë¬¸ì— ëŒ€í•œ í•œêµ­ì–´ í”¼ë“œë°± ì œê³µ"""
    if not OPENAI_OK or client is None:
        return "âš ï¸ GPT ì‚¬ìš©ì„ ìœ„í•œ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤."
    if not korean_text.strip():
        return "âš ï¸ í”¼ë“œë°±í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."

    prompt = f"""
    ë‹¹ì‹ ì€ í•œêµ­ì¸ í•™ìŠµìë¥¼ ìœ„í•œ ê¸€ì“°ê¸° ì§€ë„êµì‚¬ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¹„êµ ì„¤ëª…ë¬¸ì„ í‰ê°€í•˜ê³  ê±´ì„¤ì ì¸ í”¼ë“œë°±ì„ í•œêµ­ì–´ë¡œ ì œê³µí•˜ì„¸ìš”.

    ë‹¤ìŒ ë£¨ë¸Œë¦­ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”:

    **1. ë‚´ìš© ë…¼ë¦¬ì„± (Content Logic)** 
    - ì£¼ì¥ì˜ ëª…í™•ì„±, ê·¼ê±° ì œì‹œ ì¶©ë¶„ì„±, ë…¼ë¦¬ì  ì—°ê²°, ë¬¸ì œ ìƒí™© ë¶„ì„ ê¹Šì´

    **2. êµ¬ì„± ì²´ê³„ì„± (Organization)**
    - ì„œë¡ -ë³¸ë¡ -ê²°ë¡  êµ¬ì¡°, ë¬¸ë‹¨ ê°„ ì—°ê²°ê³¼ íë¦„, ì‘ì§‘ì„±ê³¼ ì¼ê´€ì„±

    **3. ë¬¸ë²•Â·ì–´íœ˜ ì •í™•ì„± (Language Accuracy)**
    - ë¬¸ë²•ì  ì •í™•ì„±, ë¬¸ì¥ êµ¬ì¡°ì˜ ë‹¤ì–‘ì„±, ì–´íœ˜ ì„ íƒì˜ ì ì ˆì„±

    ê° ì˜ì—­ë³„ë¡œ êµ¬ì²´ì ì¸ í”¼ë“œë°±ê³¼ 3-5ê°œì˜ ê°œì„  ì œì•ˆì„ ì œê³µí•´ì£¼ì„¸ìš”.

    í‰ê°€ ëŒ€ìƒ ê¸€:
    {korean_text}
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸€ì“°ê¸° ì§€ë„êµì‚¬ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=1200
        )
        return response.choices[0].message.content.strip()
    except APIError as e:
        return f"âš ï¸ OpenAI API ì˜¤ë¥˜: {e}"
    except Exception as e:
        return f"âš ï¸ GPT í˜¸ì¶œ ì˜¤ë¥˜: {e}"

def translate_to_korean(text: str) -> str:
    """ì˜ë¬¸ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­"""
    if not OPENAI_OK or client is None:
        return "ë²ˆì—­ ë¶ˆê°€: API ì˜¤ë¥˜"
    if "ìš”ì•½ ì‹¤íŒ¨" in text or "ìš”ì•½ ë¶ˆê°€" in text:
        return "ì›ë³¸ ìš”ì•½ì´ ì—†ì–´ ë²ˆì—­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    if not text.strip():
        return "ë²ˆì—­ ë¶ˆê°€: ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."

    prompt = f"ë‹¤ìŒ ì˜ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì¤˜:\n\n{text}"
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=1000
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"ë²ˆì—­ ì‹¤íŒ¨: {e}"

def translate_to_english(text: str) -> str:
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­"""
    if not OPENAI_OK or client is None:
        return "ë²ˆì—­ ë¶ˆê°€: API ì˜¤ë¥˜"
    if not text.strip():
        return "ë²ˆì—­ ë¶ˆê°€: ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."

    prompt = f"ë‹¤ìŒ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ì˜ì–´ë¡œ ë²ˆì—­í•´ì¤˜:\n\n{text}"
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=1200
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"ë²ˆì—­ ì‹¤íŒ¨: {e}"

def create_docx_content(text: str, analysis_data: dict = None) -> bytes:
    """í…ìŠ¤íŠ¸ë¥¼ DOCX íŒŒì¼ë¡œ ë³€í™˜í•˜ì—¬ ë°”ì´íŠ¸ ë°ì´í„° ë°˜í™˜ (ìˆ˜ì •ë¨)"""
    doc = Document()
    doc.add_heading('News Comparison Analysis', 0)
    doc.add_paragraph(f"ì‘ì„±ì¼: {datetime.datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}")
    doc.add_paragraph("")
    
    if analysis_data:
        doc.add_heading('ë¶„ì„ ìš”ì•½', level=1)
        
        for key, value in analysis_data.items():
            if key == "ë…¼ì¡°ë¶„ì„1":
                formatted_analysis1 = format_analysis_for_display(value, "analysis")
                doc.add_paragraph(format_for_docx(formatted_analysis1, "ë…¼ì¡°ë¶„ì„1"))
                doc.add_paragraph("")
            elif key == "ë…¼ì¡°ë¶„ì„2":
                formatted_analysis2 = format_analysis_for_display(value, "analysis")
                doc.add_paragraph(format_for_docx(formatted_analysis2, "ë…¼ì¡°ë¶„ì„2"))
                doc.add_paragraph("")
            elif key == "ì˜ì–´í‘œí˜„í‰ê°€":
                formatted_evaluation = format_analysis_for_display(value, "evaluation")
                doc.add_paragraph(format_for_docx(formatted_evaluation, "ì˜ì–´í‘œí˜„í‰ê°€"))
                doc.add_paragraph("")
            elif key == "ë¬¸ì œí•´ê²°í‰ê°€":
                formatted_problem_solving = format_analysis_for_display(value, "assessment")
                doc.add_paragraph(format_for_docx(formatted_problem_solving, "ë¬¸ì œí•´ê²°í‰ê°€"))
                doc.add_paragraph("")
        
        doc.add_paragraph("")
    
    doc.add_heading('ì‘ì„±ëœ ì„¤ëª…ë¬¸', level=1)
    for line in text.splitlines():
        if line.strip():
            doc.add_paragraph(line)
    
    with tempfile.NamedTemporaryFile() as tmp:
        doc.save(tmp.name)
        tmp.seek(0)
        return tmp.read()

# â”€â”€â”€â”€â”€ Streamlit ì•± ì„¤ì • â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="News Comparison Assistant", 
    layout="wide",
    initial_sidebar_state="collapsed"
)

# â”€â”€â”€â”€â”€ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” â”€â”€â”€â”€â”€
if "stage" not in st.session_state:
    st.session_state.update({
        "stage": "input",
        "article1": "", "article2": "",
        "summary1": "", "summary2": "",
        "summary1_kr": "", "summary2_kr": "",
        "tone_analysis1": {}, "tone_analysis2": {},
        "draft": "", "feedback": "",
        "writing_evaluation": {},
        "problem_solving_score": {},
        "reflection_log": [],
        "final_text": ""
    })

# â”€â”€â”€â”€â”€ ë©”ì¸ íƒ€ì´í‹€ê³¼ ê²½ê³  ë©”ì‹œì§€ â”€â”€â”€â”€â”€
st.title("ğŸ“° News Comparison and Writing Assistant")

if not OPENAI_OK:
    st.warning("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ìš”ì•½ ë° í”¼ë“œë°± ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€ ì§„í–‰ ìƒíƒœ í‘œì‹œ â”€â”€â”€â”€â”€
progress_stages = ["input", "analysis", "draft", "feedback", "final"]
current_stage_idx = progress_stages.index(st.session_state.stage)
progress = (current_stage_idx + 1) / len(progress_stages)

st.progress(progress)
stage_names = ["ê¸°ì‚¬ ì…ë ¥", "ë…¼ì¡° ë¶„ì„", "ì´ˆì•ˆ ì‘ì„±", "AI í”¼ë“œë°±", "ìµœì¢… ì™„ì„±"]
st.caption(f"í˜„ì¬ ë‹¨ê³„: {stage_names[current_stage_idx]} ({current_stage_idx + 1}/{len(progress_stages)})")

# â”€â”€â”€â”€â”€ ë‹¨ê³„ë³„ í™”ë©´ êµ¬ì„± â”€â”€â”€â”€â”€

# 1ë‹¨ê³„: ê¸°ì‚¬ ì…ë ¥
if st.session_state.stage == "input":
    st.subheader("â‘  ê¸°ì‚¬ ë³¸ë¬¸ ì…ë ¥")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**ê¸°ì‚¬ 1 ë³¸ë¬¸**")
        error_placeholder1 = st.empty()
        article1 = st.text_area(
            "ì²« ë²ˆì§¸ ê¸°ì‚¬ì˜ ë³¸ë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
            value=st.session_state.get("article1", ""),
            height=300,
            key="article1_input"
        )
    
    with col2:
        st.markdown("**ê¸°ì‚¬ 2 ë³¸ë¬¸**")
        error_placeholder2 = st.empty()
        article2 = st.text_area(
            "ë‘ ë²ˆì§¸ ê¸°ì‚¬ì˜ ë³¸ë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
            value=st.session_state.get("article2", ""),
            height=300,
            key="article2_input"
        )
    
    st.markdown("---")
    
    col_btn1, col_btn2 = st.columns([1, 1])
    with col_btn2:
        overall_error_placeholder = st.empty()
        if st.button("ë‹¤ìŒ ë‹¨ê³„ â†’ (ë¶„ì„ ì‹œì‘)", type="primary", use_container_width=True):
            is_valid = True
            if not article1.strip():
                error_placeholder1.error("ê¸°ì‚¬ 1 ë³¸ë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                is_valid = False
            else:
                error_placeholder1.empty()

            if not article2.strip():
                error_placeholder2.error("ê¸°ì‚¬ 2 ë³¸ë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                is_valid = False
            else:
                error_placeholder2.empty()

            if is_valid:
                overall_error_placeholder.empty()
                st.session_state.article1 = article1
                st.session_state.article2 = article2
                st.session_state.stage = "analysis"
                st.rerun()
            else:
                overall_error_placeholder.error("ëª¨ë“  í•„ìˆ˜ ì…ë ¥ í•„ë“œë¥¼ ì±„ì›Œì£¼ì„¸ìš”.")

# 2ë‹¨ê³„: ë…¼ì¡° ë¶„ì„ ë° ì‹œê°í™”
elif st.session_state.stage == "analysis":
    st.subheader("â‘¡ ë…¼ì¡° ë¶„ì„ ë° ìš”ì•½")
    
    if not st.session_state.get("summary1"):
        with st.spinner("ê¸°ì‚¬ ë¶„ì„ ë° ìš”ì•½ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
            st.session_state.summary1 = summarize_text(st.session_state.article1)
            st.session_state.summary2 = summarize_text(st.session_state.article2)
            
            st.session_state.tone_analysis1 = analyze_tone_and_stance(st.session_state.article1)
            st.session_state.tone_analysis2 = analyze_tone_and_stance(st.session_state.article2)
            
            st.session_state.summary1_kr = translate_to_korean(st.session_state.summary1)
            st.session_state.summary2_kr = translate_to_korean(st.session_state.summary2)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ—ï¸ ê¸°ì‚¬ 1 ë¶„ì„")
        with st.expander("ìš”ì•½ (ì˜ì–´/í•œêµ­ì–´)", expanded=True):
            st.info(f"**[English]**\n{st.session_state.summary1}")
            st.success(f"**[í•œêµ­ì–´]**\n{st.session_state.summary1_kr}")
        
        with st.expander("ë…¼ì¡° ë¶„ì„", expanded=True):
            analysis1 = format_analysis_for_display(st.session_state.tone_analysis1, "analysis")
            if "error" not in analysis1:
                st.markdown(f"**ë…¼ì¡°**: {analysis1.get('ë…¼ì¡°ë¶„ë¥˜', 'N/A')} ({analysis1.get('ë…¼ì¡°ì ìˆ˜', 0)}ì )")
                st.markdown(f"**ì‹ ë¢°ë„**: {analysis1.get('ì‹ ë¢°ë„ì ìˆ˜', 0)}/10ì ")
                st.markdown(f"**ê°ê´€ì„±**: {analysis1.get('ê°ê´€ì„±ì ìˆ˜', 0)}/10ì ")
                
                if analysis1.get('ì£¼ìš”ë…¼ì '):
                    st.markdown("**ì£¼ìš” ë…¼ì **:")
                    for i, point in enumerate(analysis1.get('ì£¼ìš”ë…¼ì ', []), 1):
                        st.markdown(f"  {i}. {point}")
            else:
                st.error(analysis1.get("error", "ë¶„ì„ ì˜¤ë¥˜"))
    
    with col2:
        st.markdown("#### ğŸ—ï¸ ê¸°ì‚¬ 2 ë¶„ì„")
        with st.expander("ìš”ì•½ (ì˜ì–´/í•œêµ­ì–´)", expanded=True):
            st.info(f"**[English]**\n{st.session_state.summary2}")
            st.success(f"**[í•œêµ­ì–´]**\n{st.session_state.summary2_kr}")
        
        with st.expander("ë…¼ì¡° ë¶„ì„", expanded=True):
            analysis2 = format_analysis_for_display(st.session_state.tone_analysis2, "analysis")
            if "error" not in analysis2:
                st.markdown(f"**ë…¼ì¡°**: {analysis2.get('ë…¼ì¡°ë¶„ë¥˜', 'N/A')} ({analysis2.get('ë…¼ì¡°ì ìˆ˜', 0)}ì )")
                st.markdown(f"**ì‹ ë¢°ë„**: {analysis2.get('ì‹ ë¢°ë„ì ìˆ˜', 0)}/10ì ")
                st.markdown(f"**ê°ê´€ì„±**: {analysis2.get('ê°ê´€ì„±ì ìˆ˜', 0)}/10ì ")
                
                if analysis2.get('ì£¼ìš”ë…¼ì '):
                    st.markdown("**ì£¼ìš” ë…¼ì **:")
                    for i, point in enumerate(analysis2.get('ì£¼ìš”ë…¼ì ', []), 1):
                        st.markdown(f"  {i}. {point}")
            else:
                st.error(analysis2.get("error", "ë¶„ì„ ì˜¤ë¥˜"))
    
    # ë…¼ì¡° ì‹œê°í™”
    st.markdown("---")
    create_enhanced_comparison_chart(st.session_state.tone_analysis1, st.session_state.tone_analysis2)
    
    # ê°ì •ì  ì–¸ì–´ ì‹œê°í™”
    st.markdown("---")
    display_emotional_words(st.session_state.tone_analysis1, st.session_state.tone_analysis2)
    
    # ì„±ì°° ì§ˆë¬¸
    st.markdown("---")
    st.markdown("#### ğŸ¤” ë¶„ì„ ì„±ì°°")
    reflection_error_placeholder = st.empty()
    reflection = st.text_area(
        "ë‘ ê¸°ì‚¬ì˜ ì°¨ì´ì ê³¼ ê³µí†µì , ê·¸ë¦¬ê³  ê°ê°ì˜ ë…¼ì¡°ì— ëŒ€í•œ ë‹¹ì‹ ì˜ ìƒê°ì„ ì ì–´ë³´ì„¸ìš”:",
        height=100,
        key="analysis_reflection"
    )
    
    col_btn1, col_btn2 = st.columns([1, 1])
    with col_btn1:
        if st.button("â† ì´ì „ ë‹¨ê³„", use_container_width=True):
            st.session_state.stage = "input"
            st.rerun()
    
    with col_btn2:
        if st.button("ì´ˆì•ˆ ì‘ì„± ë‹¨ê³„ë¡œ â†’", type="primary", use_container_width=True):
            if not reflection.strip():
                reflection_error_placeholder.error("ë¶„ì„ ì„±ì°° ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                reflection_error_placeholder.empty()
                st.session_state.reflection_log.append({
                    "stage": "analysis",
                    "content": reflection,
                    "timestamp": datetime.datetime.now()
                })
                st.session_state.stage = "draft"
                st.rerun()

# 3ë‹¨ê³„: ì´ˆì•ˆ ì‘ì„± (ê¸°ì¡´ê³¼ ë™ì¼í•˜ë¯€ë¡œ ìƒëµ)
elif st.session_state.stage == "draft":
    st.subheader("â‘¢ ë¹„êµ ì„¤ëª…ë¬¸ ì´ˆì•ˆ ì‘ì„±")

    def paragraph_input_with_guide(title, key, guide_title, guide_lines, summary_text=None, hint_key=None, hint_prompt=None):
        col1, col2 = st.columns([2, 1])
        with col1:
            st.subheader(title)
            if key not in st.session_state:
                st.session_state[key] = ""
            
            error_key = f"{key}_error_placeholder"
            if error_key not in st.session_state:
                st.session_state[error_key] = st.empty()
            
            user_input = st.text_area("", key=key, height=160)
        
        with col2:
            st.markdown(f"#### ğŸ§­ {guide_title}")
            for line in guide_lines:
                st.markdown(f"- {line}")
            
            if summary_text:
                st.markdown("#### ğŸ—ï¸ ê´€ë ¨ ê¸°ì‚¬ ìš”ì•½")
                summary_en = summary_text
                summary_kr_key = "summary1_kr" if summary_en == st.session_state.get("summary1") else "summary2_kr"
                summary_kr = st.session_state.get(summary_kr_key, "ë²ˆì—­ ì—†ìŒ")
                
                with st.expander("ìš”ì•½ë¬¸ ë³´ê¸°", expanded=True):
                    st.info(f"**[English]**\n{summary_en}")
                    st.success(f"**[í•œêµ­ì–´]**\n{summary_kr}")

            if hint_key and hint_prompt and OPENAI_OK:
                if f"{hint_key}_hint" not in st.session_state:
                    st.session_state[f"{hint_key}_hint"] = ""
                if st.button(f"âœï¸ AI íŒíŠ¸ ë°›ê¸°", key=f"{hint_key}_btn"):
                    with st.spinner("AI íŒíŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                        try:
                            hint_response = client.chat.completions.create(
                                model="gpt-4o",
                                messages=[{"role": "user", "content": hint_prompt}],
                                temperature=0.5,
                                max_tokens=300
                            )
                            st.session_state[f"{hint_key}_hint"] = hint_response.choices[0].message.content.strip()
                        except Exception as e:
                            st.session_state[f"{hint_key}_hint"] = f"âŒ íŒíŠ¸ ìƒì„± ì‹¤íŒ¨: {e}"
                if st.session_state[f"{hint_key}_hint"]:
                    st.markdown("#### ğŸ’¡ AI íŒíŠ¸")
                    st.success(st.session_state[f"{hint_key}_hint"])
        
        return user_input

    intro = paragraph_input_with_guide(
        "1ï¸âƒ£ ì„œë¡ ", "intro_input", "ë¹„êµ ì£¼ì œ ì†Œê°œ", [
            "ë¹„êµí•  ë‘ ê¸°ì‚¬ ê°„ë‹¨íˆ ì†Œê°œ",
            "ê¸€ì˜ ëª©ì , ë¬¸ì œ ì œê¸°",
            "ë‘ ê´€ì  ê°„ ì°¨ì´ì— ëŒ€í•œ ì•”ì‹œ"
        ],
        hint_key="intro", hint_prompt="ë¹„êµ ì„¤ëª…ë¬¸ì˜ ì„œë¡ ì„ ì“°ê¸° ìœ„í•œ ë¬¸ì¥ êµ¬ì„± íŒíŠ¸ë¥¼ 3ê°œ ì œì‹œí•´ì¤˜. (í•œêµ­ì–´)"
    )

    body1 = paragraph_input_with_guide(
        "2ï¸âƒ£ ë³¸ë¡  - ê¸°ì‚¬ 1 ì„¤ëª…", "body1_input", "ê¸°ì‚¬ 1 ìš”ì•½", [
            "ê¸°ì‚¬ 1ì˜ ì£¼ì¥ê³¼ ê·¼ê±° ìš”ì•½",
            "ìë£Œ, ì‚¬ë¡€, ê°•ì¡°ì  ê¸°ìˆ "
        ],
        summary_text=st.session_state.get("summary1"),
        hint_key="body1", hint_prompt="ì²« ë²ˆì§¸ ê¸°ì‚¬ ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” ë¬¸ë‹¨ ì‘ì„±ì— ì“¸ ìˆ˜ ìˆëŠ” ë¬¸ì¥ ì˜ˆì‹œ 3ê°œë¥¼ ì œì‹œí•´ì¤˜. (í•œêµ­ì–´)"
    )

    body2 = paragraph_input_with_guide(
        "3ï¸âƒ£ ë³¸ë¡  - ê¸°ì‚¬ 2 ì„¤ëª…", "body2_input", "ê¸°ì‚¬ 2 ìš”ì•½", [
            "ê¸°ì‚¬ 2ì˜ ì£¼ìš” ë‚´ìš© ìš”ì•½",
            "ê¸°ì‚¬ 1ê³¼ ë¹„êµí–ˆì„ ë•Œì˜ íŠ¹ì§• ì–¸ê¸‰"
        ],
        summary_text=st.session_state.get("summary2"),
        hint_key="body2", hint_prompt="ë‘ ë²ˆì§¸ ê¸°ì‚¬ ë‚´ìš©ì„ ìš”ì•½í•˜ë©° ë¹„êµí•˜ëŠ” ë¬¸ë‹¨ì„ ì“°ê¸° ìœ„í•œ ë¬¸ì¥ ì˜ˆì‹œ 3ê°œë¥¼ ì œì‹œí•´ì¤˜. (í•œêµ­ì–´)"
    )

    compare = paragraph_input_with_guide(
        "4ï¸âƒ£ ë¹„êµ ë¶„ì„", "compare_input", "ê³µí†µì ê³¼ ì°¨ì´ì ", [
            "ê¸°ì¤€(ê´€ì , ëª©ì  ë“±)ì„ ì„¤ì •í•´ ë¹„êµ",
            "ë…¼ë¦¬ì ìœ¼ë¡œ ìœ ì‚¬ì Â·ì°¨ì´ì  ì œì‹œ"
        ],
        hint_key="compare", hint_prompt="ë‘ ê¸°ì‚¬ ê°„ ê³µí†µì ê³¼ ì°¨ì´ì ì„ ë¹„êµí•˜ì—¬ ë¶„ì„í•˜ëŠ” ë¬¸ë‹¨ì„ ìœ„í•œ ë¬¸ì¥ êµ¬ì„± íŒíŠ¸ë¥¼ ì œì‹œí•´ì¤˜. (í•œêµ­ì–´)"
    )

    conclusion = paragraph_input_with_guide(
        "5ï¸âƒ£ ê²°ë¡ ", "conclusion_input", "ìš”ì•½ ë° ì˜ê²¬", [
            "ì „ì²´ ë¹„êµ ë‚´ìš© ìš”ì•½",
            "ìì‹ ì˜ ì˜ê²¬ì´ë‚˜ í‰ê°€ í¬í•¨"
        ],
        hint_key="conclusion", hint_prompt="ë¹„êµ ì„¤ëª…ë¬¸ ê²°ë¡ ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë§ˆë¬´ë¦¬ ë¬¸ì¥ 3ê°œë¥¼ ì œì•ˆí•´ì¤˜. (í•œêµ­ì–´)"
    )

    st.markdown("---")
    st.markdown("### ğŸ§¾ ì „ì²´ ì´ˆì•ˆ ë¯¸ë¦¬ë³´ê¸°")

    full_draft = "\n\n".join([
        f"[ì„œë¡ ]\n{intro}",
        f"[ë³¸ë¡  1 - ê¸°ì‚¬ 1]\n{body1}",
        f"[ë³¸ë¡  2 - ê¸°ì‚¬ 2]\n{body2}",
        f"[ë¹„êµ ë¶„ì„]\n{compare}",
        f"[ê²°ë¡ ]\n{conclusion}"
    ])

    st.session_state.draft = full_draft

    st.markdown(f"""<div style="background-color:#f9f9f9; padding:15px; border-radius:10px; color:black; font-size:16px;">
<pre style="white-space: pre-wrap; word-wrap: break-word;">{full_draft}</pre>
</div>""", unsafe_allow_html=True)

    col_btn1, col_btn2 = st.columns([1, 1])
    with col_btn1:
        if st.button("â† ì´ì „ ë‹¨ê³„", use_container_width=True):
            st.session_state.stage = "analysis"
            st.rerun()

    with col_btn2:
        overall_draft_error = st.empty()
        if st.button("AI í”¼ë“œë°± ë°›ê¸° â†’", type="primary", use_container_width=True):
            paragraphs = [
                (intro, "intro_input", "ì„œë¡ "),
                (body1, "body1_input", "ë³¸ë¡  1"),
                (body2, "body2_input", "ë³¸ë¡  2"),
                (compare, "compare_input", "ë¹„êµ ë¶„ì„"),
                (conclusion, "conclusion_input", "ê²°ë¡ ")
            ]
            
            is_valid = True
            for content, key, title in paragraphs:
                error_key = f"{key}_error_placeholder"
                if not content.strip():
                    if error_key in st.session_state:
                        st.session_state[error_key].error(f"{title} ë¶€ë¶„ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.")
                    is_valid = False
                else:
                    if error_key in st.session_state:
                        st.session_state[error_key].empty()
            
            if is_valid:
                overall_draft_error.empty()
                st.session_state.stage = "feedback"
                st.rerun()
            else:
                overall_draft_error.error("ëª¨ë“  ë¬¸ë‹¨ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.")

# 4ë‹¨ê³„: AI í”¼ë“œë°± (ìˆ˜ì •ë¨)
elif st.session_state.stage == "feedback":
    st.subheader("â‘£ AI í”¼ë“œë°± ë° ë£¨ë¸Œë¦­ í‰ê°€")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**ë‚´ ì´ˆì•ˆ**")
        st.text_area(
            "ì‘ì„±í•œ ì´ˆì•ˆ",
            value=st.session_state.draft,
            height=400,
            disabled=True,
            key="draft_display"
        )
    
    with col2:
        st.markdown("**AI í”¼ë“œë°± ë° í‰ê°€**")
        
        if "feedback" not in st.session_state or not st.session_state.feedback:
            if OPENAI_OK:
                with st.spinner("AI í”¼ë“œë°± ë° í‰ê°€ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    # í•œêµ­ì–´ í”¼ë“œë°± ìƒì„±
                    feedback = gpt_feedback(st.session_state.draft)
                    st.session_state.feedback = feedback
                    
                    # ì˜ì–´ í‘œí˜„ ëŠ¥ë ¥ ë£¨ë¸Œë¦­ í‰ê°€
                    english_draft = translate_to_english(st.session_state.draft)
                    st.session_state.writing_evaluation = evaluate_writing_rubric(english_draft)
            else:
                st.session_state.feedback = "âš ï¸ AI í”¼ë“œë°± ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        
        # íƒ­ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ í‘œì‹œ
        tab1, tab2 = st.tabs(["ğŸ‡°ğŸ‡· í•œêµ­ì–´ í”¼ë“œë°±", "ğŸ“Š ë£¨ë¸Œë¦­ í‰ê°€"])
        
        with tab1:
            st.text_area(
                "AI í”¼ë“œë°±",
                value=st.session_state.feedback,
                height=350,
                disabled=True
            )
        
        with tab2:
            st.markdown("#### ğŸ“‹ ì˜ì–´ í‘œí˜„ ëŠ¥ë ¥ í‰ê°€")
            eval_data = format_analysis_for_display(st.session_state.writing_evaluation, "evaluation")
            
            if "error" not in eval_data:
                # ì ìˆ˜ ì¹´ë“œ í˜•íƒœë¡œ í‘œì‹œ
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    if "ë‚´ìš©ë…¼ë¦¬ì„±" in eval_data and isinstance(eval_data["ë‚´ìš©ë…¼ë¦¬ì„±"], dict):
                        logic = eval_data["ë‚´ìš©ë…¼ë¦¬ì„±"]
                        st.metric("ë‚´ìš© ë…¼ë¦¬ì„±", f"{logic.get('ì ìˆ˜', 0)}/4ì ")
                        st.caption(logic.get('ê·¼ê±°', ''))
                    else:
                        st.metric("ë‚´ìš© ë…¼ë¦¬ì„±", "N/A")
                
                with col2:
                    if "êµ¬ì„±ì²´ê³„ì„±" in eval_data and isinstance(eval_data["êµ¬ì„±ì²´ê³„ì„±"], dict):
                        org = eval_data["êµ¬ì„±ì²´ê³„ì„±"]
                        st.metric("êµ¬ì„± ì²´ê³„ì„±", f"{org.get('ì ìˆ˜', 0)}/4ì ")
                        st.caption(org.get('ê·¼ê±°', ''))
                    else:
                        st.metric("êµ¬ì„± ì²´ê³„ì„±", "N/A")
                
                with col3:
                    if "ë¬¸ë²•ì–´íœ˜ì •í™•ì„±" in eval_data and isinstance(eval_data["ë¬¸ë²•ì–´íœ˜ì •í™•ì„±"], dict):
                        lang = eval_data["ë¬¸ë²•ì–´íœ˜ì •í™•ì„±"]
                        st.metric("ë¬¸ë²•Â·ì–´íœ˜", f"{lang.get('ì ìˆ˜', 0)}/4ì ")
                        st.caption(lang.get('ê·¼ê±°', ''))
                    else:
                        st.metric("ë¬¸ë²•Â·ì–´íœ˜", "N/A")
                
                if eval_data.get('ì´ì '):
                    st.markdown(f"**ì´ì **: {eval_data['ì´ì ']}")
                
                if eval_data.get('ì¢…í•©í‰ê°€'):
                    st.markdown("**ì¢…í•© í‰ê°€**")
                    st.info(eval_data['ì¢…í•©í‰ê°€'])
            else:
                st.error(eval_data.get("error", "í‰ê°€ ì˜¤ë¥˜"))
    
    st.markdown("---")
    st.markdown("#### ğŸ¤” í”¼ë“œë°± ì„±ì°°")
    feedback_reflection_error = st.empty()
    feedback_reflection = st.text_area(
        "AI í”¼ë“œë°±ì„ ë°›ì€ í›„ ëŠë‚€ ì ê³¼ ê°œì„ í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì„ ì ì–´ë³´ì„¸ìš”:",
        height=100,
        key="feedback_reflection"
    )
    
    col_btn1, col_btn2 = st.columns([1, 1])
    with col_btn1:
        if st.button("â† ì´ì „ ë‹¨ê³„", use_container_width=True):
            st.session_state.stage = "draft"
            st.rerun()
    
    with col_btn2:
        if st.button("ìµœì¢… ìˆ˜ì • ë‹¨ê³„ë¡œ â†’", type="primary", use_container_width=True):
            if not feedback_reflection.strip():
                feedback_reflection_error.error("í”¼ë“œë°± ì„±ì°° ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                feedback_reflection_error.empty()
                st.session_state.reflection_log.append({
                    "stage": "feedback",
                    "content": feedback_reflection,
                    "timestamp": datetime.datetime.now()
                })
                # ë¬¸ì œí•´ê²° ì—­ëŸ‰ í‰ê°€ ìˆ˜í–‰
                st.session_state.problem_solving_score = assess_problem_solving(feedback_reflection)
                st.session_state.stage = "final"
                st.rerun()

# 5ë‹¨ê³„: ìµœì¢… ì™„ì„± (ìˆ˜ì •ë¨)
elif st.session_state.stage == "final":
    st.subheader("â‘¤ ìµœì¢… ìˆ˜ì • ë° ì™„ì„±")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("**ìµœì¢… ìˆ˜ì •**")
        if "final_text" not in st.session_state or not st.session_state.final_text:
             st.session_state.final_text = st.session_state.draft
             
        final_text = st.text_area(
            "í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ìµœì¢… ìˆ˜ì •í•˜ì„¸ìš”",
            value=st.session_state.final_text,
            height=400,
            key="final_input"
        )
        
        st.session_state.final_text = final_text
    
    with col2:
        st.markdown("**ì¢…í•© í‰ê°€ ê²°ê³¼**")
        
        # ë¬¸ì œí•´ê²° ì—­ëŸ‰ í‰ê°€ ê²°ê³¼
        if st.session_state.problem_solving_score:
            with st.expander("ğŸ§  ë¬¸ì œí•´ê²° ì—­ëŸ‰ í‰ê°€", expanded=True):
                problem_data = format_analysis_for_display(st.session_state.problem_solving_score, "assessment")
                
                if "error" not in problem_data:
                    # assessment í‚¤ê°€ ìˆëŠ” ê²½ìš° (ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì‘ë‹µ)
                    if "assessment" in problem_data:
                        st.info(problem_data["assessment"])
                    else:
                        # 4ê°œ ì˜ì—­ì„ 2x2 ê·¸ë¦¬ë“œë¡œ ë°°ì¹˜
                        col1, col2 = st.columns(2)
                        
                        areas = ["ë¬¸ì œì´í•´", "ë¶„ì„ì ì‚¬ê³ ", "ëŒ€ì•ˆë°œê²¬ë°ê¸°íš", "ì˜ì‚¬ì†Œí†µ"]
                        for i, area in enumerate(areas):
                            col = col1 if i % 2 == 0 else col2
                            with col:
                                if area in problem_data and isinstance(problem_data[area], dict):
                                    score = problem_data[area].get('ì ìˆ˜', 0)
                                    st.metric(area.replace('ë°', ' & '), f"{score}/5ì ")
                                elif area in problem_data:
                                    st.metric(area.replace('ë°', ' & '), str(problem_data[area]))
                        
                        if problem_data.get('ì´ì '):
                            st.markdown(f"**ì´ì **: {problem_data['ì´ì ']}")
                        
                        if problem_data.get('ì¢…í•©í‰ê°€'):
                            st.markdown("**ì¢…í•© í‰ê°€**")
                            st.info(problem_data['ì¢…í•©í‰ê°€'])
                else:
                    st.error(problem_data.get("error", "í‰ê°€ ì˜¤ë¥˜"))
        
        # ì˜ì–´ í‘œí˜„ ëŠ¥ë ¥ í‰ê°€ ê²°ê³¼
        if st.session_state.writing_evaluation:
            with st.expander("âœï¸ ì˜ì–´ í‘œí˜„ ëŠ¥ë ¥ í‰ê°€", expanded=True):
                eval_data = format_analysis_for_display(st.session_state.writing_evaluation, "evaluation")
                
                if "error" not in eval_data:
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        if "ë‚´ìš©ë…¼ë¦¬ì„±" in eval_data and isinstance(eval_data["ë‚´ìš©ë…¼ë¦¬ì„±"], dict):
                            logic = eval_data["ë‚´ìš©ë…¼ë¦¬ì„±"]
                            score = logic.get('ì ìˆ˜', 0)
                            st.metric("ë‚´ìš© ë…¼ë¦¬ì„±", f"{score}/4ì ")
                        else:
                            st.metric("ë‚´ìš© ë…¼ë¦¬ì„±", "N/A")
                    
                    with col2:
                        if "êµ¬ì„±ì²´ê³„ì„±" in eval_data and isinstance(eval_data["êµ¬ì„±ì²´ê³„ì„±"], dict):
                            org = eval_data["êµ¬ì„±ì²´ê³„ì„±"]
                            score = org.get('ì ìˆ˜', 0)
                            st.metric("êµ¬ì„± ì²´ê³„ì„±", f"{score}/4ì ")
                        else:
                            st.metric("êµ¬ì„± ì²´ê³„ì„±", "N/A")
                    
                    with col3:
                        if "ë¬¸ë²•ì–´íœ˜ì •í™•ì„±" in eval_data and isinstance(eval_data["ë¬¸ë²•ì–´íœ˜ì •í™•ì„±"], dict):
                            lang = eval_data["ë¬¸ë²•ì–´íœ˜ì •í™•ì„±"]
                            score = lang.get('ì ìˆ˜', 0)
                            st.metric("ë¬¸ë²•Â·ì–´íœ˜", f"{score}/4ì ")
                        else:
                            st.metric("ë¬¸ë²•Â·ì–´íœ˜", "N/A")
                else:
                    st.error(eval_data.get("error", "í‰ê°€ ì˜¤ë¥˜"))
    
    st.markdown("---")
    
    col_btn1, col_btn2, col_btn3, col_btn4 = st.columns([1, 1, 1, 1])
    
    with col_btn1:
        if st.button("â† ì´ì „ ë‹¨ê³„", use_container_width=True):
            st.session_state.stage = "feedback"
            st.rerun()

    with col_btn2:
        # ì¢…í•© ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ
        analysis_summary = {
            "ë…¼ì¡°ë¶„ì„1": st.session_state.tone_analysis1,
            "ë…¼ì¡°ë¶„ì„2": st.session_state.tone_analysis2,
            "ì˜ì–´í‘œí˜„í‰ê°€": st.session_state.writing_evaluation,
            "ë¬¸ì œí•´ê²°í‰ê°€": st.session_state.problem_solving_score
        }
        docx_data = create_docx_content(final_text, analysis_summary)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"news_comparison_complete_{timestamp}.docx"
        st.download_button(
            label="ğŸ“„ ì¢…í•© ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
            data=docx_data,
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            use_container_width=True,
            disabled=not final_text.strip()
        )

    with col_btn4:
        if st.button("ì²˜ìŒë¶€í„° ë‹¤ì‹œ", use_container_width=True):
            # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            for key in list(st.session_state.keys()):
                if key != 'stage':
                    st.session_state.pop(key)
            st.session_state.stage = "input"
            st.rerun()
    
    # ì™„ì„±ëœ ì‘ë¬¸ ë¯¸ë¦¬ë³´ê¸°
    if final_text.strip():
        st.markdown("### ğŸ“‹ ì™„ì„±ëœ ì‘ë¬¸ ë¯¸ë¦¬ë³´ê¸°")
        st.success(final_text)
        
        # í•™ìŠµ ì„±ì°° ë¡œê·¸ í‘œì‹œ
        if st.session_state.reflection_log:
            with st.expander("ğŸ“ í•™ìŠµ ì„±ì°° ê¸°ë¡", expanded=False):
                for idx, log in enumerate(st.session_state.reflection_log):
                    st.markdown(f"**{log['stage']} ë‹¨ê³„ ì„±ì°°:**")
                    st.write(log['content'])
                    st.caption(f"ì‘ì„± ì‹œê°„: {log['timestamp']}")
                    st.markdown("---")

# â”€â”€â”€â”€â”€ ì‚¬ì´ë“œë°” ì •ë³´ â”€â”€â”€â”€â”€
with st.sidebar:
    st.markdown("### ğŸ“ ì‚¬ìš© ë°©ë²•")
    st.markdown("""
    1. **ê¸°ì‚¬ ì…ë ¥**: ë¹„êµí•  ë‘ ê¸°ì‚¬ì˜ ë³¸ë¬¸ì„ ì…ë ¥
    2. **ë…¼ì¡° ë¶„ì„**: AIê°€ ê° ê¸°ì‚¬ì˜ ë…¼ì¡°ì™€ ì…ì¥ì„ ë¶„ì„
    3. **ì´ˆì•ˆ ì‘ì„±**: ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ë¹„êµ ì„¤ëª…ë¬¸ ì‘ì„±
    4. **AI í”¼ë“œë°±**: ì¢…í•©ì ì¸ í”¼ë“œë°±ê³¼ ë£¨ë¸Œë¦­ í‰ê°€ ì œê³µ
    5. **ìµœì¢… ì™„ì„±**: í”¼ë“œë°±ì„ ë°˜ì˜í•œ ìˆ˜ì • í›„ ì¢…í•© ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ
    """)
    
    st.markdown("### âš™ï¸ ì„¤ì • ìƒíƒœ")
    if OPENAI_OK:
        st.success("âœ… OpenAI API ì—°ê²°ë¨")
    else:
        st.error("âŒ OpenAI API ì—°ê²° ì‹¤íŒ¨")
    
    st.markdown("### ğŸ“Š ì§„í–‰ ìƒí™©")
    st.markdown(f"í˜„ì¬ ë‹¨ê³„: **{stage_names[current_stage_idx]}**")
    
    # ì§„í–‰ ìƒí™© ì²´í¬ë¦¬ìŠ¤íŠ¸
    checklist_items = [
        ("ê¸°ì‚¬ ì…ë ¥", bool(st.session_state.get("article1") and st.session_state.get("article2"))),
        ("ë…¼ì¡° ë¶„ì„", bool(st.session_state.get("tone_analysis1") and st.session_state.get("tone_analysis2"))),
        ("ì´ˆì•ˆ ì‘ì„±", bool(st.session_state.get("draft"))),
        ("AI í”¼ë“œë°±", bool(st.session_state.get("feedback"))),
        ("ë£¨ë¸Œë¦­ í‰ê°€", bool(st.session_state.get("writing_evaluation"))),
        ("ìµœì¢… ì™„ì„±", bool(st.session_state.get("final_text")))
    ]
    
    for item, completed in checklist_items:
        icon = "âœ…" if completed else "â³"
        st.markdown(f"{icon} {item}")